{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47737138-e04c-4ce6-8d20-bed805d73508",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7108ae7f-e30e-4f11-a4ae-05c253044225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data mining\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "path = 'C:/Users/aless/OneDrive - Universit√† degli Studi di Catania/tesi/dataset/lag_data.csv'\n",
    "\n",
    "#training\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import cross_validate, LeaveOneGroupOut, HalvingGridSearchCV, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#selection\n",
    "from mlxtend.evaluate import mcnemar_table, mcnemar\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "#interpretability\n",
    "import shap\n",
    "\n",
    "#deployment\n",
    "from micromlgen import port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98b25b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hr_maximum</th>\n",
       "      <th>hr_minimum</th>\n",
       "      <th>hr_abs_maximum</th>\n",
       "      <th>hr_abs_minimum</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>hr_abs_energy</th>\n",
       "      <th>hr_mean_abs_change</th>\n",
       "      <th>hr_cid_ce</th>\n",
       "      <th>temp_maximum</th>\n",
       "      <th>temp_minimum</th>\n",
       "      <th>temp_abs_maximum</th>\n",
       "      <th>temp_abs_minimum</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>temp_abs_energy</th>\n",
       "      <th>temp_mean_abs_change</th>\n",
       "      <th>temp_cid_ce</th>\n",
       "      <th>target</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.447531</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.447531</td>\n",
       "      <td>0.469939</td>\n",
       "      <td>0.384935</td>\n",
       "      <td>0.052254</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.944060</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.944060</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.937919</td>\n",
       "      <td>0.930941</td>\n",
       "      <td>0.160912</td>\n",
       "      <td>0.019084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.447658</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.447658</td>\n",
       "      <td>0.471027</td>\n",
       "      <td>0.385993</td>\n",
       "      <td>0.053366</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.944060</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.944060</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.937961</td>\n",
       "      <td>0.930987</td>\n",
       "      <td>0.160423</td>\n",
       "      <td>0.018968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.447722</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.447722</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>0.387034</td>\n",
       "      <td>0.054231</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.937979</td>\n",
       "      <td>0.931007</td>\n",
       "      <td>0.160134</td>\n",
       "      <td>0.018899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.448104</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.448104</td>\n",
       "      <td>0.473156</td>\n",
       "      <td>0.388064</td>\n",
       "      <td>0.054478</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.938063</td>\n",
       "      <td>0.931100</td>\n",
       "      <td>0.159399</td>\n",
       "      <td>0.018748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.449060</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.449060</td>\n",
       "      <td>0.474201</td>\n",
       "      <td>0.389080</td>\n",
       "      <td>0.054046</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.948555</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.948555</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.938160</td>\n",
       "      <td>0.931207</td>\n",
       "      <td>0.159405</td>\n",
       "      <td>0.018749</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hr_maximum  hr_minimum  hr_abs_maximum  hr_abs_minimum   hr_mean  \\\n",
       "0     0.44192    0.447531         0.44192        0.447531  0.469939   \n",
       "1     0.44192    0.447658         0.44192        0.447658  0.471027   \n",
       "2     0.44192    0.447722         0.44192        0.447722  0.472097   \n",
       "3     0.44192    0.448104         0.44192        0.448104  0.473156   \n",
       "4     0.44192    0.449060         0.44192        0.449060  0.474201   \n",
       "\n",
       "   hr_abs_energy  hr_mean_abs_change  hr_cid_ce  temp_maximum  temp_minimum  \\\n",
       "0       0.384935            0.052254   0.000717      0.944060      0.928227   \n",
       "1       0.385993            0.053366   0.000725      0.944060      0.928227   \n",
       "2       0.387034            0.054231   0.000729      0.944667      0.928227   \n",
       "3       0.388064            0.054478   0.000730      0.944667      0.928227   \n",
       "4       0.389080            0.054046   0.000727      0.948555      0.928227   \n",
       "\n",
       "   temp_abs_maximum  temp_abs_minimum  temp_mean  temp_abs_energy  \\\n",
       "0          0.944060          0.928227   0.937919         0.930941   \n",
       "1          0.944060          0.928227   0.937961         0.930987   \n",
       "2          0.944667          0.928227   0.937979         0.931007   \n",
       "3          0.944667          0.928227   0.938063         0.931100   \n",
       "4          0.948555          0.928227   0.938160         0.931207   \n",
       "\n",
       "   temp_mean_abs_change  temp_cid_ce  target  ID  \n",
       "0              0.160912     0.019084     0.0   0  \n",
       "1              0.160423     0.018968     0.0   0  \n",
       "2              0.160134     0.018899     0.0   0  \n",
       "3              0.159399     0.018748     0.0   0  \n",
       "4              0.159405     0.018749     0.0   0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df.drop('target_name', inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04ca0fb6-73db-47ec-9363-345d3fcad8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target'], axis=1, inplace=False)\n",
    "y = df.target\n",
    "group = df.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a157671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18765\n",
      "11176\n"
     ]
    }
   ],
   "source": [
    "false = (y == 0).sum()\n",
    "true = (y == 1).sum()\n",
    "\n",
    "print(false)\n",
    "print(true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20aae746",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb1e1615",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d2c06d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 369\n",
      "max_resources_: 29941\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 180\n",
      "n_resources: 369\n",
      "Fitting 15 folds for each of 180 candidates, totalling 2700 fits\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.183, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.178, test=0.288) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.178, test=0.288) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.180, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.645, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.565, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.661, test=0.309) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.702, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.606, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.664, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.532, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.673, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.699, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.757, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.688, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.587, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.475, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.381, test=0.778) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.736, test=0.576) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.461, test=0.786) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.409, test=0.288) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.632, test=0.782) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.713, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.329, test=0.384) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.408, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.716, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.725, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.763, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.326, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.645, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.565, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.661, test=0.309) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.699, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.606, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.664, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.532, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.673, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.696, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.757, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.688, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.587, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.645, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.565, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.661, test=0.309) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.699, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.606, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.664, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.532, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.673, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.696, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.757, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.688, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.587, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.645, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.565, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.661, test=0.309) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.702, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.606, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.664, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.532, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.673, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.696, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.757, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.688, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.587, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.645, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.565, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.661, test=0.309) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.699, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.563, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.606, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.664, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.532, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.673, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.696, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.757, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.688, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.587, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.183, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.178, test=0.288) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.178, test=0.288) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.180, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.727, test=0.906) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.605, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.695, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.733, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.603, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.577, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.658, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.716, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.579, test=0.920) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.716, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.742, test=0.635) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.777, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.696, test=0.674) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.613, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.599, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.572, test=0.778) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.729, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.733, test=0.576) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.569, test=0.746) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.564, test=0.288) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.669, test=0.774) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.725, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.458, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.702, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.571, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.707, test=0.635) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.777, test=0.733) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.459, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.727, test=0.906) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.605, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.695, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.733, test=0.576) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.603, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.577, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.658, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.710, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.579, test=0.920) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.716, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.742, test=0.635) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.777, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.696, test=0.674) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.613, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.727, test=0.906) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.605, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.695, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.733, test=0.576) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.603, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.577, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.658, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.710, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.579, test=0.920) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.716, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.742, test=0.635) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.777, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.696, test=0.674) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.613, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.727, test=0.906) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.605, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.695, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.733, test=0.576) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.603, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.574, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.658, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.710, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.579, test=0.920) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.716, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.742, test=0.635) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.777, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.696, test=0.674) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.613, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.727, test=0.906) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.605, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.695, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.733, test=0.576) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.603, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.574, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.658, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.710, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.579, test=0.920) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.719, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.618, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.742, test=0.635) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.779, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.696, test=0.674) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.613, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.183, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.180, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.756, test=0.568) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.613, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.778, test=0.575) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.750, test=0.661) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.611, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.609, test=0.543) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.689, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.762, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.622, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.762, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.656, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.757, test=0.871) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.771, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.734, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.667, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.657, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.663, test=0.778) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.735, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.727, test=0.619) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.674, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.673, test=0.637) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.612) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.595, test=0.920) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.716, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.685, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.713, test=0.871) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.745, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.622, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.756, test=0.568) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.613, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.778, test=0.575) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.750, test=0.661) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.611, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.609, test=0.543) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.689, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.762, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.622, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.762, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.656, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.757, test=0.871) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.771, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.734, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.667, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.756, test=0.568) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.613, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.778, test=0.575) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.750, test=0.661) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.611, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.609, test=0.543) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.689, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.762, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.622, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.762, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.656, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.757, test=0.871) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.771, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.734, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.667, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.756, test=0.568) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.613, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.778, test=0.575) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.750, test=0.661) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.611, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.609, test=0.543) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.689, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.762, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.622, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.762, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.656, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.757, test=0.871) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.771, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.734, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.667, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.756, test=0.568) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.613, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.775, test=0.575) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.750, test=0.661) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.611, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.609, test=0.543) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.689, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.762, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.622, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.759, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.656, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.757, test=0.871) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.765, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.734, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.667, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.201, test=0.309) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.762, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.662, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.786, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.759, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.665, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.645, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.757, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.770, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.716, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.759, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.704, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.745, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.776, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.773, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.692, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.709, test=0.778) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.755, test=0.548) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.619) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.719, test=0.611) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.831) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.703, test=0.670) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.750, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.683, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.733, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.736, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.742, test=0.917) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.748, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.688, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.762, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.662, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.786, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.759, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.665, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.645, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.757, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.770, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.716, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.759, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.704, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.776, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.773, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.692, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.762, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.662, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.786, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.759, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.665, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.645, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.757, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.770, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.716, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.759, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.704, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.745, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.776, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.773, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.692, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.762, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.665, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.786, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.759, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.665, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.645, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.757, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.770, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.716, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.759, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.704, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.745, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.773, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.773, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.692, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.762, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.665, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.786, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.756, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.665, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.645, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.752, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.770, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.716, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.759, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.704, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.742, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.773, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.776, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.692, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.255, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.250, test=0.288) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.250, test=0.288) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.253, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.267, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.525, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.201, test=0.309) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.531, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.531, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.563, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.573, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.774, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.744, test=0.671) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.786, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.762, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.736, test=0.611) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.745, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.778, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.764, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.776, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.767, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.756, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.756, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.785, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.787, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.729, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.762, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.753, test=0.872) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.775, test=0.684) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.748, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.756, test=0.671) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.770, test=0.831) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.754, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.753, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.738, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.748, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.761, test=0.580) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.748, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.774, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.784, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.732, test=0.154) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.774, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.744, test=0.671) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.786, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.762, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.736, test=0.611) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.778, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.764, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.776, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.767, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.756, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.756, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.785, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.787, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.729, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.774, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.744, test=0.671) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.786, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.762, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.736, test=0.611) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.745, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.778, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.764, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.776, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.767, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.756, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.756, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.785, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.787, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.729, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.774, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.744, test=0.671) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.786, test=0.912) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.762, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.736, test=0.611) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.745, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.778, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.764, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.776, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.767, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.756, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.756, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.785, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.784, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.729, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.774, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.744, test=0.671) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.792, test=0.912) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.762, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.736, test=0.611) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.745, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.778, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.764, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.776, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.759, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.756, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.756, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.782, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.787, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.729, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.255, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.250, test=0.288) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.250, test=0.288) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.310, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.253, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.267, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.525, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.201, test=0.309) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.531, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.531, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.529, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.524, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.563, test=0.288) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.573, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.758, test=0.872) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.792, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.765, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.773, test=0.671) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.778, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.777, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.778, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.765, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.778, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.792, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.790, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.798, test=0.715) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.766, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.777, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.758, test=0.831) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.783, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.776, test=0.671) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.784, test=0.831) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.774) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.770, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.755, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.784, test=0.580) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.756, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.788, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.789, test=0.715) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.755, test=0.154) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.758, test=0.872) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.792, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.765, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.773, test=0.671) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.778, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.777, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.778, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.765, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.778, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.792, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.790, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.798, test=0.715) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.766, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.758, test=0.872) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.792, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.765, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.773, test=0.671) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.778, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.777, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.778, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.765, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.778, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.792, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.790, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.798, test=0.715) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.766, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.758, test=0.872) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.792, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.765, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.773, test=0.671) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.778, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.777, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.778, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.765, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.778, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.792, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.790, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.798, test=0.715) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.766, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.761, test=0.872) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.792, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.765, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.776, test=0.671) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.778, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.777, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.769, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.765, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.778, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.792, test=0.450) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.790, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.798, test=0.715) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.769, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.686, test=0.468) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.792, test=0.825) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.776, test=0.814) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.692, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.687, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.774) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.801, test=0.699) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.660, test=0.781) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.785, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.687, test=0.583) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.775, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.793, test=0.674) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.807, test=0.645) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.746, test=0.228) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.776, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.690, test=0.750) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.775, test=0.514) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.670, test=0.576) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.727, test=0.577) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.716, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.775, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.659, test=0.644) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.676, test=0.781) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.650, test=0.833) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.693, test=0.583) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.665, test=0.878) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.676, test=0.845) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.717, test=0.350) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.717, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.752, test=0.831) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.803, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.773, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.781, test=0.727) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.775, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.789, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.780, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.780, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.775, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.786, test=0.580) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.790, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.807, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.768, test=0.154) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.788, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.755, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.798, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.773, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.727) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.792, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.772, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.763, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.773, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.580) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.761, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.782, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.789, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.775, test=0.228) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.752, test=0.831) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.803, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.773, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.781, test=0.727) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.775, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.789, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.780, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.780, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.775, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.786, test=0.580) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.790, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.807, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.768, test=0.154) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.752, test=0.831) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.803, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.773, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.781, test=0.727) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.775, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.789, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.780, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.780, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.775, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.786, test=0.580) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.790, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.807, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.768, test=0.154) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.752, test=0.831) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.803, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.773, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.781, test=0.727) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.775, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.789, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.780, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.780, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.775, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.786, test=0.580) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.790, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.807, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.768, test=0.154) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.785, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.752, test=0.831) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.803, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.773, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.781, test=0.727) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.775, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.789, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.780, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.777, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.775, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.786, test=0.580) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.787, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.804, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.768, test=0.154) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.782, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.778, test=0.872) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.829, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.825, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.789, test=0.671) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.812, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.829, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.807, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.794, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.804, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.601) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.796, test=0.920) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.807, test=0.706) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.814, test=0.715) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.800, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.796, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.769, test=0.750) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.803, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.779, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.789, test=0.689) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.790, test=0.831) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.800, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.809, test=0.840) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.794, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.792, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.767, test=0.578) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.784, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.804, test=0.706) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.788, test=0.570) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.783, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.791, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.763, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.814, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.767, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.781, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.781, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.800, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.786, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.774, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.787, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.784, test=0.637) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.785, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.813, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.785, test=0.228) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.791, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.763, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.800, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.773, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.775, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.800, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.786, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.777, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.637) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.764, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.785, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.795, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.783, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.791, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.763, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.814, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.767, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.781, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.781, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.800, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.786, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.774, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.787, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.784, test=0.637) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.769, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.785, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.813, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.785, test=0.228) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.791, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.763, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.814, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.767, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.781, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.781, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.800, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.786, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.774, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.787, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.784, test=0.637) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.769, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.785, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.813, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.785, test=0.228) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.791, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.763, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.814, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.767, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.781, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.781, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.800, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.786, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.774, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.787, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.784, test=0.637) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.769, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.785, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.813, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.782, test=0.228) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.791, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.763, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.812, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.767, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.781, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.781, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.800, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.786, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.774, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.787, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.784, test=0.637) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.767, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.787, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.813, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.782, test=0.228) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.854, test=0.568) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.834, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.880, test=0.956) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.833, test=0.740) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.852, test=0.872) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.851, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.888, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.856, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.835, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.853, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.823, test=0.831) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.831, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.842, test=0.706) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.856, test=0.884) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.873, test=0.359) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.796, test=0.440) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.795, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.820, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.805, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.818, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.812, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.805, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.804, test=0.840) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.788, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.801, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.784, test=0.739) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.795, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.804, test=0.635) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.813, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.805, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.805, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.788, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.817, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.781, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.798, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.792, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.808, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.798, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.783, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.792, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.789, test=0.690) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.781, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.801, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.818, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.797, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.794, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.817, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.787, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.798, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.792, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.805, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.795, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.789, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.795, test=0.690) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.801, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.809, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.797, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.805, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.788, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.817, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.781, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.798, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.792, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.808, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.798, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.783, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.792, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.789, test=0.690) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.781, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.801, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.821, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.797, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.805, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.788, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.817, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.781, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.798, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.792, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.808, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.798, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.783, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.792, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.789, test=0.690) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.781, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.801, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.821, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.797, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.805, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.788, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.817, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.781, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.798, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.789, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.808, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.798, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.783, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.792, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.789, test=0.690) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.781, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.801, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.818, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.797, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.802, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.780, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.817, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.779, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.798, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.792, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.808, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.798, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.783, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.786, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.789, test=0.690) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.781, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.799, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.815, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.797, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.900, test=0.866) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.874, test=0.915) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.917, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.882, test=0.740) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.880, test=0.874) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.880, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.908, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.908, test=0.922) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.902, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.908, test=0.961) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.866, test=0.874) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.894, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.905, test=0.706) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.899, test=0.884) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.910, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.799, test=0.440) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.791, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.826, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.805, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.823, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.812, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.811, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.798, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.794, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.792, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.795, test=0.739) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.790, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.810, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.827, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.819, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.808, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.806, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.828, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.802, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.823, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.809, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.811, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.803, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.800, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.801, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.800, test=0.739) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.792, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.810, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.830, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.808, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.808, test=0.440) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.806, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.823, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.802, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.820, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.803, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.811, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.803, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.800, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.798, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.800, test=0.739) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.792, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.813, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.824, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.816, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.808, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.806, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.828, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.802, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.823, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.809, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.811, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.803, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.800, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.801, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.800, test=0.739) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.792, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.810, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.830, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.808, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.808, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.806, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.828, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.802, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.823, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.809, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.811, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.803, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.800, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.801, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.800, test=0.739) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.792, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.810, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.830, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.808, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.805, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.797, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.828, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.796, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.820, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.803, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.808, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.803, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.800, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.798, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.797, test=0.739) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.792, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.807, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.830, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.808, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.802, test=0.440) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.788, test=0.833) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.823, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.790, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.812, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.792, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.808, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.800, test=0.840) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.783, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.792, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.795, test=0.739) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.784, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.804, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.818, test=0.766) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.805, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 60\n",
      "n_resources: 1107\n",
      "Fitting 15 folds for each of 60 candidates, totalling 900 fits\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.741, test=0.334) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.777, test=0.728) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.749, test=0.433) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.732, test=0.973) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.750, test=0.728) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.745, test=0.892) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.778, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.758, test=0.817) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.741, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.746, test=0.870) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.764, test=0.296) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.776, test=0.430) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.769, test=0.630) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.757, test=0.697) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.689, test=0.208) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.741, test=0.334) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.777, test=0.728) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.749, test=0.433) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.732, test=0.973) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.749, test=0.728) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.745, test=0.892) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.778, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.758, test=0.817) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.741, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.746, test=0.870) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.764, test=0.296) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.775, test=0.430) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.769, test=0.630) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.757, test=0.697) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.689, test=0.208) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.741, test=0.334) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.777, test=0.728) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.749, test=0.433) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.732, test=0.973) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.749, test=0.728) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.892) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.778, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.758, test=0.817) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.741, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.746, test=0.870) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.764, test=0.296) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.775, test=0.430) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.769, test=0.630) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.757, test=0.697) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.689, test=0.208) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.710, test=0.279) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.799) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.695, test=0.679) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.711, test=0.726) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.741, test=0.972) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.706, test=0.434) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.704, test=0.550) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.713, test=0.804) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.687, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.669, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.694, test=0.413) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.693, test=0.587) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.685, test=0.610) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.697) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.656, test=0.236) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.782, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.789, test=0.871) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.802, test=0.728) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.801, test=0.853) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.783, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.772, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.794, test=0.803) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.748, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.762, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.796, test=0.391) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.778, test=0.713) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.788, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.796, test=0.856) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.758, test=0.208) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.782, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.789, test=0.871) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.802, test=0.728) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.801, test=0.853) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.783, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.772, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.794, test=0.803) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.748, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.762, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.796, test=0.391) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.778, test=0.713) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.788, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.796, test=0.856) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.758, test=0.208) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.782, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.790, test=0.871) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.803, test=0.728) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.801, test=0.853) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.783, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.772, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.794, test=0.803) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.748, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.762, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.796, test=0.391) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.778, test=0.713) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.788, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.796, test=0.856) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.758, test=0.208) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.782, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.790, test=0.871) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.802, test=0.728) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.801, test=0.853) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.783, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.772, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.794, test=0.803) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.748, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.762, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.796, test=0.391) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.778, test=0.713) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.787, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.796, test=0.856) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.758, test=0.208) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.782, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.789, test=0.871) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.802, test=0.728) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.801, test=0.853) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.783, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.772, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.794, test=0.803) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.748, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.762, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.796, test=0.391) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.778, test=0.713) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.788, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.796, test=0.856) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.758, test=0.208) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.820, test=0.518) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.818, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.826, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.820, test=0.794) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.827, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.812, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.826, test=0.887) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.826, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.821, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.816, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.797, test=0.742) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.801, test=0.892) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.822, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.833, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.824, test=0.364) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.753, test=0.825) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.734, test=0.816) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.753, test=0.767) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.776, test=0.958) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.757, test=0.513) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.659) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.803) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.731, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.740, test=0.513) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.741, test=0.855) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.745, test=0.574) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.758, test=0.817) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.764, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.767, test=0.825) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.764, test=0.872) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.765, test=0.780) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.785, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.772, test=0.602) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.768, test=0.770) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.776, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.765, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.757, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.585) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.761, test=0.868) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.779, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.787, test=0.772) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.752, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.829, test=0.558) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.823, test=0.864) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.845, test=0.914) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.839, test=0.794) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.834, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.822, test=0.866) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.846, test=0.887) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.846, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.842, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.841, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.800, test=0.799) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.830, test=0.906) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.842, test=0.673) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.843, test=0.787) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.852, test=0.364) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.783, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.777, test=0.847) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.795, test=0.817) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.778, test=0.832) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.807, test=0.915) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.786, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.775, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.790, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.773, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.773, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.790, test=0.434) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.775, test=0.855) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.798, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.794, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.784, test=0.236) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.783, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.777, test=0.847) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.795, test=0.817) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.778, test=0.832) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.806, test=0.915) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.786, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.775, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.791, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.773, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.774, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.790, test=0.434) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.775, test=0.855) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.797, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.794, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.784, test=0.236) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.783, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.777, test=0.847) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.795, test=0.817) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.778, test=0.832) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.806, test=0.915) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.786, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.775, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.791, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.773, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.774, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.790, test=0.434) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.775, test=0.855) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.797, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.794, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.784, test=0.236) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.783, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.777, test=0.847) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.795, test=0.817) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.778, test=0.832) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.806, test=0.915) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.786, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.775, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.791, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.773, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.774, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.790, test=0.434) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.775, test=0.855) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.797, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.794, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.784, test=0.236) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.783, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.778, test=0.847) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.795, test=0.817) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.778, test=0.832) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.807, test=0.915) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.786, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.775, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.791, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.773, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.774, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.790, test=0.434) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.775, test=0.855) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.800, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.793, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.784, test=0.236) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.776, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.775, test=0.851) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.776, test=0.855) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.769, test=0.781) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.789, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.781, test=0.651) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.775, test=0.815) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.792, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.774, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.767, test=0.619) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.906) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.794, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.796, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.762, test=0.316) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.783, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.780, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.788, test=0.866) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.774, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.798, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.786, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.779, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.791, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.786, test=0.494) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.790, test=0.906) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.807, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.795, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.788, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.783, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.780, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.788, test=0.866) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.774, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.798, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.786, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.779, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.791, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.786, test=0.494) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.790, test=0.906) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.807, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.795, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.788, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.783, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.780, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.788, test=0.866) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.774, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.798, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.786, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.779, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.791, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.786, test=0.494) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.790, test=0.906) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.807, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.795, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.788, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.784, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.780, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.787, test=0.866) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.774, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.798, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.786, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.779, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.791, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.786, test=0.494) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.790, test=0.906) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.807, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.795, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.788, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.783, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.780, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.788, test=0.866) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.774, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.798, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.786, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.779, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.791, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.780, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.786, test=0.494) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.790, test=0.906) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.807, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.795, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.788, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.785, test=0.432) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.837) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.786, test=0.883) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.779, test=0.781) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.799, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.787, test=0.727) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.786, test=0.844) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.799, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.775, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.776, test=0.651) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.783, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.806, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.801, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.776, test=0.316) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.795, test=0.432) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.786, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.792, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.778, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.802, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.795, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.787, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.799, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.781, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.788, test=0.513) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.789, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.808, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.799, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.794, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.795, test=0.432) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.786, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.792, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.778, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.802, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.795, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.787, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.799, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.781, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.788, test=0.513) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.789, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.808, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.799, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.795, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.796, test=0.432) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.786, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.793, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.778, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.803, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.795, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.787, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.799, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.781, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.788, test=0.513) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.789, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.808, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.799, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.795, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.796, test=0.432) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.786, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.793, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.778, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.802, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.795, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.787, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.798, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.781, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.788, test=0.513) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.789, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.808, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.799, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.795, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.795, test=0.432) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.786, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.792, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.778, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.802, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.795, test=0.770) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.787, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.799, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.777, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.781, test=0.896) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.788, test=0.513) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.789, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.808, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.799, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.795, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.827, test=0.596) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.828, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.839, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.826, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.833, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.820, test=0.866) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.840, test=0.887) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.833, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.834, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.824, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.810, test=0.771) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.818, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.825, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.845, test=0.787) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.844, test=0.364) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.803, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.792, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.799, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.785, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.805, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.798, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.801, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.809, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.789, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.789, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.792, test=0.619) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.791, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.809, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.801, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.798, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.803, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.792, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.799, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.785, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.805, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.798, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.801, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.809, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.789, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.789, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.792, test=0.619) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.791, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.809, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.801, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.798, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.803, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.792, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.799, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.785, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.805, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.798, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.801, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.809, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.789, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.789, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.792, test=0.619) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.791, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.809, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.801, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.798, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.803, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.792, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.799, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.785, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.805, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.798, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.801, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.809, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.789, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.789, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.792, test=0.619) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.791, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.809, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.801, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.798, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.803, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.792, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.799, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.785, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.805, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.798, test=0.798) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.801, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.809, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.789, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.789, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.792, test=0.619) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.791, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.809, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.801, test=0.770) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.798, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.800, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.791, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.798, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.788, test=0.794) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.806, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.795, test=0.784) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.797, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.810, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.792, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.790, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.785, test=0.667) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.792, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.811, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.808, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.802, test=0.340) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.817, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.807, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.816, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.803, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.813, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.808, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.810, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.816, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.804, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.808, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.795, test=0.651) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.797, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.816, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.818, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.806, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.817, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.807, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.816, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.803, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.813, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.808, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.810, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.816, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.804, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.808, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.795, test=0.651) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.797, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.816, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.818, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.806, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.817, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.807, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.816, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.803, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.813, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.808, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.810, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.816, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.804, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.808, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.795, test=0.651) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.797, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.816, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.818, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.806, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.817, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.807, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.816, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.803, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.813, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.808, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.810, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.816, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.804, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.808, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.795, test=0.651) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.797, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.816, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.818, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.806, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.817, test=0.476) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.807, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.816, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.803, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.813, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.808, test=0.839) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.809, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.816, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.804, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.808, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.795, test=0.651) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.797, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.816, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.817, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.806, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.824, test=0.614) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.819, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.828, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.818, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.825, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.815, test=0.866) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.825, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.830, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.814, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.816, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.809, test=0.742) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.812, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.826, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.835, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.822, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.824, test=0.614) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.819, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.828, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.818, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.825, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.815, test=0.866) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.825, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.830, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.814, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.816, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.809, test=0.742) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.812, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.826, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.835, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.822, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.824, test=0.614) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.819, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.828, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.818, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.825, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.815, test=0.866) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.825, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.830, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.814, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.816, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.809, test=0.742) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.812, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.826, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.835, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.822, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.824, test=0.614) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.819, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.828, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.818, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.825, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.815, test=0.866) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.825, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.830, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.814, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.816, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.809, test=0.742) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.812, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.826, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.835, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.822, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.814, test=0.498) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.805, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.817, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.804, test=0.794) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.815, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.807, test=0.825) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.812, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.814, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.803, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.807, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.796, test=0.697) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.804, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.821, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.817, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.810, test=0.340) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.866, test=0.700) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.863, test=0.878) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.883, test=0.928) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.869, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.865, test=0.972) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.865, test=0.932) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.878, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.879, test=0.830) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.884, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.883, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.847, test=0.852) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.877, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.886, test=0.673) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.894, test=0.841) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.879, test=0.473) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.821, test=0.577) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.818, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.827, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.814, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.825, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.814, test=0.852) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.822, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.830, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.814, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.815, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.809, test=0.727) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.810, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.827, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.829, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.820, test=0.264) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.825, test=0.614) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.821, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.824, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.816, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.825, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.817, test=0.866) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.825, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.829, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.814, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.816, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.806, test=0.770) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.814, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.828, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.835, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.828, test=0.340) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.846, test=0.667) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.835, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.841, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.839, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.840, test=0.931) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.826, test=0.906) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.842, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.854, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.843, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.838, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.822, test=0.798) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.831, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.840, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.856, test=0.801) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.847, test=0.340) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.846, test=0.667) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.835, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.841, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.839, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.840, test=0.931) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.826, test=0.906) total time=   0.1s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.842, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.854, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.844, test=0.907) total time=   0.1s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.838, test=0.909) total time=   0.1s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.822, test=0.798) total time=   0.1s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.831, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.840, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.856, test=0.801) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.847, test=0.340) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.846, test=0.667) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.835, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.841, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.839, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.840, test=0.931) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.826, test=0.906) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.842, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.854, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.843, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.838, test=0.909) total time=   0.1s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.822, test=0.798) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.831, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.840, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.856, test=0.801) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.847, test=0.340) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.843, test=0.650) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.833, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.839, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.837, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.839, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.825, test=0.879) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.841, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.849, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.837, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.836, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.820, test=0.798) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.828, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.838, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.854, test=0.787) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.847, test=0.340) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.833, test=0.614) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.833, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.836, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.822, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.834, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.821, test=0.866) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.833, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.837, test=0.802) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.825, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.827, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.815, test=0.798) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.818, test=0.945) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.834, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.843, test=0.772) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.843, test=0.316) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.846, test=0.667) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.836, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.840, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.838, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.840, test=0.931) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.826, test=0.906) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.842, test=0.872) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.854, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.843, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.838, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.823, test=0.798) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.835, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.840, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.856, test=0.801) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.849, test=0.364) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.848, test=0.650) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.835, test=0.810) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.840, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.842, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.842, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.829, test=0.906) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.842, test=0.887) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.851, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.849, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.837, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.824, test=0.798) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.833, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.839, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.859, test=0.787) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.852, test=0.364) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.836, test=0.632) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.835, test=0.836) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.838, test=0.897) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.831, test=0.807) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.838, test=0.944) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.824, test=0.866) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.842, test=0.887) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.842, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.844, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.832, test=0.909) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.816, test=0.798) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.825, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.835, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.854, test=0.787) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.845, test=0.364) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.910, test=0.854) total time=   0.1s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.900, test=0.892) total time=   0.1s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.926, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.908, test=0.884) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.905, test=0.919) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.905, test=0.932) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.917, test=0.872) total time=   0.1s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.918, test=0.883) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.914, test=0.934) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.919, test=0.934) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.898, test=0.906) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.914, test=0.945) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.915, test=0.773) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.913, test=0.922) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.916, test=0.757) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.931, test=0.883) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.924, test=0.879) total time=   0.1s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.947, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.928, test=0.961) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.933, test=0.919) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.935, test=0.959) total time=   0.1s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.935, test=0.887) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.934, test=0.947) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.940, test=0.974) total time=   0.1s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.939, test=0.934) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.916, test=0.933) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.937, test=0.973) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.944, test=0.773) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.936, test=0.934) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.944, test=0.840) total time=   0.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 20\n",
      "n_resources: 3321\n",
      "Fitting 15 folds for each of 20 candidates, totalling 300 fits\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.848, test=0.730) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.850, test=0.826) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.848, test=0.924) total time=   0.1s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.855, test=0.824) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.853, test=0.922) total time=   0.1s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.843, test=0.910) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.852, test=0.870) total time=   0.1s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.851, test=0.799) total time=   0.1s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.839, test=0.925) total time=   0.1s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.846, test=0.926) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.838, test=0.779) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.845, test=0.937) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.854, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.859, test=0.793) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.856, test=0.317) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.857, test=0.710) total time=   0.1s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.862, test=0.868) total time=   0.1s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.865, test=0.901) total time=   0.1s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.868, test=0.828) total time=   0.1s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.866, test=0.972) total time=   0.1s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.862, test=0.901) total time=   0.1s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.862, test=0.884) total time=   0.1s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.865, test=0.812) total time=   0.2s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.847, test=0.925) total time=   0.1s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.862, test=0.926) total time=   0.1s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.853, test=0.793) total time=   0.1s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.860, test=0.923) total time=   0.1s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.860, test=0.496) total time=   0.1s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.874, test=0.807) total time=   0.1s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.867, test=0.348) total time=   0.1s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.849, test=0.736) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.851, test=0.826) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.849, test=0.924) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.856, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.854, test=0.917) total time=   0.1s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.844, test=0.910) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.853, test=0.870) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.853, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.842, test=0.930) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.847, test=0.930) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.839, test=0.784) total time=   0.1s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.848, test=0.937) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.855, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.860, test=0.793) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.856, test=0.325) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.849, test=0.736) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.851, test=0.826) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.849, test=0.924) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.857, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.854, test=0.917) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.844, test=0.910) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.853, test=0.870) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.853, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.842, test=0.930) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.847, test=0.930) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.840, test=0.784) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.848, test=0.937) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.855, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.860, test=0.793) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.856, test=0.325) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.849, test=0.736) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.852, test=0.826) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.849, test=0.924) total time=   0.1s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.857, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.854, test=0.917) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.844, test=0.910) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.853, test=0.870) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.853, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.842, test=0.930) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.847, test=0.930) total time=   0.1s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.840, test=0.784) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.848, test=0.937) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.855, test=0.496) total time=   0.1s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.860, test=0.793) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.856, test=0.325) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.849, test=0.736) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.851, test=0.826) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.849, test=0.924) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.857, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.854, test=0.917) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.844, test=0.910) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.853, test=0.870) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.853, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.842, test=0.930) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.847, test=0.930) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.840, test=0.784) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.848, test=0.937) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.855, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.860, test=0.793) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.856, test=0.325) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.849, test=0.736) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.852, test=0.826) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.848, test=0.915) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.857, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.855, test=0.917) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.844, test=0.910) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.853, test=0.870) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.853, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.843, test=0.930) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.848, test=0.930) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.841, test=0.788) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.848, test=0.937) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.857, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.861, test=0.793) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.857, test=0.325) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.860, test=0.761) total time=   0.1s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.860, test=0.831) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.859, test=0.925) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.864, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.863, test=0.922) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.858, test=0.924) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.861, test=0.879) total time=   0.1s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.867, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.852, test=0.934) total time=   0.1s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.858, test=0.930) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.849, test=0.811) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.862, test=0.937) total time=   0.1s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.863, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.870, test=0.798) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.868, test=0.348) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.869, test=0.782) total time=   0.1s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.871, test=0.873) total time=   0.1s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.874, test=0.911) total time=   0.1s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.877, test=0.828) total time=   0.1s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.874, test=0.964) total time=   0.1s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.871, test=0.914) total time=   0.1s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.871, test=0.889) total time=   0.1s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.875, test=0.817) total time=   0.1s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.863, test=0.934) total time=   0.1s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.873, test=0.926) total time=   0.1s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.858, test=0.825) total time=   0.1s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.872, test=0.928) total time=   0.1s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.876, test=0.496) total time=   0.1s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.887, test=0.821) total time=   0.1s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.879, test=0.378) total time=   0.1s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.864, test=0.796) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.866, test=0.841) total time=   0.1s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.870, test=0.925) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.870, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.869, test=0.927) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.865, test=0.924) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.868, test=0.884) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.869, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.857, test=0.934) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.868, test=0.930) total time=   0.1s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.856, test=0.825) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.869, test=0.937) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.871, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.879, test=0.816) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.872, test=0.348) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.874, test=0.806) total time=   0.1s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.875, test=0.855) total time=   0.1s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.876, test=0.915) total time=   0.1s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.880, test=0.828) total time=   0.1s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.880, test=0.941) total time=   0.1s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.873, test=0.919) total time=   0.1s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.873, test=0.889) total time=   0.1s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.881, test=0.812) total time=   0.1s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.870, test=0.934) total time=   0.1s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.877, test=0.930) total time=   0.1s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.861, test=0.848) total time=   0.1s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.878, test=0.932) total time=   0.1s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.880, test=0.496) total time=   0.1s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.893, test=0.829) total time=   0.1s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.884, test=0.378) total time=   0.1s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.865, test=0.796) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.868, test=0.846) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.872, test=0.925) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.871, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.870, test=0.927) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.866, test=0.924) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.869, test=0.884) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.869, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.858, test=0.934) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.869, test=0.930) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.856, test=0.839) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.869, test=0.937) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.873, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.881, test=0.816) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.873, test=0.348) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.865, test=0.796) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.868, test=0.846) total time=   0.1s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.872, test=0.925) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.871, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.870, test=0.927) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.866, test=0.924) total time=   0.1s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.869, test=0.884) total time=   0.1s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.869, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.858, test=0.934) total time=   0.1s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.869, test=0.930) total time=   0.1s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.856, test=0.839) total time=   0.1s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.869, test=0.937) total time=   0.1s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.873, test=0.496) total time=   0.1s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.881, test=0.816) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.873, test=0.348) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.865, test=0.796) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.868, test=0.846) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.872, test=0.925) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.871, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.870, test=0.927) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.866, test=0.924) total time=   0.1s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.869, test=0.884) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.869, test=0.799) total time=   0.1s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.858, test=0.934) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.869, test=0.930) total time=   0.1s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.856, test=0.839) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.869, test=0.937) total time=   0.1s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.873, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.881, test=0.816) total time=   0.1s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.873, test=0.348) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.875, test=0.821) total time=   0.1s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.879, test=0.860) total time=   0.1s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.881, test=0.920) total time=   0.1s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.882, test=0.828) total time=   0.1s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.881, test=0.941) total time=   0.1s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.875, test=0.924) total time=   0.1s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.875, test=0.898) total time=   0.1s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.882, test=0.816) total time=   0.1s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.873, test=0.934) total time=   0.1s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.880, test=0.935) total time=   0.1s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.863, test=0.852) total time=   0.1s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.880, test=0.937) total time=   0.1s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.883, test=0.496) total time=   0.1s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.896, test=0.825) total time=   0.1s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.887, test=0.386) total time=   0.1s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.865, test=0.796) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.868, test=0.846) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.872, test=0.925) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.871, test=0.828) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.870, test=0.927) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.866, test=0.924) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.869, test=0.884) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.869, test=0.799) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.858, test=0.934) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.869, test=0.930) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.856, test=0.839) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.870, test=0.937) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.873, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.880, test=0.816) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.873, test=0.348) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.878, test=0.787) total time=   0.2s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.889, test=0.896) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.889, test=0.911) total time=   0.1s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.887, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.897, test=0.973) total time=   0.1s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.894, test=0.919) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.888, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.893, test=0.821) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.877, test=0.943) total time=   0.1s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.894, test=0.926) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.876, test=0.848) total time=   0.2s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.892, test=0.932) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.891, test=0.637) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.899, test=0.855) total time=   0.1s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.894, test=0.561) total time=   0.1s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.914, test=0.874) total time=   0.3s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.918, test=0.905) total time=   0.1s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.922, test=0.953) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.913, test=0.897) total time=   0.1s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.923, test=0.932) total time=   0.4s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.920, test=0.932) total time=   0.4s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.917, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.917, test=0.874) total time=   0.3s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.914, test=0.970) total time=   0.3s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.922, test=0.935) total time=   0.4s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.909, test=0.906) total time=   0.1s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.916, test=0.937) total time=   0.1s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.917, test=0.701) total time=   0.1s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.916, test=0.913) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.920, test=0.709) total time=   0.5s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.936, test=0.942) total time=   0.1s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.941, test=0.932) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.941, test=0.962) total time=   0.5s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.927, test=0.931) total time=   0.7s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.947, test=0.928) total time=   0.2s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.938, test=0.950) total time=   0.1s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.936, test=0.902) total time=   0.6s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.934, test=0.913) total time=   0.5s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.940, test=0.996) total time=   0.5s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.941, test=0.939) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.931, test=0.919) total time=   0.3s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.938, test=0.946) total time=   0.5s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.938, test=0.747) total time=   0.2s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.935, test=0.913) total time=   0.3s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.942, test=0.779) total time=   0.3s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.953, test=0.961) total time=   0.6s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.954, test=0.982) total time=   0.3s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.957, test=0.972) total time=   0.7s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.936, test=0.905) total time=   0.7s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.968, test=0.914) total time=   0.1s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.955, test=0.955) total time=   0.7s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.957, test=0.912) total time=   0.5s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.946, test=0.913) total time=   2.5s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.954, test=1.000) total time=   0.8s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.954, test=0.961) total time=   1.5s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.943, test=0.928) total time=   0.8s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.950, test=0.955) total time=   0.5s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.954, test=0.783) total time=   0.8s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.949, test=0.891) total time=   3.7s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.951, test=0.788) total time=   1.4s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 7\n",
      "n_resources: 9963\n",
      "Fitting 15 folds for each of 7 candidates, totalling 105 fits\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.897, test=0.934) total time=   0.5s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.909, test=0.907) total time=   0.5s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.910, test=0.911) total time=   0.5s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.911, test=0.887) total time=   0.5s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.907, test=0.938) total time=   0.5s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.905, test=0.928) total time=   0.5s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.911, test=0.915) total time=   0.5s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.912, test=0.857) total time=   0.5s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.906, test=0.948) total time=   0.4s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.910, test=0.934) total time=   0.5s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.903, test=0.906) total time=   0.5s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.907, test=0.913) total time=   0.5s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.908, test=0.547) total time=   0.5s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.912, test=0.886) total time=   0.6s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.916, test=0.695) total time=   0.6s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.901, test=0.942) total time=   0.6s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.909, test=0.913) total time=   0.5s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.912, test=0.911) total time=   0.5s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.913, test=0.880) total time=   0.5s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.908, test=0.938) total time=   0.5s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.907, test=0.931) total time=   0.5s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.913, test=0.916) total time=   0.5s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.915, test=0.861) total time=   0.5s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.909, test=0.946) total time=   0.5s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.911, test=0.934) total time=   0.4s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.907, test=0.910) total time=   0.5s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.909, test=0.916) total time=   0.5s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.910, test=0.561) total time=   0.5s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.913, test=0.888) total time=   0.5s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.920, test=0.703) total time=   0.4s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.902, test=0.948) total time=   0.6s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.909, test=0.916) total time=   0.5s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.912, test=0.913) total time=   0.5s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.913, test=0.880) total time=   0.5s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.908, test=0.938) total time=   0.5s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.908, test=0.933) total time=   0.5s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.913, test=0.918) total time=   0.5s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.915, test=0.864) total time=   0.5s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.909, test=0.942) total time=   0.5s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.912, test=0.936) total time=   0.5s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.908, test=0.910) total time=   0.5s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.909, test=0.917) total time=   0.5s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.911, test=0.575) total time=   0.5s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.914, test=0.892) total time=   0.5s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.920, test=0.705) total time=   0.5s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.926, test=0.951) total time=   1.9s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.932, test=0.917) total time=   0.8s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.931, test=0.927) total time=   4.6s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.924, test=0.935) total time=   1.8s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.935, test=0.928) total time=   2.3s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.927, test=0.944) total time=   1.6s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.933, test=0.915) total time=   3.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.927, test=0.891) total time=   1.5s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.926, test=0.977) total time=   1.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.935, test=0.927) total time=   1.9s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.924, test=0.919) total time=   0.3s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.926, test=0.925) total time=   1.7s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.929, test=0.694) total time=   1.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.929, test=0.927) total time=   0.5s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.933, test=0.738) total time=   1.1s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.940, test=0.975) total time=   1.1s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.949, test=0.944) total time=   0.4s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.944, test=0.943) total time=   0.8s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.939, test=0.979) total time=   1.7s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.956, test=0.916) total time=   0.8s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.941, test=0.971) total time=   0.1s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.951, test=0.919) total time=   2.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.944, test=0.914) total time=   1.1s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.942, test=0.991) total time=   1.4s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.951, test=0.937) total time=   0.5s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.942, test=0.937) total time=   1.7s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.944, test=0.940) total time=   2.3s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.945, test=0.705) total time=   1.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.946, test=0.931) total time=   0.7s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.950, test=0.769) total time=   0.7s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.958, test=0.945) total time=  13.5s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.966, test=0.977) total time=   2.5s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.959, test=0.973) total time=   8.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.950, test=0.987) total time=  21.8s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.968, test=0.897) total time=   2.9s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.957, test=0.979) total time=  23.2s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.967, test=0.917) total time=   4.7s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.954, test=0.939) total time=  24.7s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.955, test=0.999) total time=  23.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.963, test=0.943) total time=  18.2s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.953, test=0.947) total time=   5.4s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.958, test=0.970) total time=   8.4s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.960, test=0.724) total time=   6.3s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.961, test=0.923) total time=   3.9s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.959, test=0.772) total time=  13.9s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.966, test=0.935) total time=   8.1s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.966, test=0.986) total time=  12.3s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.966, test=0.989) total time=  13.2s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.961, test=0.990) total time=  13.7s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.974, test=0.897) total time=   4.4s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.963, test=0.980) total time=  24.9s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.975, test=0.920) total time=  18.9s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.961, test=0.984) total time=  12.5s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.960, test=0.999) total time=  10.6s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.968, test=0.949) total time=  19.9s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.957, test=0.958) total time=   4.3s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.965, test=0.991) total time=   8.7s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.968, test=0.762) total time=  13.6s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.967, test=0.896) total time=   4.1s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.966, test=0.762) total time=  10.0s\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 3\n",
      "n_resources: 29889\n",
      "Fitting 15 folds for each of 3 candidates, totalling 45 fits\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.958, test=0.934) total time=  24.9s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.961, test=0.985) total time=  54.6s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.961, test=0.984) total time=  48.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.960, test=0.993) total time= 1.0min\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.974, test=0.909) total time=  14.5s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.961, test=0.984) total time=  53.7s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.971, test=0.913) total time=  28.5s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.958, test=0.951) total time=  57.1s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.962, test=0.996) total time=  16.1s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.966, test=0.950) total time= 1.0min\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.960, test=0.951) total time=  37.9s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.958, test=0.987) total time=  58.6s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.960, test=0.749) total time=  45.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.960, test=0.895) total time=  31.5s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.962, test=0.744) total time= 1.1min\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.963, test=0.932) total time=  51.1s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.965, test=0.991) total time= 1.6min\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.964, test=0.977) total time=  24.2s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.965, test=0.997) total time= 1.4min\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.978, test=0.895) total time= 1.2min\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.965, test=0.984) total time= 1.6min\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.976, test=0.908) total time= 1.1min\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.962, test=0.979) total time= 1.6min\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.965, test=0.995) total time=  26.7s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.969, test=0.955) total time= 1.3min\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.965, test=0.969) total time=  57.8s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.963, test=0.994) total time= 1.3min\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.967, test=0.808) total time=  35.8s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.966, test=0.900) total time= 1.1min\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.968, test=0.743) total time= 1.2min\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.966, test=0.966) total time= 1.6min\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.967, test=0.992) total time=  40.2s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.967, test=0.970) total time= 1.5min\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.967, test=0.999) total time= 1.2min\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.979, test=0.897) total time= 1.6min\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.968, test=0.984) total time= 1.4min\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.978, test=0.909) total time= 1.5min\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.964, test=0.995) total time= 1.4min\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.967, test=0.994) total time=  35.7s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.971, test=0.957) total time= 1.5min\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.964, test=0.965) total time=  22.9s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.964, test=0.992) total time= 1.3min\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.971, test=0.814) total time= 1.1min\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.967, test=0.893) total time=  30.2s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.971, test=0.754) total time= 1.2min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=LeaveOneGroupOut(),\n",
       "                    estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                 random_state=46),\n",
       "                    param_grid={&#x27;C&#x27;: array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                &#x27;penalty&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;),\n",
       "                                &#x27;solver&#x27;: (&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                           &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;)},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=LeaveOneGroupOut(),\n",
       "                    estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                 random_state=46),\n",
       "                    param_grid={&#x27;C&#x27;: array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                &#x27;penalty&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;),\n",
       "                                &#x27;solver&#x27;: (&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                           &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;)},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=46)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=46)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(cv=LeaveOneGroupOut(),\n",
       "                    estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                 random_state=46),\n",
       "                    param_grid={'C': array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                'penalty': ('l1', 'l2', 'elasticnet'),\n",
       "                                'solver': ('lbfgs', 'liblinear', 'newton-cg',\n",
       "                                           'newton-cholesky', 'sag', 'saga')},\n",
       "                    random_state=46, scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_logreg = {'penalty':('l1', 'l2', 'elasticnet'), \n",
    "                     'solver':('lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'),\n",
    "                     'C': np.logspace(-3, 0, 10)}\n",
    "logreg = LogisticRegression(random_state=46, class_weight = 'balanced')\n",
    "cv = LeaveOneGroupOut()\n",
    "logreg_hyperparams = HalvingGridSearchCV(logreg, parameters_logreg, cv = cv, scoring = 'f1_weighted', random_state=46, verbose=3)\n",
    "logreg_hyperparams.fit(X, y, groups = group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f27f1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "0.938767758108484\n"
     ]
    }
   ],
   "source": [
    "print(logreg_hyperparams.best_params_)\n",
    "print(logreg_hyperparams.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37518221",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = logreg_hyperparams.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1752669",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "438a2b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 1108\n",
      "max_resources_: 29941\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 48\n",
      "n_resources: 1108\n",
      "Fitting 15 folds for each of 48 candidates, totalling 720 fits\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.986, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.995, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.985, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.995, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.993, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.991, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.990, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.995, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.990, test=0.879) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.778) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.990, test=0.487) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.988, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.987, test=0.970) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.991, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.994, test=0.812) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.992, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.990, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.990, test=0.892) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.994, test=0.805) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.990, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.992, test=0.985) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.988, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.993, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.995, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.994, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.991, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.995, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.993, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.994, test=0.932) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.995, test=0.883) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.995, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.992, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.994, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.993, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.995, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.991, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.995, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.987) total time=   1.3s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.995, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.992, test=0.959) total time=   0.1s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.987) total time=   0.1s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.715) total time=   0.1s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.995, test=0.960) total time=   0.1s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.996, test=1.000) total time=   0.1s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.987, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.992, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.988, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.989, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.992, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.988, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.991, test=0.961) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.986, test=0.946) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.997, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.988, test=0.487) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.985, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.928) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.990, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.534) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.990, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.992, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.987, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.995, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.991, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.988, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.992, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.993, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.989, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.792) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.990, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.992, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.990, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.991, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.989, test=0.986) total time=   0.1s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.997, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.994, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.988, test=0.959) total time=   0.1s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.754) total time=   0.1s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.994, test=0.681) total time=   0.1s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.992, test=1.000) total time=   0.1s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.985, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.985, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.987, test=0.958) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.984, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.984, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.990, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.984, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.985, test=0.893) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=0.551) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.981, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.992, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.984, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.992, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.984, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.984, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.992, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.992, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.989, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.987, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.994, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.994, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.987, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.994, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.988, test=0.973) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.995, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.993, test=0.973) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.987, test=0.973) total time=   0.1s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.992, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.987, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.991, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.995, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.987, test=0.986) total time=   0.1s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.997, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.991, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.987, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.994, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.987, test=0.946) total time=   0.1s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=1.000) total time=   0.2s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.995, test=0.754) total time=   0.1s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.995, test=0.973) total time=   0.2s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.990, test=0.973) total time=   0.2s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.995, test=0.956) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.959) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.893) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.973) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.852) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.778) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.469) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.865) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=1.000, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.551) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.918) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.839) total time=   0.2s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.754) total time=   0.1s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.854) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.947) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.991, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.998, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.852) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.998, test=0.778) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.487) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.959) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.986) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.883) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.973) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.973) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.791) total time=   0.1s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.987, test=0.250) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=0.958) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.973) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.987, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.896) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.983, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.883) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.958) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.973) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=0.973) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.997, test=0.985) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.998, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.999, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.997, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.992, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=1.000, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.959) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.997, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.973) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.995, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.945) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.992, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.883) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.997, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=0.959) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.791) total time=   0.1s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=0.973) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.997, test=0.973) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.995, test=0.956) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.959) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.893) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.973) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.852) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.778) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.469) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.865) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=1.000, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.551) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.918) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.754) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.854) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.947) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.991, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.998, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.852) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.998, test=0.778) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.487) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.959) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.986) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.883) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.973) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.973) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.791) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.987, test=0.250) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=0.958) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.973) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.987, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.896) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.983, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.883) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.958) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.973) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=0.973) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.997, test=0.985) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.998, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.999, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.997, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.992, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=1.000, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.997, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.973) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.995, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.945) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.992, test=0.839) total time=   0.2s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.883) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.997, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=0.959) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.791) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=0.973) total time=   0.2s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.997, test=0.973) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.995, test=0.956) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.959) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.893) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.973) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.852) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.778) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.469) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.865) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=1.000, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.551) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.918) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.2s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.868) total time=   0.3s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.754) total time=   0.1s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.854) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.947) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.991, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.998, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.852) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.998, test=0.778) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.487) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.959) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.986) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.883) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.973) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.868) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.973) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.791) total time=   0.2s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.2s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.973) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.987, test=0.250) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=0.958) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.973) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.987, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.896) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.983, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.883) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.958) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.826) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.898) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=1.000) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.973) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.754) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=0.973) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.997, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.998, test=0.945) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.999, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.997, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.992, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=1.000, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.987) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.948) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.959) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.998, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.997, test=0.791) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.973) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.995, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.985) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.945) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.992, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.883) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.997, test=0.948) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=0.959) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.791) total time=   0.1s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.996, test=0.973) total time=   0.1s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.997, test=0.973) total time=   0.1s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 16\n",
      "n_resources: 3324\n",
      "Fitting 15 folds for each of 16 candidates, totalling 240 fits\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.990) total time=   0.3s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.963) total time=   0.4s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.981) total time=   0.3s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.982) total time=   0.3s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.869) total time=   0.4s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.982) total time=   0.4s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.928) total time=   0.4s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.978) total time=   0.3s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.953) total time=   0.3s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.978) total time=   0.4s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.941) total time=   0.4s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.978) total time=   0.4s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.613) total time=   0.4s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.410) total time=   0.4s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.3s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.990) total time=   0.3s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.963) total time=   0.4s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.981) total time=   0.3s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.982) total time=   0.3s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.869) total time=   0.4s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.982) total time=   0.3s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.928) total time=   0.3s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.965) total time=   0.3s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.953) total time=   0.4s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.978) total time=   0.4s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.950) total time=   0.4s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.978) total time=   0.4s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.613) total time=   0.4s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.413) total time=   0.4s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.3s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.990) total time=   0.3s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.963) total time=   0.4s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.981) total time=   0.4s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.982) total time=   0.4s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.869) total time=   0.3s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.982) total time=   0.4s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.928) total time=   0.4s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.978) total time=   0.4s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.953) total time=   0.4s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.978) total time=   0.3s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.941) total time=   0.4s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.978) total time=   0.4s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.613) total time=   0.4s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.999, test=0.410) total time=   0.4s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.990) total time=   0.4s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.968) total time=   0.3s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.4s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.982) total time=   0.3s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.883) total time=   0.3s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.964) total time=   0.4s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.933) total time=   0.3s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.991) total time=   0.3s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.953) total time=   0.4s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.996) total time=   0.4s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.968) total time=   0.4s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.960) total time=   0.3s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.604) total time=   0.4s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.511) total time=   0.4s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.990) total time=   0.4s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.972) total time=   0.3s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.976) total time=   0.3s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.982) total time=   0.3s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.869) total time=   0.4s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.991) total time=   0.4s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.933) total time=   0.4s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.991) total time=   0.4s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.957) total time=   0.4s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.996) total time=   0.3s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.964) total time=   0.4s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.613) total time=   0.4s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.514) total time=   0.4s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.985) total time=   0.4s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.972) total time=   0.4s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.981) total time=   0.5s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.869) total time=   0.4s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.982) total time=   0.5s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.933) total time=   0.5s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.3s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.965) total time=   0.4s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.996) total time=   0.3s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.964) total time=   0.4s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.610) total time=   0.3s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.514) total time=   0.5s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.985) total time=   0.4s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.972) total time=   0.4s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.981) total time=   0.4s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.3s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.869) total time=   0.3s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.982) total time=   0.3s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.933) total time=   0.3s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.4s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.965) total time=   0.4s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.996) total time=   0.3s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.964) total time=   0.5s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.610) total time=   0.4s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.514) total time=   0.4s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.3s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.980) total time=   0.2s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.963) total time=   0.2s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.3s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.969) total time=   0.2s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.874) total time=   0.2s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.968) total time=   0.5s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.933) total time=   0.2s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.953) total time=   0.3s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.964) total time=   0.2s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.960) total time=   0.2s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.613) total time=   0.3s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.635) total time=   0.2s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.980) total time=   0.2s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.963) total time=   0.3s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.986) total time=   0.3s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.969) total time=   0.3s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.874) total time=   0.2s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.968) total time=   0.2s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.933) total time=   0.3s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.953) total time=   0.2s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.964) total time=   0.3s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.960) total time=   0.3s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.613) total time=   0.2s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.635) total time=   0.3s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.990) total time=   0.2s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.963) total time=   0.2s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.986) total time=   0.2s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.969) total time=   0.2s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.883) total time=   0.2s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.964) total time=   0.2s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.933) total time=   0.2s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.982) total time=   0.2s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.953) total time=   0.2s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.996) total time=   0.2s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.973) total time=   0.2s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.969) total time=   0.2s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.597) total time=   0.2s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.594) total time=   0.2s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.951) total time=   0.2s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.980) total time=   0.4s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.968) total time=   0.4s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.3s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.982) total time=   0.4s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.879) total time=   0.3s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.964) total time=   0.4s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.933) total time=   0.4s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.4s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.953) total time=   0.4s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.4s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.964) total time=   0.4s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.960) total time=   0.4s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.613) total time=   0.4s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.502) total time=   0.4s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.980) total time=   0.3s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.968) total time=   0.4s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.986) total time=   0.4s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.982) total time=   0.3s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.879) total time=   0.3s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.964) total time=   0.4s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.933) total time=   0.4s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.3s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.953) total time=   0.4s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.987) total time=   0.4s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.964) total time=   0.4s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.960) total time=   0.4s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.613) total time=   0.3s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.502) total time=   0.4s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.978) total time=   0.4s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.717) total time=   0.2s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.972) total time=   0.2s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.986) total time=   0.2s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.973) total time=   0.2s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.869) total time=   0.2s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.991) total time=   0.2s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.933) total time=   0.3s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.953) total time=   0.2s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.996) total time=   0.2s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.964) total time=   0.2s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.982) total time=   0.2s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.605) total time=   0.2s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.604) total time=   0.2s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.973) total time=   0.2s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.793) total time=   0.2s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.968) total time=   0.2s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.981) total time=   0.2s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.879) total time=   0.3s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.991) total time=   0.2s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.933) total time=   0.2s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.957) total time=   0.2s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.996) total time=   0.2s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.968) total time=   0.2s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.982) total time=   0.2s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.605) total time=   0.2s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.518) total time=   0.2s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.955) total time=   0.2s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.717) total time=   0.2s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.972) total time=   0.2s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.986) total time=   0.3s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.973) total time=   0.2s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.869) total time=   0.2s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.991) total time=   0.2s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.933) total time=   0.2s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.953) total time=   0.2s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.996) total time=   0.2s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.964) total time=   0.2s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.982) total time=   0.2s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.605) total time=   0.2s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.604) total time=   0.2s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.973) total time=   0.2s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.976) total time=   0.1s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.973) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.869) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.982) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.933) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.960) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.965) total time=   0.1s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.992, test=0.982) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.986) total time=   0.1s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.964) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.637) total time=   0.1s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.535) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.978) total time=   0.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 6\n",
      "n_resources: 9972\n",
      "Fitting 15 folds for each of 6 candidates, totalling 90 fits\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.980) total time=   1.4s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.973) total time=   1.2s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.962) total time=   1.2s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.960) total time=   1.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.854) total time=   1.2s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.974) total time=   1.2s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.938) total time=   1.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.966) total time=   1.2s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.929) total time=   1.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.971) total time=   1.3s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.953) total time=   1.2s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.970) total time=   1.2s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.626) total time=   1.2s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.265) total time=   1.3s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.972) total time=   1.2s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.993) total time=   0.8s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.965) total time=   0.8s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.964) total time=   0.7s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.956) total time=   0.7s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.865) total time=   0.7s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.979) total time=   0.7s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.935) total time=   0.7s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.965) total time=   0.7s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.922) total time=   0.7s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.975) total time=   0.7s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.964) total time=   0.8s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.972) total time=   0.7s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.634) total time=   0.8s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.583) total time=   0.7s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.972) total time=   0.7s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.989) total time=   1.2s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.974) total time=   1.4s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.962) total time=   1.2s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.961) total time=   1.2s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.857) total time=   1.3s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.968) total time=   1.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.938) total time=   1.2s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.963) total time=   1.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.929) total time=   1.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.965) total time=   1.2s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.940) total time=   1.2s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.959) total time=   1.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.629) total time=   1.2s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.300) total time=   1.2s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.972) total time=   1.2s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.877) total time=   0.3s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.971) total time=   0.3s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.975) total time=   0.2s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.982) total time=   0.2s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.851) total time=   0.3s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.992) total time=   0.3s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.939) total time=   0.2s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.953) total time=   0.3s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.945) total time=   0.3s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.962) total time=   0.2s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.992, test=0.949) total time=   0.2s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=0.973) total time=   0.2s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.637) total time=   0.3s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.537) total time=   0.2s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.972) total time=   0.2s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.982) total time=   0.8s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.959) total time=   0.8s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.967) total time=   0.7s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.966) total time=   0.7s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.848) total time=   0.8s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.959) total time=   0.8s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.936) total time=   0.7s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.954) total time=   0.7s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.933) total time=   0.7s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.972) total time=   0.7s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.966) total time=   0.7s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.968) total time=   0.7s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.638) total time=   0.7s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.466) total time=   0.8s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.972) total time=   0.8s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.982) total time=   0.8s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.959) total time=   0.7s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.967) total time=   0.7s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.966) total time=   0.7s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.848) total time=   0.7s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.959) total time=   0.8s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.936) total time=   0.8s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.954) total time=   0.7s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.933) total time=   0.7s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.972) total time=   0.7s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.966) total time=   0.8s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.968) total time=   1.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.638) total time=   0.9s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.466) total time=   0.9s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.972) total time=   0.8s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 2\n",
      "n_resources: 29916\n",
      "Fitting 15 folds for each of 2 candidates, totalling 30 fits\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.990) total time=   0.8s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.969) total time=   0.8s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.993, test=0.973) total time=   0.8s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.992, test=0.957) total time=   0.8s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.836) total time=   0.8s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.985) total time=   0.8s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.956) total time=   0.8s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.971) total time=   0.8s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.991, test=0.972) total time=   0.8s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.984) total time=   0.9s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.992, test=0.978) total time=   0.8s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=0.965) total time=   0.8s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.723) total time=   0.8s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.225) total time=   0.8s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.992, test=0.971) total time=   0.8s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.989) total time=   2.5s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.947) total time=   2.4s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.967) total time=   2.3s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.975) total time=   2.4s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.843) total time=   2.3s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.973) total time=   2.3s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.944) total time=   2.4s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.957) total time=   2.3s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.939) total time=   2.3s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.979) total time=   2.4s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.963) total time=   2.4s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.975) total time=   2.4s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.708) total time=   2.4s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.182) total time=   2.4s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.971) total time=   2.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=LeaveOneGroupOut(),\n",
       "                    estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                     random_state=46),\n",
       "                    param_grid={&#x27;max_depth&#x27;: [5, 10, 20, 30],\n",
       "                                &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                &#x27;n_estimators&#x27;: [5, 10, 20, 30]},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=LeaveOneGroupOut(),\n",
       "                    estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                     random_state=46),\n",
       "                    param_grid={&#x27;max_depth&#x27;: [5, 10, 20, 30],\n",
       "                                &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                &#x27;n_estimators&#x27;: [5, 10, 20, 30]},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=46)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=46)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(cv=LeaveOneGroupOut(),\n",
       "                    estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                                     random_state=46),\n",
       "                    param_grid={'max_depth': [5, 10, 20, 30],\n",
       "                                'min_samples_split': [2, 5, 10],\n",
       "                                'n_estimators': [5, 10, 20, 30]},\n",
       "                    random_state=46, scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_rf = {'n_estimators': [5, 10, 20, 30],\n",
    "               'max_depth': [5, 10, 20, 30],\n",
    "               'min_samples_split': [2, 5, 10]}\n",
    "rf = RandomForestClassifier(random_state=46, class_weight= 'balanced')\n",
    "rf_hyperparams = HalvingGridSearchCV(rf, parameters_rf, cv = cv, scoring = 'f1_weighted', random_state=46, verbose=3)\n",
    "rf_hyperparams.fit(X, y, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78223bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.8970483852271778\n"
     ]
    }
   ],
   "source": [
    "print(rf_hyperparams.best_params_)\n",
    "print(rf_hyperparams.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "071b556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = rf_hyperparams.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c69448",
   "metadata": {},
   "source": [
    "### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb573df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 369\n",
      "max_resources_: 29941\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 100\n",
      "n_resources: 369\n",
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n",
      "[CV 1/15] END var_smoothing=1e-09;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-09;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-09;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-09;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-09;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-09;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-09;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-09;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-09;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-09;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-09;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-09;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-09;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-09;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-09;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.840, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.837, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1e-07;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-07;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-07;, score=(train=0.837, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-07;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-07;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-07;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-07;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-07;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-07;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-07;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-07;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-07;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-07;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-07;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-07;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.837, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.837, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.837, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.834, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.718, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.797, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.831, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.716, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.795, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.736, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.751, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.791, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.831, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.716, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.795, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.733, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.748, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.791, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.831, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.716, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.795, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.733, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.748, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.791, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.831, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.716, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.713, test=0.747) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.792, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.733, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.748, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.791, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.828, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.716, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.713, test=0.791) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.792, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.742, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.731, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.748, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.744, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.788, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.721, test=0.450) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.820, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.716, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.716, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.713, test=0.791) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.786, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.739, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.731, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.728, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.748, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.741, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1e-05;, score=(train=0.785, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-05;, score=(train=0.721, test=0.374) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-05;, score=(train=0.820, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-05;, score=(train=0.716, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-05;, score=(train=0.716, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-05;, score=(train=0.713, test=0.791) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-05;, score=(train=0.783, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-05;, score=(train=0.739, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-05;, score=(train=0.743, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-05;, score=(train=0.731, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-05;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-05;, score=(train=0.725, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-05;, score=(train=0.748, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-05;, score=(train=0.734, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-05;, score=(train=0.741, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.777, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.721, test=0.374) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.809, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.716, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.713, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.710, test=0.791) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.783, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.733, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.740, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.731, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.701, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.725, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.745, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.731, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.741, test=0.735) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.777, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.718, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.806, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.716, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.713, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.710, test=0.791) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.778, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.733, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.734, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.725, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.716, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.745, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.722, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.741, test=0.696) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.777, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.715, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.797, test=0.774) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.719, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.710, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.710, test=0.791) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.760, test=0.774) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.730, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.728, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.722, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.716, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.742, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.722, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.744, test=0.696) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.768, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.712, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.789, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.716, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.704, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.710, test=0.791) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.758, test=0.774) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.725, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.725, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.713, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.711, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.734, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.711, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.735, test=0.696) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.759, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.715, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.781, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.713, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.701, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.701, test=0.791) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.758, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.719, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.722, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.711, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.708, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.728, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.699, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.727, test=0.656) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0001232846739442066;, score=(train=0.754, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0001232846739442066;, score=(train=0.707, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0001232846739442066;, score=(train=0.766, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0001232846739442066;, score=(train=0.713, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0001232846739442066;, score=(train=0.701, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0001232846739442066;, score=(train=0.696, test=0.701) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0001232846739442066;, score=(train=0.752, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0001232846739442066;, score=(train=0.713, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0001232846739442066;, score=(train=0.716, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0001232846739442066;, score=(train=0.702, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0001232846739442066;, score=(train=0.704, test=0.662) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0001232846739442066;, score=(train=0.699, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0001232846739442066;, score=(train=0.725, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0001232846739442066;, score=(train=0.696, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0001232846739442066;, score=(train=0.727, test=0.656) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0001873817422860383;, score=(train=0.745, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0001873817422860383;, score=(train=0.701, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0001873817422860383;, score=(train=0.763, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0001873817422860383;, score=(train=0.704, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0001873817422860383;, score=(train=0.701, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0001873817422860383;, score=(train=0.690, test=0.739) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0001873817422860383;, score=(train=0.738, test=0.670) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0001873817422860383;, score=(train=0.707, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0001873817422860383;, score=(train=0.704, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0001873817422860383;, score=(train=0.696, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0001873817422860383;, score=(train=0.707, test=0.623) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0001873817422860383;, score=(train=0.693, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0001873817422860383;, score=(train=0.716, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0001873817422860383;, score=(train=0.693, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0001873817422860383;, score=(train=0.706, test=0.656) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0002848035868435805;, score=(train=0.742, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0002848035868435805;, score=(train=0.693, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0002848035868435805;, score=(train=0.746, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0002848035868435805;, score=(train=0.696, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0002848035868435805;, score=(train=0.696, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0002848035868435805;, score=(train=0.696, test=0.637) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0002848035868435805;, score=(train=0.732, test=0.548) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0002848035868435805;, score=(train=0.698, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0002848035868435805;, score=(train=0.701, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0002848035868435805;, score=(train=0.684, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0002848035868435805;, score=(train=0.687, test=0.623) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0002848035868435805;, score=(train=0.684, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0002848035868435805;, score=(train=0.707, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0002848035868435805;, score=(train=0.696, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0002848035868435805;, score=(train=0.706, test=0.568) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.00043287612810830614;, score=(train=0.736, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.00043287612810830614;, score=(train=0.690, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.00043287612810830614;, score=(train=0.746, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.00043287612810830614;, score=(train=0.698, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.00043287612810830614;, score=(train=0.696, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.00043287612810830614;, score=(train=0.690, test=0.580) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.00043287612810830614;, score=(train=0.729, test=0.548) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.00043287612810830614;, score=(train=0.698, test=0.796) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.00043287612810830614;, score=(train=0.692, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.00043287612810830614;, score=(train=0.687, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.00043287612810830614;, score=(train=0.684, test=0.623) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.00043287612810830614;, score=(train=0.684, test=0.917) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.00043287612810830614;, score=(train=0.701, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.00043287612810830614;, score=(train=0.684, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.00043287612810830614;, score=(train=0.703, test=0.568) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0006579332246575682;, score=(train=0.734, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0006579332246575682;, score=(train=0.687, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0006579332246575682;, score=(train=0.741, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0006579332246575682;, score=(train=0.701, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0006579332246575682;, score=(train=0.687, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0006579332246575682;, score=(train=0.696, test=0.580) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0006579332246575682;, score=(train=0.723, test=0.548) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0006579332246575682;, score=(train=0.698, test=0.840) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0006579332246575682;, score=(train=0.686, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0006579332246575682;, score=(train=0.684, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0006579332246575682;, score=(train=0.687, test=0.667) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0006579332246575682;, score=(train=0.681, test=0.917) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0006579332246575682;, score=(train=0.704, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0006579332246575682;, score=(train=0.687, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0006579332246575682;, score=(train=0.703, test=0.521) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.001;, score=(train=0.722, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.001;, score=(train=0.687, test=0.288) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.001;, score=(train=0.723, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.001;, score=(train=0.698, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.001;, score=(train=0.679, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.001;, score=(train=0.696, test=0.580) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.001;, score=(train=0.714, test=0.548) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.001;, score=(train=0.692, test=0.840) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.001;, score=(train=0.679, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.001;, score=(train=0.684, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.001;, score=(train=0.687, test=0.667) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.001;, score=(train=0.678, test=0.917) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.001;, score=(train=0.698, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.001;, score=(train=0.690, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.001;, score=(train=0.706, test=0.471) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0015199110829529332;, score=(train=0.716, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0015199110829529332;, score=(train=0.699, test=0.374) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0015199110829529332;, score=(train=0.720, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0015199110829529332;, score=(train=0.701, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0015199110829529332;, score=(train=0.682, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0015199110829529332;, score=(train=0.710, test=0.580) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0015199110829529332;, score=(train=0.708, test=0.548) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0015199110829529332;, score=(train=0.687, test=0.840) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0015199110829529332;, score=(train=0.688, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0015199110829529332;, score=(train=0.684, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0015199110829529332;, score=(train=0.693, test=0.667) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0015199110829529332;, score=(train=0.678, test=0.871) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0015199110829529332;, score=(train=0.696, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0015199110829529332;, score=(train=0.693, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0015199110829529332;, score=(train=0.715, test=0.471) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0023101297000831626;, score=(train=0.722, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0023101297000831626;, score=(train=0.710, test=0.374) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0023101297000831626;, score=(train=0.720, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0023101297000831626;, score=(train=0.704, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0023101297000831626;, score=(train=0.696, test=0.875) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0023101297000831626;, score=(train=0.716, test=0.580) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0023101297000831626;, score=(train=0.708, test=0.548) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0023101297000831626;, score=(train=0.690, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0023101297000831626;, score=(train=0.683, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0023101297000831626;, score=(train=0.687, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0023101297000831626;, score=(train=0.693, test=0.583) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0023101297000831626;, score=(train=0.678, test=0.822) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0023101297000831626;, score=(train=0.695, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0023101297000831626;, score=(train=0.699, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0023101297000831626;, score=(train=0.724, test=0.417) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0035111917342151347;, score=(train=0.725, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0035111917342151347;, score=(train=0.710, test=0.374) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0035111917342151347;, score=(train=0.717, test=0.399) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0035111917342151347;, score=(train=0.701, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0035111917342151347;, score=(train=0.727, test=0.874) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0035111917342151347;, score=(train=0.722, test=0.580) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0035111917342151347;, score=(train=0.711, test=0.548) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0035111917342151347;, score=(train=0.696, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0035111917342151347;, score=(train=0.683, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0035111917342151347;, score=(train=0.693, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0035111917342151347;, score=(train=0.708, test=0.583) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0035111917342151347;, score=(train=0.684, test=0.706) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0035111917342151347;, score=(train=0.696, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0035111917342151347;, score=(train=0.696, test=0.733) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0035111917342151347;, score=(train=0.727, test=0.417) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.005336699231206312;, score=(train=0.739, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.005336699231206312;, score=(train=0.735, test=0.580) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.005336699231206312;, score=(train=0.726, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.005336699231206312;, score=(train=0.716, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.005336699231206312;, score=(train=0.779, test=0.786) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.005336699231206312;, score=(train=0.764, test=0.637) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.005336699231206312;, score=(train=0.714, test=0.548) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.005336699231206312;, score=(train=0.705, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.005336699231206312;, score=(train=0.703, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.005336699231206312;, score=(train=0.702, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.005336699231206312;, score=(train=0.738, test=0.583) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.005336699231206312;, score=(train=0.699, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.005336699231206312;, score=(train=0.708, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.005336699231206312;, score=(train=0.713, test=0.674) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.005336699231206312;, score=(train=0.774, test=0.417) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.008111308307896872;, score=(train=0.748, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.008111308307896872;, score=(train=0.760, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.008111308307896872;, score=(train=0.732, test=0.478) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.008111308307896872;, score=(train=0.716, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.008111308307896872;, score=(train=0.780, test=0.727) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.008111308307896872;, score=(train=0.794, test=0.831) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.008111308307896872;, score=(train=0.720, test=0.670) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.008111308307896872;, score=(train=0.710, test=0.840) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.008111308307896872;, score=(train=0.723, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.008111308307896872;, score=(train=0.732, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.008111308307896872;, score=(train=0.769, test=0.626) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.008111308307896872;, score=(train=0.736, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.008111308307896872;, score=(train=0.739, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.008111308307896872;, score=(train=0.740, test=0.674) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.008111308307896872;, score=(train=0.785, test=0.417) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.012328467394420659;, score=(train=0.758, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.012328467394420659;, score=(train=0.758, test=0.872) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.012328467394420659;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.012328467394420659;, score=(train=0.724, test=0.661) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.012328467394420659;, score=(train=0.727, test=0.611) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.012328467394420659;, score=(train=0.784, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.012328467394420659;, score=(train=0.734, test=0.774) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.012328467394420659;, score=(train=0.761, test=0.733) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.012328467394420659;, score=(train=0.722, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.012328467394420659;, score=(train=0.725, test=0.920) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.012328467394420659;, score=(train=0.782, test=0.577) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.012328467394420659;, score=(train=0.760, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.012328467394420659;, score=(train=0.754, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.012328467394420659;, score=(train=0.739, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.012328467394420659;, score=(train=0.781, test=0.417) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.01873817422860387;, score=(train=0.787, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.01873817422860387;, score=(train=0.677, test=0.611) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.01873817422860387;, score=(train=0.765, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.01873817422860387;, score=(train=0.712, test=0.777) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.01873817422860387;, score=(train=0.634, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.01873817422860387;, score=(train=0.641, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.01873817422860387;, score=(train=0.769, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.01873817422860387;, score=(train=0.703, test=0.635) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.01873817422860387;, score=(train=0.731, test=0.781) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.01873817422860387;, score=(train=0.702, test=0.767) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.01873817422860387;, score=(train=0.682, test=0.442) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.01873817422860387;, score=(train=0.743, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.01873817422860387;, score=(train=0.740, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.01873817422860387;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.01873817422860387;, score=(train=0.781, test=0.417) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.028480358684358047;, score=(train=0.796, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.028480358684358047;, score=(train=0.536, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.028480358684358047;, score=(train=0.750, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.028480358684358047;, score=(train=0.636, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.028480358684358047;, score=(train=0.524, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.028480358684358047;, score=(train=0.531, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.028480358684358047;, score=(train=0.749, test=0.736) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.028480358684358047;, score=(train=0.641, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.028480358684358047;, score=(train=0.645, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.028480358684358047;, score=(train=0.594, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.028480358684358047;, score=(train=0.557, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.028480358684358047;, score=(train=0.655, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.028480358684358047;, score=(train=0.661, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.028480358684358047;, score=(train=0.652, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.028480358684358047;, score=(train=0.594, test=0.490) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.043287612810830614;, score=(train=0.647, test=0.568) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.043287612810830614;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.043287612810830614;, score=(train=0.697, test=0.448) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.043287612810830614;, score=(train=0.552, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.043287612810830614;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.043287612810830614;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.043287612810830614;, score=(train=0.648, test=0.338) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.043287612810830614;, score=(train=0.534, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.043287612810830614;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.043287612810830614;, score=(train=0.493, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.043287612810830614;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.043287612810830614;, score=(train=0.547, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.043287612810830614;, score=(train=0.547, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.043287612810830614;, score=(train=0.516, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.043287612810830614;, score=(train=0.509, test=0.620) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.06579332246575682;, score=(train=0.457, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.06579332246575682;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.06579332246575682;, score=(train=0.492, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.06579332246575682;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.06579332246575682;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.06579332246575682;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.06579332246575682;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.06579332246575682;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.06579332246575682;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.06579332246575682;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.06579332246575682;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.06579332246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.06579332246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.06579332246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.06579332246575682;, score=(train=0.503, test=0.764) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.1;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.1;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.1;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.1;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.1;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.1;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.1;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.1;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.1;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.1;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.1;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.1;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.1;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.1;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.1;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.1519911082952933;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.1519911082952933;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.1519911082952933;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.1519911082952933;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.1519911082952933;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.1519911082952933;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.1519911082952933;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.1519911082952933;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.1519911082952933;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.1519911082952933;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.1519911082952933;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.1519911082952933;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.1519911082952933;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.1519911082952933;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.1519911082952933;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.2310129700083158;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.2310129700083158;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.2310129700083158;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.2310129700083158;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.2310129700083158;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.2310129700083158;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.2310129700083158;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.2310129700083158;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.2310129700083158;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.2310129700083158;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.2310129700083158;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.2310129700083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.2310129700083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.2310129700083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.2310129700083158;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.3511191734215127;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.3511191734215127;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.3511191734215127;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.3511191734215127;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.3511191734215127;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.3511191734215127;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.3511191734215127;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.3511191734215127;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.3511191734215127;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.3511191734215127;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.3511191734215127;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.3511191734215127;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.3511191734215127;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.3511191734215127;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.3511191734215127;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.5336699231206302;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.5336699231206302;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.5336699231206302;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.5336699231206302;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.5336699231206302;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.5336699231206302;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.5336699231206302;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.5336699231206302;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.5336699231206302;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.5336699231206302;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.5336699231206302;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.5336699231206302;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.5336699231206302;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.5336699231206302;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.5336699231206302;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.811130830789689;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.811130830789689;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.811130830789689;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.811130830789689;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.811130830789689;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.811130830789689;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.811130830789689;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.811130830789689;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.811130830789689;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.811130830789689;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.811130830789689;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.811130830789689;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.811130830789689;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.811130830789689;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.811130830789689;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.2328467394420684;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.2328467394420684;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.2328467394420684;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.2328467394420684;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.2328467394420684;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.2328467394420684;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.2328467394420684;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.2328467394420684;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.2328467394420684;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.2328467394420684;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.2328467394420684;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.2328467394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.2328467394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.2328467394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.2328467394420684;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.8738174228603868;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.8738174228603868;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.8738174228603868;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.8738174228603868;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.8738174228603868;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.8738174228603868;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.8738174228603868;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.8738174228603868;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.8738174228603868;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.8738174228603868;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.8738174228603868;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.8738174228603868;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.8738174228603868;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.8738174228603868;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.8738174228603868;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083062;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083062;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083062;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083062;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083062;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083062;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083062;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083062;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083062;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083062;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083062;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083062;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083062;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083062;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083062;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.5793322465756825;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.5793322465756825;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.5793322465756825;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.5793322465756825;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.5793322465756825;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.5793322465756825;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.5793322465756825;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.5793322465756825;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.5793322465756825;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.5793322465756825;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.5793322465756825;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.5793322465756825;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.5793322465756825;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.5793322465756825;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.5793322465756825;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=10.0;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=10.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=10.0;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=10.0;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=10.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=10.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=10.0;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=10.0;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=10.0;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=10.0;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=10.0;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=10.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=10.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=10.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=10.0;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=15.199110829529332;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=15.199110829529332;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=15.199110829529332;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=15.199110829529332;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=15.199110829529332;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=15.199110829529332;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=15.199110829529332;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=15.199110829529332;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=15.199110829529332;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=15.199110829529332;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=15.199110829529332;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=15.199110829529332;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=15.199110829529332;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=15.199110829529332;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=15.199110829529332;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=23.10129700083158;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=23.10129700083158;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=23.10129700083158;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=23.10129700083158;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=23.10129700083158;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=23.10129700083158;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=23.10129700083158;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=23.10129700083158;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=23.10129700083158;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=23.10129700083158;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=23.10129700083158;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=23.10129700083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=23.10129700083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=23.10129700083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=23.10129700083158;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=35.11191734215127;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=35.11191734215127;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=35.11191734215127;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=35.11191734215127;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=35.11191734215127;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=35.11191734215127;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=35.11191734215127;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=35.11191734215127;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=35.11191734215127;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=35.11191734215127;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=35.11191734215127;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=35.11191734215127;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=35.11191734215127;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=35.11191734215127;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=35.11191734215127;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=53.36699231206324;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=53.36699231206324;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=53.36699231206324;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=53.36699231206324;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=53.36699231206324;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=53.36699231206324;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=53.36699231206324;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=53.36699231206324;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=53.36699231206324;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=53.36699231206324;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=53.36699231206324;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=53.36699231206324;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=53.36699231206324;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=53.36699231206324;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=53.36699231206324;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=81.11308307896888;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=81.11308307896888;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=81.11308307896888;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=81.11308307896888;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=81.11308307896888;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=81.11308307896888;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=81.11308307896888;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=81.11308307896888;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=81.11308307896888;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=81.11308307896888;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=81.11308307896888;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=81.11308307896888;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=81.11308307896888;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=81.11308307896888;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=81.11308307896888;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=123.28467394420684;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=123.28467394420684;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=123.28467394420684;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=123.28467394420684;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=123.28467394420684;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=123.28467394420684;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=123.28467394420684;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=123.28467394420684;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=123.28467394420684;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=123.28467394420684;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=123.28467394420684;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=123.28467394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=123.28467394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=123.28467394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=123.28467394420684;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=187.38174228603867;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=187.38174228603867;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=187.38174228603867;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=187.38174228603867;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=187.38174228603867;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=187.38174228603867;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=187.38174228603867;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=187.38174228603867;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=187.38174228603867;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=187.38174228603867;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=187.38174228603867;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=187.38174228603867;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=187.38174228603867;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=187.38174228603867;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=187.38174228603867;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=284.8035868435805;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=284.8035868435805;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=284.8035868435805;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=284.8035868435805;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=284.8035868435805;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=284.8035868435805;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=284.8035868435805;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=284.8035868435805;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=284.8035868435805;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=284.8035868435805;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=284.8035868435805;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=284.8035868435805;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=284.8035868435805;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=284.8035868435805;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=284.8035868435805;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=432.87612810830615;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=432.87612810830615;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=432.87612810830615;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=432.87612810830615;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=432.87612810830615;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=432.87612810830615;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=432.87612810830615;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=432.87612810830615;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=432.87612810830615;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=432.87612810830615;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=432.87612810830615;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=432.87612810830615;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=432.87612810830615;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=432.87612810830615;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=432.87612810830615;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=657.9332246575682;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=657.9332246575682;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=657.9332246575682;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=657.9332246575682;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=657.9332246575682;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=657.9332246575682;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=657.9332246575682;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=657.9332246575682;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=657.9332246575682;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=657.9332246575682;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=657.9332246575682;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=657.9332246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=657.9332246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=657.9332246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=657.9332246575682;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1000.0;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1000.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1000.0;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1000.0;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1000.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1000.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1000.0;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1000.0;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1000.0;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1000.0;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1000.0;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1000.0;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1519.9110829529332;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1519.9110829529332;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1519.9110829529332;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1519.9110829529332;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1519.9110829529332;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1519.9110829529332;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1519.9110829529332;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1519.9110829529332;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1519.9110829529332;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1519.9110829529332;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1519.9110829529332;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1519.9110829529332;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1519.9110829529332;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1519.9110829529332;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1519.9110829529332;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2310.1297000831582;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2310.1297000831582;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2310.1297000831582;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2310.1297000831582;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2310.1297000831582;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2310.1297000831582;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2310.1297000831582;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2310.1297000831582;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2310.1297000831582;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2310.1297000831582;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2310.1297000831582;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2310.1297000831582;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2310.1297000831582;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2310.1297000831582;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2310.1297000831582;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3511.1917342151273;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3511.1917342151273;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3511.1917342151273;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3511.1917342151273;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3511.1917342151273;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3511.1917342151273;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3511.1917342151273;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3511.1917342151273;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3511.1917342151273;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3511.1917342151273;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3511.1917342151273;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3511.1917342151273;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3511.1917342151273;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3511.1917342151273;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3511.1917342151273;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5336.699231206324;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5336.699231206324;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5336.699231206324;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5336.699231206324;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5336.699231206324;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5336.699231206324;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5336.699231206324;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5336.699231206324;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5336.699231206324;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5336.699231206324;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5336.699231206324;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5336.699231206324;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5336.699231206324;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5336.699231206324;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5336.699231206324;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8111.308307896889;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8111.308307896889;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8111.308307896889;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8111.308307896889;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8111.308307896889;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8111.308307896889;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8111.308307896889;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8111.308307896889;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8111.308307896889;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8111.308307896889;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8111.308307896889;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8111.308307896889;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8111.308307896889;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8111.308307896889;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8111.308307896889;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=12328.467394420684;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=12328.467394420684;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=12328.467394420684;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=12328.467394420684;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=12328.467394420684;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=12328.467394420684;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=12328.467394420684;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=12328.467394420684;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=12328.467394420684;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=12328.467394420684;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=12328.467394420684;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=12328.467394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=12328.467394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=12328.467394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=12328.467394420684;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=18738.174228603868;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=18738.174228603868;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=18738.174228603868;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=18738.174228603868;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=18738.174228603868;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=18738.174228603868;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=18738.174228603868;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=18738.174228603868;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=18738.174228603868;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=18738.174228603868;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=18738.174228603868;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=18738.174228603868;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=18738.174228603868;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=18738.174228603868;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=18738.174228603868;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=28480.35868435805;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=28480.35868435805;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=28480.35868435805;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=28480.35868435805;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=28480.35868435805;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=28480.35868435805;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=28480.35868435805;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=28480.35868435805;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=28480.35868435805;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=28480.35868435805;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=28480.35868435805;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=28480.35868435805;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=28480.35868435805;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=28480.35868435805;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=28480.35868435805;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=43287.612810830615;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=43287.612810830615;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=43287.612810830615;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=43287.612810830615;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=43287.612810830615;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=43287.612810830615;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=43287.612810830615;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=43287.612810830615;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=43287.612810830615;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=43287.612810830615;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=43287.612810830615;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=43287.612810830615;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=43287.612810830615;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=43287.612810830615;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=43287.612810830615;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=65793.32246575682;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=65793.32246575682;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=65793.32246575682;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=65793.32246575682;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=65793.32246575682;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=65793.32246575682;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=65793.32246575682;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=65793.32246575682;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=65793.32246575682;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=65793.32246575682;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=65793.32246575682;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=65793.32246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=65793.32246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=65793.32246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=65793.32246575682;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=100000.0;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=100000.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=100000.0;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=100000.0;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=100000.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=100000.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=100000.0;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=100000.0;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=100000.0;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=100000.0;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=100000.0;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=100000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=100000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=100000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=100000.0;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=151991.10829529332;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=151991.10829529332;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=151991.10829529332;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=151991.10829529332;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=151991.10829529332;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=151991.10829529332;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=151991.10829529332;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=151991.10829529332;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=151991.10829529332;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=151991.10829529332;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=151991.10829529332;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=151991.10829529332;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=151991.10829529332;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=151991.10829529332;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=151991.10829529332;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=231012.9700083158;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=231012.9700083158;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=231012.9700083158;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=231012.9700083158;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=231012.9700083158;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=231012.9700083158;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=231012.9700083158;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=231012.9700083158;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=231012.9700083158;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=231012.9700083158;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=231012.9700083158;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=231012.9700083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=231012.9700083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=231012.9700083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=231012.9700083158;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=351119.17342151416;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=351119.17342151416;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=351119.17342151416;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=351119.17342151416;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=351119.17342151416;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=351119.17342151416;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=351119.17342151416;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=351119.17342151416;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=351119.17342151416;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=351119.17342151416;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=351119.17342151416;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=351119.17342151416;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=351119.17342151416;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=351119.17342151416;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=351119.17342151416;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=533669.9231206323;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=533669.9231206323;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=533669.9231206323;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=533669.9231206323;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=533669.9231206323;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=533669.9231206323;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=533669.9231206323;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=533669.9231206323;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=533669.9231206323;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=533669.9231206323;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=533669.9231206323;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=533669.9231206323;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=533669.9231206323;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=533669.9231206323;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=533669.9231206323;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=811130.8307896889;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=811130.8307896889;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=811130.8307896889;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=811130.8307896889;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=811130.8307896889;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=811130.8307896889;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=811130.8307896889;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=811130.8307896889;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=811130.8307896889;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=811130.8307896889;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=811130.8307896889;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=811130.8307896889;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=811130.8307896889;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=811130.8307896889;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=811130.8307896889;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1232846.7394420684;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1232846.7394420684;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1232846.7394420684;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1232846.7394420684;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1232846.7394420684;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1232846.7394420684;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1232846.7394420684;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1232846.7394420684;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1232846.7394420684;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1232846.7394420684;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1232846.7394420684;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1232846.7394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1232846.7394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1232846.7394420684;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1232846.7394420684;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1873817.4228603868;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1873817.4228603868;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1873817.4228603868;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1873817.4228603868;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1873817.4228603868;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1873817.4228603868;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1873817.4228603868;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1873817.4228603868;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1873817.4228603868;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1873817.4228603868;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1873817.4228603868;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1873817.4228603868;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1873817.4228603868;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1873817.4228603868;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1873817.4228603868;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2848035.8684358047;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2848035.8684358047;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2848035.8684358047;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2848035.8684358047;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2848035.8684358047;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2848035.8684358047;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2848035.8684358047;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2848035.8684358047;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2848035.8684358047;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2848035.8684358047;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2848035.8684358047;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2848035.8684358047;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2848035.8684358047;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2848035.8684358047;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2848035.8684358047;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4328761.281083061;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4328761.281083061;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4328761.281083061;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4328761.281083061;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4328761.281083061;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4328761.281083061;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4328761.281083061;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4328761.281083061;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4328761.281083061;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4328761.281083061;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4328761.281083061;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4328761.281083061;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4328761.281083061;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4328761.281083061;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4328761.281083061;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6579332.246575682;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6579332.246575682;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6579332.246575682;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6579332.246575682;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6579332.246575682;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6579332.246575682;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6579332.246575682;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6579332.246575682;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6579332.246575682;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6579332.246575682;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6579332.246575682;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6579332.246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6579332.246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6579332.246575682;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6579332.246575682;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=10000000.0;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=10000000.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=10000000.0;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=10000000.0;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=10000000.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=10000000.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=10000000.0;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=10000000.0;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=10000000.0;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=10000000.0;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=10000000.0;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=10000000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=10000000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=10000000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=10000000.0;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=15199110.829529393;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=15199110.829529393;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=15199110.829529393;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=15199110.829529393;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=15199110.829529393;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=15199110.829529393;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=15199110.829529393;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=15199110.829529393;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=15199110.829529393;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=15199110.829529393;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=15199110.829529393;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=15199110.829529393;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=15199110.829529393;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=15199110.829529393;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=15199110.829529393;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=23101297.00083158;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=23101297.00083158;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=23101297.00083158;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=23101297.00083158;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=23101297.00083158;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=23101297.00083158;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=23101297.00083158;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=23101297.00083158;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=23101297.00083158;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=23101297.00083158;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=23101297.00083158;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=23101297.00083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=23101297.00083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=23101297.00083158;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=23101297.00083158;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=35111917.34215142;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=35111917.34215142;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=35111917.34215142;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=35111917.34215142;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=35111917.34215142;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=35111917.34215142;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=35111917.34215142;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=35111917.34215142;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=35111917.34215142;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=35111917.34215142;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=35111917.34215142;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=35111917.34215142;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=35111917.34215142;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=35111917.34215142;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=35111917.34215142;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=53366992.312063016;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=53366992.312063016;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=53366992.312063016;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=53366992.312063016;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=53366992.312063016;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=53366992.312063016;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=53366992.312063016;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=53366992.312063016;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=53366992.312063016;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=53366992.312063016;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=53366992.312063016;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=53366992.312063016;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=53366992.312063016;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=53366992.312063016;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=53366992.312063016;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=81113083.0789689;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=81113083.0789689;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=81113083.0789689;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=81113083.0789689;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=81113083.0789689;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=81113083.0789689;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=81113083.0789689;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=81113083.0789689;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=81113083.0789689;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=81113083.0789689;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=81113083.0789689;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=81113083.0789689;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=81113083.0789689;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=81113083.0789689;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=81113083.0789689;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=123284673.94420634;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=123284673.94420634;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=123284673.94420634;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=123284673.94420634;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=123284673.94420634;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=123284673.94420634;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=123284673.94420634;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=123284673.94420634;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=123284673.94420634;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=123284673.94420634;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=123284673.94420634;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=123284673.94420634;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=123284673.94420634;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=123284673.94420634;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=123284673.94420634;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=187381742.2860387;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=187381742.2860387;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=187381742.2860387;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=187381742.2860387;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=187381742.2860387;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=187381742.2860387;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=187381742.2860387;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=187381742.2860387;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=187381742.2860387;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=187381742.2860387;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=187381742.2860387;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=187381742.2860387;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=187381742.2860387;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=187381742.2860387;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=187381742.2860387;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=284803586.8435793;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=284803586.8435793;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=284803586.8435793;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=284803586.8435793;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=284803586.8435793;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=284803586.8435793;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=284803586.8435793;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=284803586.8435793;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=284803586.8435793;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=284803586.8435793;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=284803586.8435793;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=284803586.8435793;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=284803586.8435793;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=284803586.8435793;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=284803586.8435793;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=432876128.10830617;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=432876128.10830617;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=432876128.10830617;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=432876128.10830617;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=432876128.10830617;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=432876128.10830617;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=432876128.10830617;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=432876128.10830617;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=432876128.10830617;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=432876128.10830617;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=432876128.10830617;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=432876128.10830617;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=432876128.10830617;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=432876128.10830617;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=432876128.10830617;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=657933224.657571;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=657933224.657571;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=657933224.657571;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=657933224.657571;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=657933224.657571;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=657933224.657571;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=657933224.657571;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=657933224.657571;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=657933224.657571;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=657933224.657571;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=657933224.657571;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=657933224.657571;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=657933224.657571;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=657933224.657571;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=657933224.657571;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1000000000.0;, score=(train=0.444, test=0.495) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1000000000.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1000000000.0;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1000000000.0;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1000000000.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1000000000.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1000000000.0;, score=(train=0.482, test=0.358) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1000000000.0;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1000000000.0;, score=(train=0.454, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1000000000.0;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1000000000.0;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1000000000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1000000000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1000000000.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1000000000.0;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 34\n",
      "n_resources: 1107\n",
      "Fitting 15 folds for each of 34 candidates, totalling 510 fits\n",
      "[CV 1/15] END var_smoothing=0.00043287612810830614;, score=(train=0.741, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.00043287612810830614;, score=(train=0.723, test=0.373) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.00043287612810830614;, score=(train=0.728, test=0.314) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.00043287612810830614;, score=(train=0.699, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.00043287612810830614;, score=(train=0.711, test=0.959) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.00043287612810830614;, score=(train=0.735, test=0.403) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.00043287612810830614;, score=(train=0.701, test=0.606) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.00043287612810830614;, score=(train=0.698, test=0.762) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.00043287612810830614;, score=(train=0.689, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.00043287612810830614;, score=(train=0.684, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.00043287612810830614;, score=(train=0.693, test=0.851) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.00043287612810830614;, score=(train=0.679, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.00043287612810830614;, score=(train=0.706, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.00043287612810830614;, score=(train=0.695, test=0.694) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.00043287612810830614;, score=(train=0.725, test=0.549) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0002848035868435805;, score=(train=0.747, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0002848035868435805;, score=(train=0.725, test=0.373) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0002848035868435805;, score=(train=0.731, test=0.314) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0002848035868435805;, score=(train=0.702, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0002848035868435805;, score=(train=0.710, test=0.932) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0002848035868435805;, score=(train=0.736, test=0.465) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0002848035868435805;, score=(train=0.702, test=0.675) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0002848035868435805;, score=(train=0.703, test=0.774) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0002848035868435805;, score=(train=0.694, test=0.907) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0002848035868435805;, score=(train=0.687, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0002848035868435805;, score=(train=0.694, test=0.851) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0002848035868435805;, score=(train=0.677, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0002848035868435805;, score=(train=0.707, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0002848035868435805;, score=(train=0.701, test=0.694) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0002848035868435805;, score=(train=0.735, test=0.567) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.008111308307896872;, score=(train=0.725, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.008111308307896872;, score=(train=0.737, test=0.744) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.008111308307896872;, score=(train=0.751, test=0.599) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.008111308307896872;, score=(train=0.736, test=0.698) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.008111308307896872;, score=(train=0.770, test=0.972) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.008111308307896872;, score=(train=0.753, test=0.513) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.008111308307896872;, score=(train=0.735, test=0.844) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.008111308307896872;, score=(train=0.738, test=0.816) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.008111308307896872;, score=(train=0.728, test=0.894) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.008111308307896872;, score=(train=0.738, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.008111308307896872;, score=(train=0.734, test=0.799) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.008111308307896872;, score=(train=0.745, test=0.626) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.008111308307896872;, score=(train=0.742, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.008111308307896872;, score=(train=0.762, test=0.516) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.008111308307896872;, score=(train=0.751, test=0.431) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.012328467394420659;, score=(train=0.752, test=0.359) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.012328467394420659;, score=(train=0.766, test=0.839) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.012328467394420659;, score=(train=0.765, test=0.872) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.012328467394420659;, score=(train=0.752, test=0.740) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.012328467394420659;, score=(train=0.771, test=0.930) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.012328467394420659;, score=(train=0.775, test=0.756) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.012328467394420659;, score=(train=0.760, test=0.755) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.012328467394420659;, score=(train=0.768, test=0.815) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.012328467394420659;, score=(train=0.730, test=0.880) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.012328467394420659;, score=(train=0.752, test=0.921) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.012328467394420659;, score=(train=0.762, test=0.825) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.012328467394420659;, score=(train=0.768, test=0.516) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.012328467394420659;, score=(train=0.768, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.012328467394420659;, score=(train=0.761, test=0.516) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.012328467394420659;, score=(train=0.765, test=0.431) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0001873817422860383;, score=(train=0.750, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0001873817422860383;, score=(train=0.726, test=0.373) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0001873817422860383;, score=(train=0.737, test=0.314) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0001873817422860383;, score=(train=0.704, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0001873817422860383;, score=(train=0.715, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0001873817422860383;, score=(train=0.734, test=0.503) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0001873817422860383;, score=(train=0.711, test=0.708) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0001873817422860383;, score=(train=0.709, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0001873817422860383;, score=(train=0.703, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0001873817422860383;, score=(train=0.695, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0001873817422860383;, score=(train=0.698, test=0.837) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0001873817422860383;, score=(train=0.689, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0001873817422860383;, score=(train=0.713, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0001873817422860383;, score=(train=0.709, test=0.715) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0001873817422860383;, score=(train=0.745, test=0.585) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0001232846739442066;, score=(train=0.763, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0001232846739442066;, score=(train=0.727, test=0.373) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0001232846739442066;, score=(train=0.740, test=0.314) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0001232846739442066;, score=(train=0.708, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0001232846739442066;, score=(train=0.718, test=0.879) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0001232846739442066;, score=(train=0.737, test=0.539) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0001232846739442066;, score=(train=0.719, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0001232846739442066;, score=(train=0.716, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0001232846739442066;, score=(train=0.706, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0001232846739442066;, score=(train=0.708, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0001232846739442066;, score=(train=0.701, test=0.823) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0001232846739442066;, score=(train=0.695, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0001232846739442066;, score=(train=0.717, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0001232846739442066;, score=(train=0.713, test=0.715) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0001232846739442066;, score=(train=0.750, test=0.635) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.768, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.732, test=0.373) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.748, test=0.365) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.709, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.726, test=0.879) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.738, test=0.591) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.727, test=0.755) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.730, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.723, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.714, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.705, test=0.823) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.701, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.724, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.713, test=0.735) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.758, test=0.683) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.772, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.733, test=0.373) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.755, test=0.389) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.714, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.729, test=0.879) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.747, test=0.607) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.729, test=0.755) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.735, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.730, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.721, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.708, test=0.821) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.707, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.729, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.724, test=0.735) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.766, test=0.742) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.776, test=0.384) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.738, test=0.394) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.759, test=0.435) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.721, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.735, test=0.879) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.749, test=0.607) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.734, test=0.755) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.744, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.729, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.731, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.708, test=0.821) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.714, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.736, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.733, test=0.754) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.770, test=0.771) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.778, test=0.409) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.737, test=0.454) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.764, test=0.519) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.722, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.738, test=0.865) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.755, test=0.623) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.739, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.751, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.733, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.737, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.709, test=0.821) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.721, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.743, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.738, test=0.773) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.771, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1e-05;, score=(train=0.781, test=0.432) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-05;, score=(train=0.739, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-05;, score=(train=0.771, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-05;, score=(train=0.727, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-05;, score=(train=0.750, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-05;, score=(train=0.756, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-05;, score=(train=0.747, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-05;, score=(train=0.758, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-05;, score=(train=0.739, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-05;, score=(train=0.739, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-05;, score=(train=0.714, test=0.821) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-05;, score=(train=0.726, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-05;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-05;, score=(train=0.737, test=0.773) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-05;, score=(train=0.777, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.780, test=0.409) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.739, test=0.454) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.770, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.725, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.745, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.757, test=0.670) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.743, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.756, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.736, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.738, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.712, test=0.821) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.724, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.738, test=0.773) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.775, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.783, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.734, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.783, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.734, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.783, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.734, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.783, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.734, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.783, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.734, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.783, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.734, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.783, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.734, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.783, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.782, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.782, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1e-07;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-07;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-07;, score=(train=0.782, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-07;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-07;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-07;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-07;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-07;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-07;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-07;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-07;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-07;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-07;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-07;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-07;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.782, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.733, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.763, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.782, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.733, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.763, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.782, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.733, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.763, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.740, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.782, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.733, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.760, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.763, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.740, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.782, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.782, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.733, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.760, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.753, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.763, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.740, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.744, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.739, test=0.773) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.782, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.781, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.733, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.759, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.753, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.763, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.740, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.744, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.732, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.738, test=0.773) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.782, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.781, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.732, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.759, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.753, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.762, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.740, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.743, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.732, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.737, test=0.773) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.782, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.782, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.733, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1e-09;, score=(train=0.783, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-09;, score=(train=0.741, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-09;, score=(train=0.783, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-09;, score=(train=0.734, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-09;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-09;, score=(train=0.761, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-09;, score=(train=0.754, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-09;, score=(train=0.764, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-09;, score=(train=0.741, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-09;, score=(train=0.745, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-09;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-09;, score=(train=0.734, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-09;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-09;, score=(train=0.739, test=0.791) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-09;, score=(train=0.783, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.782, test=0.454) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.740, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.779, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.730, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.758, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.752, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.758, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.739, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.743, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.714, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.732, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.737, test=0.773) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.779, test=0.813) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.781, test=0.432) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.740, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.776, test=0.557) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.728, test=0.670) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.753, test=0.852) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.756, test=0.658) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.750, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.758, test=0.760) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.739, test=0.921) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.742, test=0.908) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.714, test=0.821) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.731, test=0.931) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.737, test=0.773) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.777, test=0.813) total time=   0.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 12\n",
      "n_resources: 3321\n",
      "Fitting 15 folds for each of 12 candidates, totalling 180 fits\n",
      "[CV 1/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.774, test=0.414) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.754, test=0.621) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.762, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1e-07;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-07;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-07;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-07;, score=(train=0.755, test=0.626) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-07;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-07;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-07;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-07;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-07;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-07;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-07;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-07;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-07;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-07;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-07;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.755, test=0.626) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.755, test=0.631) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.755, test=0.631) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.755, test=0.631) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.755, test=0.631) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.755, test=0.631) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.755, test=0.631) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.755, test=0.631) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.774, test=0.414) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.754, test=0.626) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.762, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.778, test=0.401) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.762, test=0.548) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.774, test=0.421) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.755, test=0.631) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.763, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.766, test=0.606) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.755, test=0.805) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.762, test=0.754) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.739, test=0.916) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.758, test=0.904) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.734, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.749, test=0.913) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.771, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.760, test=0.777) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.765, test=0.765) total time=   0.0s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 4\n",
      "n_resources: 9963\n",
      "Fitting 15 folds for each of 4 candidates, totalling 60 fits\n",
      "[CV 1/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.769, test=0.352) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.752, test=0.504) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.773, test=0.362) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.755, test=0.614) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.741, test=0.895) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.750, test=0.572) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.755, test=0.824) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.754, test=0.768) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.745, test=0.903) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.749, test=0.900) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.749, test=0.815) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.741, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.771, test=0.463) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.760, test=0.663) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.752, test=0.726) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.769, test=0.352) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.752, test=0.504) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.773, test=0.362) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.755, test=0.614) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.741, test=0.895) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.750, test=0.572) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.755, test=0.824) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.754, test=0.768) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.745, test=0.903) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.749, test=0.900) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.749, test=0.815) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.741, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.771, test=0.463) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.760, test=0.663) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.752, test=0.726) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.769, test=0.352) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.752, test=0.504) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.773, test=0.362) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.755, test=0.614) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.741, test=0.895) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.750, test=0.572) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.755, test=0.824) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.754, test=0.768) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.745, test=0.903) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.749, test=0.900) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.749, test=0.815) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.741, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.771, test=0.463) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.760, test=0.663) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.752, test=0.726) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.769, test=0.352) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.752, test=0.504) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.773, test=0.362) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.755, test=0.614) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.741, test=0.895) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.750, test=0.572) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.755, test=0.824) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.754, test=0.768) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.745, test=0.903) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.749, test=0.900) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.749, test=0.815) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.741, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.771, test=0.463) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.760, test=0.663) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.752, test=0.726) total time=   0.0s\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 29889\n",
      "Fitting 15 folds for each of 2 candidates, totalling 30 fits\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.771, test=0.307) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.756, test=0.556) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.777, test=0.408) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.764, test=0.597) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.749, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.758, test=0.609) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.766, test=0.803) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.762, test=0.774) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.758, test=0.923) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.754, test=0.907) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.756, test=0.811) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.746, test=0.920) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.771, test=0.473) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.765, test=0.680) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.758, test=0.732) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.771, test=0.307) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.756, test=0.556) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.777, test=0.408) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.764, test=0.597) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.749, test=0.905) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.758, test=0.609) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.766, test=0.803) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.762, test=0.774) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.758, test=0.923) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.754, test=0.907) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.756, test=0.811) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.746, test=0.920) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.771, test=0.473) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.765, test=0.680) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.758, test=0.732) total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=LeaveOneGroupOut(), estimator=GaussianNB(),\n",
       "                    param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e-09, 1.51991108e-09, 2.31012970e-09, 3.51119173e-09,\n",
       "       5.33669923e-09, 8.11130831e-09, 1.23284674e-08, 1.87381742e-08,\n",
       "       2.84803587e-08, 4.32876128e-08, 6.57933225e-08, 1.00000000e-07,\n",
       "       1.51991108e-07, 2.31012970e-07, 3.51119173e-07, 5.33669923e-07,\n",
       "       8.11130831...\n",
       "       3.51119173e+05, 5.33669923e+05, 8.11130831e+05, 1.23284674e+06,\n",
       "       1.87381742e+06, 2.84803587e+06, 4.32876128e+06, 6.57933225e+06,\n",
       "       1.00000000e+07, 1.51991108e+07, 2.31012970e+07, 3.51119173e+07,\n",
       "       5.33669923e+07, 8.11130831e+07, 1.23284674e+08, 1.87381742e+08,\n",
       "       2.84803587e+08, 4.32876128e+08, 6.57933225e+08, 1.00000000e+09])},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=LeaveOneGroupOut(), estimator=GaussianNB(),\n",
       "                    param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e-09, 1.51991108e-09, 2.31012970e-09, 3.51119173e-09,\n",
       "       5.33669923e-09, 8.11130831e-09, 1.23284674e-08, 1.87381742e-08,\n",
       "       2.84803587e-08, 4.32876128e-08, 6.57933225e-08, 1.00000000e-07,\n",
       "       1.51991108e-07, 2.31012970e-07, 3.51119173e-07, 5.33669923e-07,\n",
       "       8.11130831...\n",
       "       3.51119173e+05, 5.33669923e+05, 8.11130831e+05, 1.23284674e+06,\n",
       "       1.87381742e+06, 2.84803587e+06, 4.32876128e+06, 6.57933225e+06,\n",
       "       1.00000000e+07, 1.51991108e+07, 2.31012970e+07, 3.51119173e+07,\n",
       "       5.33669923e+07, 8.11130831e+07, 1.23284674e+08, 1.87381742e+08,\n",
       "       2.84803587e+08, 4.32876128e+08, 6.57933225e+08, 1.00000000e+09])},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(cv=LeaveOneGroupOut(), estimator=GaussianNB(),\n",
       "                    param_grid={'var_smoothing': array([1.00000000e-09, 1.51991108e-09, 2.31012970e-09, 3.51119173e-09,\n",
       "       5.33669923e-09, 8.11130831e-09, 1.23284674e-08, 1.87381742e-08,\n",
       "       2.84803587e-08, 4.32876128e-08, 6.57933225e-08, 1.00000000e-07,\n",
       "       1.51991108e-07, 2.31012970e-07, 3.51119173e-07, 5.33669923e-07,\n",
       "       8.11130831...\n",
       "       3.51119173e+05, 5.33669923e+05, 8.11130831e+05, 1.23284674e+06,\n",
       "       1.87381742e+06, 2.84803587e+06, 4.32876128e+06, 6.57933225e+06,\n",
       "       1.00000000e+07, 1.51991108e+07, 2.31012970e+07, 3.51119173e+07,\n",
       "       5.33669923e+07, 8.11130831e+07, 1.23284674e+08, 1.87381742e+08,\n",
       "       2.84803587e+08, 4.32876128e+08, 6.57933225e+08, 1.00000000e+09])},\n",
       "                    random_state=46, scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_gnb = {'var_smoothing': np.logspace(-9, 9, 100)}\n",
    "gnb = GaussianNB()\n",
    "gnb_hyperparams = HalvingGridSearchCV(gnb, parameters_gnb, cv = cv, scoring = 'f1_weighted', random_state=46, verbose=3)\n",
    "gnb_hyperparams.fit(X, y, groups = group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6841d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 2.310129700083158e-09}\n",
      "0.6937254660066979\n"
     ]
    }
   ],
   "source": [
    "print(gnb_hyperparams.best_params_)\n",
    "print(gnb_hyperparams.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d0610cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = gnb_hyperparams.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4d9c9",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89902138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 369\n",
      "max_resources_: 29941\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 81\n",
      "n_resources: 369\n",
      "Fitting 15 folds for each of 81 candidates, totalling 1215 fits\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.985, test=0.961) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.986, test=0.960) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.985, test=0.961) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.986, test=0.960) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.985, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.831) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.983, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.961) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.980, test=0.960) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.958) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.959) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.2s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.958) total time=   0.2s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.959) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.917) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.917) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.960) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.831) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.2s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.959) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.958) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.958) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.694, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.530, test=0.611) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.778, test=0.956) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.748, test=0.923) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.524, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.537, test=0.727) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.839, test=0.782) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.754, test=0.635) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.758, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.753, test=0.822) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.571, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.721, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.687, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.716, test=0.908) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.511, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.517, test=0.611) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.744, test=0.870) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.724, test=0.814) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.517, test=0.381) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.524, test=0.611) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.771, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.727, test=0.635) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.575, test=0.920) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.737, test=0.871) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.546, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.705, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.659, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.706, test=0.843) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.764, test=0.575) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.743, test=0.661) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.664, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.738, test=0.840) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.700, test=0.871) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.688, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.678, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.553, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.811, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.822, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.834, test=0.958) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.823, test=0.913) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.807, test=0.661) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.845, test=0.915) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.834, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.831, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.819, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.818, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.819, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.814, test=0.831) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.816, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.831, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.824, test=0.833) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.839, test=0.568) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.745, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.775, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.792, test=0.684) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.756, test=0.661) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.815, test=0.778) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.791, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.777, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.770, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.734, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.770, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.799, test=0.623) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.773, test=0.767) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.779, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.790, test=0.785) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.803, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.293, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.578, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.752, test=0.548) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.730, test=0.529) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.581, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.585, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.675, test=0.670) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.727, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.291, test=0.511) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.755, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.621, test=0.389) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.766, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.765, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.748, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.674, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.819, test=0.367) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.837, test=0.874) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.860, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.828, test=0.740) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.178, test=0.288) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.853, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.839, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.821, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.839, test=0.922) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.822, test=0.791) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.836, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.844, test=0.806) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.844, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.774, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.751, test=0.831) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.806, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.773, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.782, test=0.671) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.794, test=0.874) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.792, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.775, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.749, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.778, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.793, test=0.637) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.772, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.784, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.795, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.787, test=0.154) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.338, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.655, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.763, test=0.684) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.739, test=0.619) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.626, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.644, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.672, test=0.670) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.745, test=0.882) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.475, test=0.567) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.764, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.631, test=0.580) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.762, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.762, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.756, test=0.635) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.654, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.7s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.957) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.985, test=0.961) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.986, test=0.960) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.957) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.831) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.985, test=0.961) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.986, test=0.960) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.957) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.985, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.831) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.983, test=1.000) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.961) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.980, test=0.960) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.957) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.831) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.958) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.957) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.958) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.917) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.917) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.957) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.958) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.960) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.831) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.959) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.958) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.958) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.985, test=0.961) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.986, test=0.960) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.831) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.819) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.985, test=0.961) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.986, test=0.960) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.985, test=1.000) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.831) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.983, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.2s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.961) total time=   3.5s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.980, test=0.960) total time=   0.8s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.9s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.957) total time=   0.3s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.9s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.831) total time=   0.8s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.958) total time=   0.4s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.3s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.959) total time=   0.2s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.4s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.3s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.4s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.4s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.3s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.3s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.957) total time=   0.3s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.958) total time=   0.4s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   0.4s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.959) total time=   0.2s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.2s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.917) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.3s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.2s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.3s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.917) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.957) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.2s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.831) total time=   0.2s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.958) total time=   0.2s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.2s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.959) total time=   0.2s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.960) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.2s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.831) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.2s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.959) total time=   0.3s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.958) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.831) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.958) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.958) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.2s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.960) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.917) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.3s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.239, test=0.194) total time=   0.3s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.510, test=0.381) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.707, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.522, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.746, test=0.913) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.563, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.513, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.516, test=0.550) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.510, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.497, test=0.550) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.233, test=0.194) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.692, test=0.867) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.515, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.517, test=0.381) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.715, test=0.670) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.546, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.225, test=0.229) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.506, test=0.550) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.514, test=0.381) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.510, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.510, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.636, test=0.867) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.503, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.647, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.514, test=0.381) total time=   0.3s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.614, test=0.228) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.635, test=0.285) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.704, test=0.671) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.795, test=0.575) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.738, test=0.701) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.720, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.704, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.763, test=0.822) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.769, test=0.699) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.570, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.763, test=0.882) total time=   0.2s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.733, test=0.340) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.767, test=0.706) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.775, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.765, test=0.645) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.826, test=0.296) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.620, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.677, test=0.611) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.789, test=0.575) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.749, test=0.740) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.684, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.662, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.726, test=0.724) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.772, test=0.699) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.475, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.743, test=0.882) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.719, test=0.361) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.760, test=0.550) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.759, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.761, test=0.610) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.784, test=0.228) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.233, test=0.194) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.575, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.742, test=0.733) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.694, test=0.777) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.582, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.575, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.655, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.720, test=0.706) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.600, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.560, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.541, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.541, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.553, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.620, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.723, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.720, test=0.700) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.792, test=0.575) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.687, test=0.619) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.747, test=0.577) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.746, test=0.958) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.783, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.690, test=0.699) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.646, test=0.918) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.668, test=0.833) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.746, test=0.577) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.690, test=0.878) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.693, test=0.884) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.725, test=0.320) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.765, test=0.228) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.669, test=0.285) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.680, test=0.611) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.792, test=0.575) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.670, test=0.619) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.676, test=0.381) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.654, test=0.958) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.772, test=0.868) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.670, test=0.699) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.555, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.662, test=0.796) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.680, test=0.478) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.696, test=0.822) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.690, test=0.803) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.716, test=0.379) total time=   0.2s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.705, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.606, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.748, test=0.733) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.667, test=0.576) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.612, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.612, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.646, test=0.478) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.670, test=0.699) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.231, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.642, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.588, test=0.361) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.571, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.571, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.609, test=0.531) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.627, test=0.072) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.7s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.957) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.831) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.819) total time=   0.8s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.985, test=0.961) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.986, test=0.960) total time=   1.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   1.7s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.957) total time=   0.8s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.831) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.819) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.8s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   1.5s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.8s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.985, test=0.961) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.986, test=0.960) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.957) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.985, test=1.000) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.831) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.983, test=1.000) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.819) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.9s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.9s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.9s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   2.7s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   1.5s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.961) total time=   0.9s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.980, test=0.960) total time=   1.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.9s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.9s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.957) total time=   0.9s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   1.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.831) total time=   1.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.958) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.8s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.959) total time=   1.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   1.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.959) total time=   1.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.9s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.9s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   1.3s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.959) total time=   1.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.8s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   1.3s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.8s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.957) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   1.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   2.3s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.958) total time=   1.2s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   1.7s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.959) total time=   1.4s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   2.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   1.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.917) total time=   0.9s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.8s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.7s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.917) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.957) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.958) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.960) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.831) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.959) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.958) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.9s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.9s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   1.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   1.9s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   2.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.958) total time=   0.9s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   1.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.9s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   1.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.958) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.4s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.4s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.4s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.960) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.917) total time=   0.4s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.991, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.983, test=1.000) total time=   0.1s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.983, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.1s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.1s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.1s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.985, test=0.961) total time=   0.1s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.980, test=0.960) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.983, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.983, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.985, test=0.961) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.980, test=0.960) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.983, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.985, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.831) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.983, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.983, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.2s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.961) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.980, test=0.960) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.831) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.958) total time=   0.1s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.874) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.991, test=0.959) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.991, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.917) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.957) total time=   0.1s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.831) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.959) total time=   0.2s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.874) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.959) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.917) total time=   0.1s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.957) total time=   0.1s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.831) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.958) total time=   0.1s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.819) total time=   0.1s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.1s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.2s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.786) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.959) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=0.997, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=0.997, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.957) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=0.997, test=0.958) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=0.997, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=0.997, test=0.917) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=0.997, test=0.960) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=0.997, test=0.917) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.233, test=0.194) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.510, test=0.381) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.486, test=0.358) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.483, test=0.656) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.517, test=0.381) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.204, test=0.309) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.483, test=0.550) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.225, test=0.229) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.487, test=0.550) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.514, test=0.381) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.490, test=0.550) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.503, test=0.700) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.6s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.991, test=1.000) total time=   0.6s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.991, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.983, test=1.000) total time=   0.5s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.983, test=0.819) total time=   0.6s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.4s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.6s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.5s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.959) total time=   0.5s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.988, test=0.917) total time=   0.5s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.985, test=0.961) total time=   0.4s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.980, test=0.960) total time=   0.5s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.5s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=1.000) total time=   0.5s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=1.000) total time=   0.4s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.991, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.983, test=1.000) total time=   0.5s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.983, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.5s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.5s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.959) total time=   0.5s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.988, test=0.917) total time=   0.5s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.985, test=0.961) total time=   0.5s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.980, test=0.960) total time=   0.5s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.6s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.983, test=1.000) total time=   0.5s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.985, test=1.000) total time=   0.4s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.983, test=1.000) total time=   0.5s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.983, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.6s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.5s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.6s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.988, test=0.917) total time=   0.5s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.961) total time=   0.5s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.980, test=0.960) total time=   0.5s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.5s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.957) total time=   0.5s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.958) total time=   0.5s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.6s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.874) total time=   0.5s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.991, test=0.959) total time=   0.5s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.991, test=1.000) total time=   0.6s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.6s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.917) total time=   0.8s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.957) total time=   0.5s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.4s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.958) total time=   0.5s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.874) total time=   0.6s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.959) total time=   0.5s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=1.000) total time=   0.5s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.917) total time=   0.5s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.957) total time=   0.5s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.958) total time=   0.6s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.960) total time=   0.5s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.786) total time=   0.5s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.959) total time=   0.5s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=1.000) total time=   0.6s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.4s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.957) total time=   0.4s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=0.997, test=0.958) total time=   0.5s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=0.997, test=0.960) total time=   0.4s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=0.997, test=0.917) total time=   0.4s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.4s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   0.4s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.5s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.957) total time=   0.4s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=0.997, test=0.958) total time=   0.4s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.819) total time=   0.4s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.4s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=0.997, test=0.960) total time=   0.5s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=0.997, test=0.917) total time=   0.5s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.4s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.917) total time=   0.4s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.4s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.4s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.958) total time=   0.4s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.5s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.819) total time=   0.5s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=0.997, test=0.960) total time=   0.5s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.5s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=0.997, test=0.917) total time=   0.4s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.5s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.6s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.4s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 1107\n",
      "Fitting 15 folds for each of 27 candidates, totalling 405 fits\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.7s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.986) total time=   1.0s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.972) total time=   1.1s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.998, test=0.987) total time=   1.0s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.998, test=0.866) total time=   0.8s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.998, test=1.000) total time=   0.8s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.996, test=0.866) total time=   0.7s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.998, test=0.974) total time=   0.7s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.961) total time=   0.8s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.987) total time=   0.7s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.8s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=1.000) total time=   0.7s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.987) total time=   0.8s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.987) total time=   0.7s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.8s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.839) total time=   0.7s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.897) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.974) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.931) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.7s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.973) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.866) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.933) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.945) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.972) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.986) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.866) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.986) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.897) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.974) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.933) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.945) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.973) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.866) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.972) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.866) total time=   0.8s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   0.9s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.897) total time=   0.8s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.974) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.931) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.7s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.973) total time=   0.9s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.866) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.972) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.866) total time=   0.7s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.973) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.897) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.974) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.931) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.973) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.986) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.992, test=0.972) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.990, test=0.987) total time=   0.2s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.996, test=0.973) total time=   0.3s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.993, test=0.850) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.990, test=0.974) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.998, test=0.961) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.996, test=0.947) total time=   0.2s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.996, test=1.000) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.987) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.987) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.993, test=0.987) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.986) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.992, test=0.972) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.990, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=0.973) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.993, test=0.850) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.990, test=0.974) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.998, test=0.961) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=0.947) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=1.000) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.987) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.987) total time=   0.2s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.993, test=0.987) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.986) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.992, test=0.972) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.990, test=0.987) total time=   0.2s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=0.973) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.993, test=0.850) total time=   0.2s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.990, test=0.974) total time=   0.2s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.998, test=0.961) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=0.947) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=1.000) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.987) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.2s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.987) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.993, test=0.987) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.993, test=1.000) total time=   0.8s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.986) total time=   0.8s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.990, test=0.972) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.987, test=0.987) total time=   0.8s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.839) total time=   0.8s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.993, test=0.973) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.850) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.989, test=0.987) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.993, test=0.961) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.996, test=0.947) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.996, test=1.000) total time=   0.8s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.995, test=0.987) total time=   0.7s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.996, test=0.974) total time=   0.8s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.987) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   0.8s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.986) total time=   1.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.992, test=0.972) total time=   1.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.990, test=0.987) total time=   1.2s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.839) total time=   0.9s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=0.973) total time=   0.9s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.993, test=0.850) total time=   0.8s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.990, test=0.974) total time=   0.8s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.998, test=0.961) total time=   0.8s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=0.947) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=1.000) total time=   0.8s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.987) total time=   0.8s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.987) total time=   0.8s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.993, test=0.987) total time=   0.8s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.8s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.986) total time=   0.8s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.992, test=0.972) total time=   0.8s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.990, test=0.987) total time=   0.8s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.839) total time=   0.9s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.996, test=0.973) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.993, test=0.850) total time=   0.8s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.990, test=0.974) total time=   0.8s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.998, test=0.961) total time=   0.8s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.996, test=0.947) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.996, test=1.000) total time=   0.8s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.987) total time=   0.8s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.987) total time=   0.8s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.987) total time=   0.8s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.993, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.986) total time=   0.2s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.990, test=0.972) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.987, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.839) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.993, test=0.973) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.850) total time=   0.2s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.989, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.993, test=0.961) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.996, test=0.947) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.996, test=1.000) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.995, test=0.987) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.2s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.996, test=0.974) total time=   0.3s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.987) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.9s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.986) total time=   1.0s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.992, test=0.972) total time=   1.1s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.990, test=0.987) total time=   1.1s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.839) total time=   1.3s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.996, test=0.973) total time=   1.3s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.993, test=0.850) total time=   1.0s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.990, test=0.974) total time=   1.2s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.998, test=0.961) total time=   1.3s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.996, test=0.947) total time=   1.1s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.996, test=1.000) total time=   1.4s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.987) total time=   1.1s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.997, test=1.000) total time=   1.2s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.987) total time=   1.1s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.993, test=0.987) total time=   1.3s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.993, test=1.000) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.986) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.990, test=0.972) total time=   0.2s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.987, test=0.987) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.839) total time=   0.3s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.993, test=0.973) total time=   0.2s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.850) total time=   0.2s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.989, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.993, test=0.961) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.996, test=0.947) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.996, test=1.000) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.995, test=0.987) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.996, test=0.974) total time=   0.2s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.987) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=1.000) total time=   1.1s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.994, test=0.986) total time=   1.0s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.992, test=0.972) total time=   1.3s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.990, test=0.987) total time=   1.2s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.839) total time=   1.0s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=0.973) total time=   1.0s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.993, test=0.850) total time=   1.2s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.990, test=0.974) total time=   0.9s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.998, test=0.961) total time=   1.1s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=0.947) total time=   0.8s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.996, test=1.000) total time=   0.8s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.987) total time=   0.7s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.995, test=0.987) total time=   0.8s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.993, test=0.987) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=1.000) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.986) total time=   0.2s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.992, test=0.972) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.990, test=0.987) total time=   0.2s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.839) total time=   0.2s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.996, test=0.973) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.993, test=0.850) total time=   0.2s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.990, test=0.974) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.998, test=0.961) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.996, test=0.947) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.996, test=1.000) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.987) total time=   0.2s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.995, test=0.987) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.994, test=0.987) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.993, test=1.000) total time=   0.9s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.986) total time=   1.0s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.990, test=0.972) total time=   1.1s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.987, test=0.987) total time=   0.8s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.839) total time=   0.8s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.993, test=0.973) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.991, test=0.850) total time=   0.8s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.989, test=0.987) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.993, test=0.961) total time=   0.9s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.996, test=0.947) total time=   0.9s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.996, test=1.000) total time=   1.2s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.995, test=0.987) total time=   1.0s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.997, test=1.000) total time=   1.0s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.996, test=0.974) total time=   0.9s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.985, test=0.987) total time=   0.8s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.866) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.897) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.974) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.931) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.7s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.973) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.866) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.972) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=0.999, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=0.999, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=0.999, test=0.897) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=0.999, test=0.987) total time=   0.1s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=0.999, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.6s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.972) total time=   0.6s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=0.999, test=0.987) total time=   0.6s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.839) total time=   0.6s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=0.999, test=0.986) total time=   0.6s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=0.999, test=0.897) total time=   0.7s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.974) total time=   0.7s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.7s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=0.999, test=0.987) total time=   0.7s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=0.999, test=1.000) total time=   0.8s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.931) total time=   0.8s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.7s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.973) total time=   0.9s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.972) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.986) total time=   0.2s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.986) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.897) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.974) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.931) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.973) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.8s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.972) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.986) total time=   0.8s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.839) total time=   0.8s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.986) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.897) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.974) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.959) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.931) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.987) total time=   0.7s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.973) total time=   0.8s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 9\n",
      "n_resources: 3321\n",
      "Fitting 15 folds for each of 9 candidates, totalling 135 fits\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   1.1s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.977) total time=   1.1s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   1.1s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.982) total time=   1.0s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.861) total time=   1.1s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.964) total time=   1.2s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.928) total time=   1.2s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   1.0s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.974) total time=   1.1s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.991) total time=   1.1s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.982) total time=   1.0s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.991) total time=   1.1s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.605) total time=   1.0s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.816) total time=   1.1s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   1.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.977) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.982) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.861) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.964) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.928) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.974) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.991) total time=   0.2s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.982) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.991) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.605) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.816) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.972) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.981) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.978) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.866) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.938) total time=   0.3s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.965) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.996) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.597) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.641) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   1.0s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.972) total time=   1.0s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.981) total time=   1.1s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.978) total time=   1.0s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.866) total time=   1.0s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.959) total time=   1.0s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.938) total time=   1.1s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   1.0s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.965) total time=   1.1s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.996) total time=   1.0s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   1.1s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   1.1s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.597) total time=   1.0s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.641) total time=   1.0s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   1.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   1.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.968) total time=   1.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   1.4s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.982) total time=   1.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.861) total time=   1.2s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.964) total time=   0.9s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.938) total time=   1.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   1.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.965) total time=   1.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.991) total time=   1.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.995) total time=   1.2s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.991) total time=   1.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.597) total time=   1.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.788) total time=   1.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.982) total time=   1.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.968) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.982) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.861) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.964) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.938) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.965) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.991) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.995) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.991) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.597) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.788) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.982) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   1.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   1.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   1.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   1.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.870) total time=   1.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.964) total time=   1.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.938) total time=   1.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   1.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   1.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.991) total time=   1.5s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.977) total time=   1.2s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.991) total time=   1.2s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.695) total time=   1.2s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.884) total time=   1.2s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   1.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.986) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   0.2s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.870) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.964) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.938) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.991) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.977) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.991) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.695) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.884) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.982) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.990) total time=   1.7s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.973) total time=   1.5s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.998, test=0.986) total time=   1.8s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.978) total time=   1.5s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.866) total time=   2.0s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.955) total time=   1.8s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.933) total time=   1.8s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.991) total time=   1.6s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.998, test=0.961) total time=   1.6s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.991) total time=   1.4s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.982) total time=   1.6s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.991) total time=   1.7s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.597) total time=   1.7s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.566) total time=   1.4s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.999, test=0.964) total time=   1.5s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 9963\n",
      "Fitting 15 folds for each of 3 candidates, totalling 45 fits\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.993) total time=   0.4s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.970) total time=   0.3s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.983) total time=   0.3s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.978) total time=   0.3s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.844) total time=   0.3s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.979) total time=   0.3s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.931) total time=   0.4s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.981) total time=   0.3s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.962) total time=   0.3s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.975) total time=   0.3s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.974) total time=   0.3s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.966) total time=   0.4s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.874) total time=   0.4s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.643) total time=   0.3s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.972) total time=   0.3s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.998) total time=   2.6s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.974) total time=   2.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.973) total time=   2.2s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.981) total time=   2.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.842) total time=   2.3s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.980) total time=   2.3s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.943) total time=   2.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.981) total time=   2.2s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.971) total time=   2.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   2.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.976) total time=   2.3s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.972) total time=   2.5s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.841) total time=   2.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.523) total time=   2.2s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.976) total time=   2.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.998) total time=   0.4s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.974) total time=   0.4s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.973) total time=   0.4s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.981) total time=   0.3s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.842) total time=   0.4s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.980) total time=   0.4s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.943) total time=   0.4s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.981) total time=   0.4s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.971) total time=   0.4s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.987) total time=   0.4s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.976) total time=   0.3s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.972) total time=   0.3s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.841) total time=   0.3s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.523) total time=   0.3s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.976) total time=   0.4s\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 1\n",
      "n_resources: 29889\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.985) total time=   1.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.975) total time=   1.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.964) total time=   1.1s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.984) total time=   1.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.842) total time=   1.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.976) total time=   1.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.952) total time=   0.9s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.977) total time=   0.9s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.971) total time=   1.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.986) total time=   1.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.982) total time=   1.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.975) total time=   1.7s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.600) total time=   1.1s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.543) total time=   1.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.970) total time=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=LeaveOneGroupOut(),\n",
       "                    estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=...\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...),\n",
       "                    param_grid={&#x27;alpha&#x27;: array([0.001     , 0.03162278, 1.        ]),\n",
       "                                &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;, &#x27;dart&#x27;],\n",
       "                                &#x27;eta&#x27;: array([0.001     , 0.03162278, 1.        ]),\n",
       "                                &#x27;lambda&#x27;: array([0.001     , 0.03162278, 1.        ])},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=LeaveOneGroupOut(),\n",
       "                    estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=...\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...),\n",
       "                    param_grid={&#x27;alpha&#x27;: array([0.001     , 0.03162278, 1.        ]),\n",
       "                                &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;, &#x27;dart&#x27;],\n",
       "                                &#x27;eta&#x27;: array([0.001     , 0.03162278, 1.        ]),\n",
       "                                &#x27;lambda&#x27;: array([0.001     , 0.03162278, 1.        ])},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(cv=LeaveOneGroupOut(),\n",
       "                    estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=...\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...),\n",
       "                    param_grid={'alpha': array([0.001     , 0.03162278, 1.        ]),\n",
       "                                'booster': ['gbtree', 'gblinear', 'dart'],\n",
       "                                'eta': array([0.001     , 0.03162278, 1.        ]),\n",
       "                                'lambda': array([0.001     , 0.03162278, 1.        ])},\n",
       "                    random_state=46, scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_xgb = {'booster': ['gbtree', 'gblinear', 'dart'], \n",
    "                  'lambda': np.logspace(-3, 0, 3),\n",
    "                  'alpha': np.logspace(-3, 0, 3),\n",
    "                  'eta': np.logspace(-3, 0, 3)}\n",
    "xgb = XGBClassifier(scale_pos_weight = false/true, objective = 'binary:logistic')\n",
    "xgb_hyperparams = HalvingGridSearchCV(xgb, parameters_xgb, cv = cv, scoring = 'f1_weighted', random_state=46, verbose=3)\n",
    "xgb_hyperparams.fit(X, y, groups = group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e6e9309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.001, 'booster': 'gbtree', 'eta': 1.0, 'lambda': 0.001}\n",
      "0.912165513557384\n"
     ]
    }
   ],
   "source": [
    "print(xgb_hyperparams.best_params_)\n",
    "print(xgb_hyperparams.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee688b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb_hyperparams.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2dc7ea7",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107f0889",
   "metadata": {},
   "source": [
    "###### https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10e16d59",
   "metadata": {},
   "source": [
    "### Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c23914d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exps(X: pd.DataFrame , y: pd.DataFrame, ID: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''\n",
    "        Lightweight script to test many models and find winners\n",
    "        :param X: features\n",
    "        :param y: target\n",
    "        :param ID: grouping variable for LOSO cross-validation\n",
    "        :return: DataFrame of predictions\n",
    "        '''\n",
    "    \n",
    "        dfs = []\n",
    "        models = [\n",
    "               ('LogReg', logreg_hyperparams.best_estimator_), \n",
    "               ('RF', rf_hyperparams.best_estimator_),\n",
    "               ('GNB', gnb_hyperparams.best_estimator_),\n",
    "               ('XGB', xgb_hyperparams.best_estimator_)\n",
    "               ]\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "        target_names = ['no-anxiety', 'anxiety']\n",
    "        for name, model in models:\n",
    "                cv_results = cross_validate(model, X, y, cv=cv, scoring=scoring, groups = ID)\n",
    "                y_pred = cross_val_predict(model, X, y, cv=cv, groups = ID)\n",
    "                print(name)\n",
    "                print(classification_report(y, y_pred, target_names=target_names))\n",
    "                results.append(cv_results)\n",
    "                names.append(name)\n",
    "                this_df = pd.DataFrame(cv_results)\n",
    "                this_df['model'] = name\n",
    "                dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68e17cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  no-anxiety       0.97      0.93      0.95     18765\n",
      "     anxiety       0.90      0.95      0.92     11176\n",
      "\n",
      "    accuracy                           0.94     29941\n",
      "   macro avg       0.93      0.94      0.94     29941\n",
      "weighted avg       0.94      0.94      0.94     29941\n",
      "\n",
      "RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  no-anxiety       0.91      0.95      0.93     18765\n",
      "     anxiety       0.90      0.84      0.87     11176\n",
      "\n",
      "    accuracy                           0.91     29941\n",
      "   macro avg       0.91      0.90      0.90     29941\n",
      "weighted avg       0.91      0.91      0.91     29941\n",
      "\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  no-anxiety       0.84      0.69      0.76     18765\n",
      "     anxiety       0.60      0.79      0.68     11176\n",
      "\n",
      "    accuracy                           0.72     29941\n",
      "   macro avg       0.72      0.74      0.72     29941\n",
      "weighted avg       0.75      0.72      0.73     29941\n",
      "\n",
      "XGB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  no-anxiety       0.91      0.97      0.94     18765\n",
      "     anxiety       0.94      0.84      0.89     11176\n",
      "\n",
      "    accuracy                           0.92     29941\n",
      "   macro avg       0.93      0.91      0.91     29941\n",
      "weighted avg       0.92      0.92      0.92     29941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final = run_exps(X=X, y=y, ID=group)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be06c6d4",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79394ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=10, replace=True, random_state=46)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics\n",
    "\n",
    "## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')\n",
    "\n",
    "## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52c3c529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB3wAAAPxCAYAAAAR49ymAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAADAtklEQVR4nOzdeVxU1f/H8fewzbAoiLtm4FIuuZFmqSmUJmoZamVpmeTyzdQKDZcW11IyxTDT6mumVlqWuZUl5oJbZe6lmaZJfjNz31ABGe7vD39MToCyzjDwej4ePJq5c5bPuXewYT73nGMyDMMQAAAAAAAAAAAAAMDluDk7AAAAAAAAAAAAAABA3pDwBQAAAAAAAAAAAAAXRcIXAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEkfAEAAAAAAAAAAADARZHwBQAAAAAAAAAAAAAXRcIXAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEkfAEAAAAAAAAAAADARZHwBQAAAG7AZDJpzJgxzg4j3z766CPVqVNHnp6eCggIcHY4mSQmJspkMmnOnDm5rpuQkCCTyaSEhITrlhszZoxMJpNOnjyZtyALQU5jL0xZvce3bNmiFi1ayNfXVyaTSTt37rSdP0fLz3ujuIqMjFRwcLCzwwAAAAAAFAEkfAEAAHBDBw8e1NNPP60aNWrIYrGodOnSatmypaZOnarLly87OzzkwK+//qrIyEjVrFlTM2fO1H//+99sy2Yk9dzc3PS///0v0+vnz5+Xt7e3TCaTBg0aVJhhu7zFixerQ4cOKleunLy8vFSlShV169ZNa9ascXZo13XlyhU98sgjOn36tN5880199NFHCgoKKvR+58+fr7i4uELvJzciIyNlMplUunTpLP+9++2332QymWQymTR58uRct3/p0iWNGTPGqQl/AAAAAIBr83B2AAAAACjali9frkceeURms1lPPvmk6tevr9TUVG3cuFFDhw7Vnj17rps8LA4uX74sDw/X/uickJCg9PR0TZ06VbVq1cpRHbPZrE8++UTDhg2zO75o0aLCCLFYMQxDvXv31pw5cxQSEqIhQ4aoUqVKOnr0qBYvXqw2bdpo06ZNatGihbNDlZT5PX7w4EH98ccfmjlzpvr27Ws7/sorr2jEiBGFFsf8+fO1e/duRUVF2R0PCgrS5cuX5enpWWh9X4+Hh4cuXbqkL7/8Ut26dbN7bd68ebJYLEpOTs5T25cuXdLYsWMlSWFhYTmuN3PmTKWnp+epTwAAAABA8eLa31oBAACgUB06dEiPPfaYgoKCtGbNGlWuXNn22sCBA3XgwAEtX77ciREWnvT0dKWmpspischisTg7nHw7fvy4JOVqKeeOHTtmmfCdP3++7r//fn3xxRcFGWKxEhsbqzlz5igqKkpTpkyxWwb55Zdf1kcffVSkbiL493s8u/eLh4eHU+I2mUxO/T00m81q2bKlPvnkk0wJX0f/Ply8eFG+vr5OS34DAAAAAIoelnQGAABAtt544w0lJSVp1qxZdsneDLVq1dLzzz9ve56WlqZXX31VNWvWlNlsVnBwsF566SWlpKTY1QsODtYDDzyghIQENW3aVN7e3mrQoIFtSdNFixapQYMGslgsatKkiXbs2GFXPzIyUn5+fvr9998VHh4uX19fValSRePGjZNhGHZlJ0+erBYtWqhs2bLy9vZWkyZNtHDhwkxjyVieeN68ebrttttkNpu1YsUK22vX7m964cIFRUVFKTg4WGazWRUqVNB9992n7du327X5+eefq0mTJvL29la5cuX0xBNP6MiRI1mO5ciRI+rcubP8/PxUvnx5RUdHy2q1ZnNl7M2YMcMWc5UqVTRw4ECdPXvW7nyPHj1aklS+fPkc70nco0cP7dy5U7/++qvt2N9//601a9aoR48eWdY5fvy4+vTpo4oVK8pisahRo0aaO3dupnJnz55VZGSk/P39FRAQoF69etnFfK1ff/1VDz/8sAIDA2WxWNS0aVMtW7bshvFfz8mTJ9WtWzeVLl1aZcuW1fPPP283QzM0NFSNGjXKsm7t2rUVHh6ebduXL19WTEyM6tSpo8mTJ2e5523Pnj3VrFmzbNvYsGGDHnnkEd18880ym82qVq2aBg8enGlJ4b///ltPPfWUbrrpJpnNZlWuXFkRERFKTEy0ldm6davCw8NVrlw5eXt7q3r16urdu7ddO9e+JyIjIxUaGipJeuSRR2QymWwzT7Pbw/fjjz9Ws2bN5OPjozJlyqh169ZauXKl7fWlS5fq/vvvV5UqVWQ2m1WzZk29+uqrdu/xsLAwLV++XH/88YdtieSMPWqz28N3zZo1atWqlXx9fRUQEKCIiAjt3bvXrkxGzAcOHFBkZKQCAgLk7++vp556SpcuXcr2Gvxbjx499M0339i9T7ds2aLffvst29+Hs2fPKioqStWqVZPZbFatWrU0ceJE28zcxMRElS9fXpI0duxY27ivvRZ+fn46ePCgOnbsqFKlSunxxx+3vfbvPXwzZvFn/PtZvnx5tW/fXlu3bs3xOAEAAAAArqfo3FIOAACAIufLL79UjRo1crzsbN++fTV37lw9/PDDeuGFF7R582bFxMRo7969Wrx4sV3ZAwcOqEePHnr66af1xBNPaPLkyerUqZPeffddvfTSSxowYIAkKSYmRt26ddO+ffvk5vbP/YpWq1Xt27fXXXfdpTfeeEMrVqzQ6NGjlZaWpnHjxtnKTZ06VQ8++KAef/xxpaam6tNPP9Ujjzyir776Svfff79dTGvWrNFnn32mQYMGqVy5cpmSKRn69++vhQsXatCgQapXr55OnTqljRs3au/evbr99tslSXPmzNFTTz2lO+64QzExMTp27JimTp2qTZs2aceOHXYzJ61Wq8LDw3XnnXdq8uTJWrVqlWJjY1WzZk0988wz1z3nY8aM0dixY9W2bVs988wz2rdvn9555x1t2bJFmzZtkqenp+Li4vThhx9q8eLFeuedd+Tn56eGDRve8Hq2bt1aN910k+bPn287pwsWLJCfn1+mcyddTXSGhYXpwIEDGjRokKpXr67PP/9ckZGROnv2rO3mAMMwFBERoY0bN6p///6qW7euFi9erF69emVqc8+ePWrZsqWqVq2qESNGyNfXV5999pk6d+6sL774Ql26dLnhOLLSrVs3BQcHKyYmRj/88IPeeustnTlzRh9++KGkqwnZfv36affu3apfv76t3pYtW7R//3698sor2ba9ceNGnT59WlFRUXJ3d89TfJ9//rkuXbqkZ555RmXLltWPP/6oadOm6c8//9Tnn39uK/fQQw9pz549evbZZxUcHKzjx4/r22+/1eHDh23P27Vrp/Lly2vEiBEKCAhQYmLidZflfvrpp1W1alVNmDBBzz33nO644w5VrFgx2/Jjx47VmDFj1KJFC40bN05eXl7avHmz1qxZo3bt2km6+vvg5+enIUOGyM/PT2vWrNGoUaN0/vx5TZo0SdLVmc/nzp3Tn3/+qTfffFOS5Ofnl22/q1atUocOHVSjRg2NGTNGly9f1rRp09SyZUtt37490+9vt27dVL16dcXExGj79u16//33VaFCBU2cOPGG10OSunbtqv79+2vRokW2hPn8+fNVp04d2+/9tS5duqTQ0FAdOXJETz/9tG6++WZ99913evHFF3X06FHFxcWpfPnyeuedd/TMM8+oS5cu6tq1qyTZ/X6mpaUpPDxcd999tyZPniwfH59sY+zTp4/mzJmjDh06qG/fvkpLS9OGDRv0ww8/qGnTpjkaJwAAAADABRkAAABAFs6dO2dIMiIiInJUfufOnYYko2/fvnbHo6OjDUnGmjVrbMeCgoIMScZ3331nOxYfH29IMry9vY0//vjDdvy9994zJBlr1661HevVq5chyXj22Wdtx9LT043777/f8PLyMk6cOGE7funSJbt4UlNTjfr16xv33nuv3XFJhpubm7Fnz55MY5NkjB492vbc39/fGDhwYLbnIjU11ahQoYJRv3594/Lly7bjX331lSHJGDVqVKaxjBs3zq6NkJAQo0mTJtn2YRiGcfz4ccPLy8to166dYbVabcfffvttQ5LxwQcf2I6NHj3akGR3brJzbdno6GijVq1attfuuOMO46mnnjIM4+p5ufY8xMXFGZKMjz/+2O5cNG/e3PDz8zPOnz9vGIZhLFmyxJBkvPHGG7ZyaWlpRqtWrQxJxuzZs23H27RpYzRo0MBITk62HUtPTzdatGhh3HLLLbZja9euzfQ+ud7YHnzwQbvjAwYMMCQZu3btMgzDMM6ePWtYLBZj+PDhduWee+45w9fX10hKSsq2j6lTpxqSjMWLF183luvF/u/3rWEYRkxMjGEymWy/H2fOnDEkGZMmTcq27cWLFxuSjC1btlw3hn+/xzNi+vzzz+3KZZy/DL/99pvh5uZmdOnSxe49aBhXr9P1xvP0008bPj4+dtf2/vvvN4KCgjKVPXToUKb3RuPGjY0KFSoYp06dsh3btWuX4ebmZjz55JOZYu7du7ddm126dDHKli2bqa9/69Wrl+Hr62sYhmE8/PDDRps2bQzDMAyr1WpUqlTJGDt2rC2+a6/Fq6++avj6+hr79++3a2/EiBGGu7u7cfjwYcMwDOPEiROZzv+1fUsyRowYkeVr156rNWvWGJKM5557LlPZa68FAAAAAKD4YUlnAAAAZOn8+fOSpFKlSuWo/Ndffy1JGjJkiN3xF154QZIy7fVbr149NW/e3Pb8zjvvlCTde++9uvnmmzMd//333zP1OWjQINvjjCWZU1NTtWrVKttxb29v2+MzZ87o3LlzatWqVabll6Wry/jWq1fvBiO9uq/p5s2b9ddff2X5+tatW3X8+HENGDDAbt/R+++/X3Xq1Mly3+P+/fvbPW/VqlWWY77WqlWrlJqaqqioKLvZz/369VPp0qULZH/lHj166MCBA9qyZYvtv9ktX/v111+rUqVK6t69u+2Yp6ennnvuOSUlJWndunW2ch4eHnazl93d3fXss8/atXf69GmtWbNG3bp104ULF3Ty5EmdPHlSp06dUnh4uH777bdMS2Tn1MCBA+2eZ/Sd8T729/dXRESEPvnkE9sy4VarVQsWLFDnzp3l6+ubbdu5/d3JyrXv24sXL+rkyZNq0aKFDMOwLXHu7e0tLy8vJSQk6MyZM1m2kzGT/KuvvtKVK1fyHE92lixZovT0dI0aNcruPSjJbunna8eTcS1btWqlS5cu2S0ZnlNHjx7Vzp07FRkZqcDAQNvxhg0b6r777rNdx2tl9Tt26tQp2/XKiR49eighIcG2tPnff/+d7e/D559/rlatWqlMmTK29+7JkyfVtm1bWa1WrV+/Psf93mimvyR98cUXMplMtuXbr5XVMtwAAAAAgOKDhC8AAACyVLp0aUlXkzM58ccff8jNzU21atWyO16pUiUFBATojz/+sDt+bVJXuppgk6Rq1aplefzfCS03NzfVqFHD7titt94qSXb7l3711Ve66667ZLFYFBgYaFtC9dy5c5nGUL169RsNU9LVvY13796tatWqqVmzZhozZoxdcjZjrLVr185Ut06dOpnORcZem9cqU6ZMtkm8G/Xj5eWlGjVqZOonL0JCQlSnTh3Nnz9f8+bNU6VKlXTvvfdmG88tt9ySKfFXt25du3j/+OMPVa5cOdNyvf8ex4EDB2QYhkaOHKny5cvb/WQktY4fP56ncd1yyy12z2vWrCk3Nze7986TTz6pw4cPa8OGDZKuJtiPHTumnj17Xrft3P7uZOXw4cO2ZGbGvs4Z++pmvHfNZrMmTpyob775RhUrVlTr1q31xhtv6O+//7a1Exoaqoceekhjx45VuXLlFBERodmzZ2faVzuvDh48KDc3txveKLFnzx516dJF/v7+Kl26tMqXL68nnnjCbjy5cb3fsbp16+rkyZO6ePGi3fF//5tTpkwZSZn/bbmejH10FyxYoHnz5umOO+7I9G9eht9++00rVqzI9N5t27atpJy/dz08PHTTTTfdsNzBgwdVpUoVuwQ4AAAAAKBkYA9fAAAAZKl06dKqUqWKdu/enat6OZ1Jlt3eptkdz5hlmRsbNmzQgw8+qNatW2vGjBmqXLmyPD09NXv2bM2fPz9T+WtnIV5Pt27d1KpVKy1evFgrV67UpEmTNHHiRC1atEgdOnTIdZx53efVUXr06KF33nlHpUqV0qOPPpopoVtY0tPTJUnR0dEKDw/Pskx2ybbcyup9Gx4erooVK+rjjz9W69at9fHHH6tSpUq2hF126tSpI0n6+eef1blz51zHYrVadd999+n06dMaPny46tSpI19fXx05ckSRkZG28yJJUVFR6tSpk5YsWaL4+HiNHDlSMTExWrNmjUJCQmQymbRw4UL98MMP+vLLLxUfH6/evXsrNjZWP/zww3X3yC0oZ8+eVWhoqEqXLq1x48apZs2aslgs2r59u4YPH243nsJUEP+2mM1mde3aVXPnztXvv/+uMWPGZFs2PT1d9913n4YNG5bl6xk3qOSkT0f9zgEAAAAAXBN/NQIAACBbDzzwgA4ePKjvv//+hmWDgoKUnp6u3377ze74sWPHdPbsWQUFBRVobOnp6ZmWPN6/f78kKTg4WNLVJU4tFostydWhQ4cbJutyqnLlyhowYICWLFmiQ4cOqWzZsho/frwk2ca6b9++TPX27dtXYOciu35SU1N16NChAuunR48eOnr0qPbv35/t8rUZ8fz222+ZEngZS/ZmxBMUFKSjR48qKSnJrty/x5Exg9vT01Nt27bN8ievyyb/+3164MABpaen29470tUEYY8ePbRw4UKdOXNGS5YsUffu3W+YoL/77rtVpkwZffLJJ7JarbmO7eeff9b+/fsVGxur4cOHKyIiQm3btlWVKlWyLF+zZk298MILWrlypXbv3q3U1FTFxsbalbnrrrs0fvx4bd26VfPmzdOePXv06aef5jq2rPpOT0/XL7/8km2ZhIQEnTp1SnPmzNHzzz+vBx54QG3btrXNsL1WTm8Yud7v2K+//qpy5cpdd9nt/OjRo4d27NihCxcu6LHHHsu2XM2aNZWUlJTtezdjxnFBLbdcs2ZN/fXXXzp9+nSBtAcAAAAAcB0kfAEAAJCtYcOGydfXV3379tWxY8cyvX7w4EFNnTpV0tWlTiUpLi7OrsyUKVMkXd2/tqC9/fbbtseGYejtt9+Wp6en2rRpI+lqws5kMtkl3RITE7VkyZI892m1WjMtQVuhQgVVqVLFtkxu06ZNVaFCBb377rt2S+d+88032rt3b4Gdi7Zt28rLy0tvvfWW3SzFWbNm6dy5cwXWT82aNRUXF6eYmBg1a9Ys23IdO3bU33//rQULFtiOpaWladq0afLz87MtSdyxY0elpaXpnXfesZWzWq2aNm2aXXsVKlRQWFiY3nvvPR09ejRTfydOnMjzmKZPn273PKPvf8/Q7tmzp86cOaOnn35aSUlJtmWIr8fHx0fDhw/X3r17NXz48CxnkH788cf68ccfs6yfkVC+tp5hGLbftQyXLl1ScnKy3bGaNWuqVKlStvfdmTNnMvXfuHFjSSqQZZ07d+4sNzc3jRs3LlOiP6PfrMaTmpqqGTNmZGrP19c3R0s8V65cWY0bN9bcuXN19uxZ2/Hdu3dr5cqVtn+PCsM999yjV199VW+//bYqVaqUbblu3brp+++/V3x8fKbXzp49q7S0NElX3y8Zx/LjoYcekmEYGjt2bKbX8rJCAgAAAADAdbCkMwAAALJVs2ZNzZ8/X48++qjq1q2rJ598UvXr11dqaqq+++47ff7554qMjJQkNWrUSL169dJ///tf2xKuP/74o+bOnavOnTvrnnvuKdDYLBaLVqxYoV69eunOO+/UN998o+XLl+ull16y7Yd7//33a8qUKWrfvr169Oih48ePa/r06apVq5Z++umnPPV74cIF3XTTTXr44YfVqFEj+fn5adWqVdqyZYttVqWnp6cmTpyop556SqGhoerevbuOHTumqVOnKjg4WIMHDy6Qc1C+fHm9+OKLGjt2rNq3b68HH3xQ+/bt04wZM3THHXfkKDmZU88///wNy/znP//Re++9p8jISG3btk3BwcFauHChNm3apLi4ONts3E6dOqlly5YaMWKEEhMTVa9ePS1atCjLRN/06dN19913q0GDBurXr59q1KihY8eO6fvvv9eff/6pXbt25Wk8hw4d0oMPPqj27dvr+++/18cff6wePXqoUaNGduVCQkJUv359ff7556pbt65uv/32HLU/dOhQ7dmzR7GxsVq7dq0efvhhVapUSX///beWLFmiH3/8Ud99912WdevUqaOaNWsqOjpaR44cUenSpfXFF19k2mt2//79atOmjbp166Z69erJw8NDixcv1rFjx2wzT+fOnasZM2aoS5cuqlmzpi5cuKCZM2eqdOnSBZIUrVWrll5++WW9+uqratWqlbp27Sqz2awtW7aoSpUqiomJUYsWLVSmTBn16tVLzz33nEwmkz766KMsk5BNmjTRggULNGTIEN1xxx3y8/NTp06dsux70qRJ6tChg5o3b64+ffro8uXLmjZtmvz9/a+71HJ+ubm56ZVXXrlhuaFDh2rZsmV64IEHFBkZqSZNmujixYv6+eeftXDhQiUmJqpcuXLy9vZWvXr1tGDBAt16660KDAxU/fr1Vb9+/VzFdc8996hnz55666239Ntvv6l9+/ZKT0/Xhg0bdM8992jQoEF5HTIAAAAAoIgj4QsAAIDrevDBB/XTTz9p0qRJWrp0qd555x2ZzWY1bNhQsbGx6tevn63s+++/rxo1amjOnDlavHixKlWqpBdffFGjR48u8Ljc3d21YsUKPfPMMxo6dKhKlSql0aNHa9SoUbYy9957r2bNmqXXX39dUVFRql69uiZOnKjExMQ8J3x9fHw0YMAArVy5UosWLVJ6erpq1aqlGTNm6JlnnrGVi4yMlI+Pj15//XUNHz5cvr6+6tKliyZOnKiAgID8Dt9mzJgxKl++vN5++20NHjxYgYGB+s9//qMJEybI09OzwPrJCW9vbyUkJGjEiBGaO3euzp8/r9q1a2v27Nm2GwOkqwmzZcuWKSoqSh9//LFMJpMefPBBxcbGKiQkxK7NevXqaevWrRo7dqzmzJmjU6dOqUKFCgoJCbG71rm1YMECjRo1SiNGjJCHh4cGDRqkSZMmZVn2ySef1LBhw9SzZ88ct+/m5qYPP/xQERER+u9//6vJkyfr/PnzKl++vFq3bq033nhDzZs3z7Kup6envvzySz333HOKiYmRxWJRly5dNGjQILuEdLVq1dS9e3etXr1aH330kTw8PFSnTh199tlneuihhyTJduPFp59+qmPHjsnf31/NmjXTvHnzVL169VycseyNGzdO1atX17Rp0/Tyyy/Lx8dHDRs2tJ2vsmXL6quvvtILL7ygV155RWXKlNETTzyhNm3aZNqbecCAAdq5c6dmz56tN998U0FBQdkmfNu2basVK1bYfu89PT0VGhqqiRMnFtjY8sPHx0fr1q3ThAkT9Pnnn+vDDz9U6dKldeutt2rs2LHy9/e3lX3//ff17LPPavDgwUpNTdXo0aNznfCVpNmzZ6thw4aaNWuWhg4dKn9/fzVt2lQtWrQoyKEBAAAAAIoYk8HaTgAAAHAxkZGRWrhwYaY9YIHCMHXqVA0ePFiJiYm2fVcBAAAAAACKCvbwBQAAAIBsGIahWbNmKTQ0lGQvAAAAAAAokljSGQAAAAD+5eLFi1q2bJnWrl2rn3/+WUuXLnV2SAAAAAAAAFki4QsAAAAA/3LixAn16NFDAQEBeumll/Tggw86OyQAAAAAAIAssYcvAAAAAAAAAAAAALgo9vAFAAAAAAAAAAAAABdFwhcAAAAAAAAAAAAAXFSJ28M3PT1df/31l0qVKiWTyeTscAAAAAAAAAAAgBMZhqELFy6oSpUqcnNjnlxeWK1WXblyxdlhAMWKl5dXjv9NKnEJ37/++kvVqlVzdhgAAAAAAAAAAKAI+d///qebbrrJ2WG4FMMw9Pfff+vs2bPODgUodtzc3FS9enV5eXndsGyJS/iWKlVK0tV/uEuXLu3kaAAAAAAAAAAAgDOdP39e1apVs+UPkHMZyd4KFSrIx8eHlVWBApKxYvHRo0d188033/B3q8QlfDNOSOnSpUn4AgAAAAAAAAAASSJZmUtWq9WW7C1btqyzwwGKnfLly+uvv/5SWlqaPD09r1uWxegBAAAAAAAAAACQKxl79vr4+Dg5EqB4yljK2Wq13rAsCV8AAAAAAAAAAADkCTOjgcKRm98tEr4AAAAAAAAAAAAA4KJK3B6+AAAAAAAAAAAAKBxWq1WGYTisP5PJJHd3d4f1BxRFJHwBAAAAAAAAAACQb1arVV26PqyzZ045rM+AMmW1eNHCXCV9w8LC1LhxY8XFxRVIDJGRkTp79qyWLFlSIO0BuUXCFwAAAAAAAAAAAPlmGIbOnjmli00jJZMDdhU10qWtcxw6o7iwXLlyRZ6ens4OAy6KPXwBAAAAAAAAAABQcExukpsDfvKQVI6MjNS6des0depUmUwmmUwmJSYmavfu3erQoYP8/PxUsWJF9ezZUydPnrTVW7hwoRo0aCBvb2+VLVtWbdu21cWLFzVmzBjNnTtXS5cutbWXkJBw3RgSExNlMpm0YMEChYaGymKxaN68eUpPT9e4ceN00003yWw2q3HjxlqxYoVd3T///FPdu3dXYGCgfH191bRpU23evPmG4z548KAiIiJUsWJF+fn56Y477tCqVavsyphMpkyzlAMCAjRnzpx894/CxQxfAAAAAAAAAAAAlAhTp07V/v37Vb9+fY0bN06S5OnpqWbNmqlv37568803dfnyZQ0fPlzdunXTmjVrdPToUXXv3l1vvPGGunTpogsXLmjDhg0yDEPR0dHau3evzp8/r9mzZ0uSAgMDcxTLiBEjFBsbq5CQEFksFk2dOlWxsbF67733FBISog8++EAPPvig9uzZo1tuuUVJSUkKDQ1V1apVtWzZMlWqVEnbt29Xenr6DftKSkpSx44dNX78eJnNZn344Yfq1KmT9u3bp5tvvjlH8eanfxQuEr4AAAAAAAAAAAAoEfz9/eXl5SUfHx9VqlRJkvTaa68pJCREEyZMsJX74IMPVK1aNe3fv19JSUlKS0tT165dFRQUJElq0KCBray3t7dSUlJs7eVUVFSUunbtans+efJkDR8+XI899pgkaeLEiVq7dq3i4uI0ffp0zZ8/XydOnNCWLVtsSeVatWrlqK9GjRqpUaNGtuevvvqqFi9erGXLlmnQoEE5aiM//aNwsaQzAAAAAAAAAAAASqxdu3Zp7dq18vPzs/3UqVNH0tWlkBs1aqQ2bdqoQYMGeuSRRzRz5kydOXMm3/02bdrU9vj8+fP666+/1LJlS7syLVu21N69eyVJO3fuVEhISI5nEF8rKSlJ0dHRqlu3rgICAuTn56e9e/fq8OHDOW4jP/2jcDHDFwAAAAAAAAAAACVWUlKSOnXqpIkTJ2Z6rXLlynJ3d9e3336r7777TitXrtS0adP08ssva/PmzapevXqe+/X19c1VeW9v7zz3FR0drW+//VaTJ09WrVq15O3trYcfflipqam2MiaTSYZh2NW7cuVKgfSPwsUMXwAAAAAAAAAAAJQYXl5eslqttue333679uzZo+DgYNWqVcvuJyMpazKZ1LJlS40dO1Y7duyQl5eXFi9enGV7eVG6dGlVqVJFmzZtsju+adMm1atXT5LUsGFD7dy5U6dPn851+5s2bVJkZKS6dOmiBg0aqFKlSkpMTLQrU758eR09etT2/LffftOlS5dsz/PTPwoXCV8AAAAAAAAAAAAUHCNdSnfAj5Gep/CCg4O1efNmJSYm6uTJkxo4cKBOnz6t7t27a8uWLTp48KDi4+P11FNPyWq1avPmzZowYYK2bt2qw4cPa9GiRTpx4oTq1q1ra++nn37Svn37dPLkSbtZsbkxdOhQTZw4UQsWLNC+ffs0YsQI7dy5U88//7wkqXv37qpUqZI6d+6sTZs26ffff9cXX3yh77///oZt33LLLVq0aJF27typXbt2qUePHkpPtz9/9957r95++23t2LFDW7duVf/+/eXp6Wl7PT/9o3CxpDMAAAAAAAAAAADyzWQyKaBMWWnrHIf1GVCmrEwmU67qREdHq1evXqpXr54uX76sQ4cOadOmTRo+fLjatWunlJQUBQUFqX379nJzc1Pp0qW1fv16xcXF6fz58woKClJsbKw6dOggSerXr58SEhLUtGlTJSUlae3atQoLC8v1WJ577jmdO3dOL7zwgo4fP6569epp2bJluuWWWyRdnUm8cuVKvfDCC+rYsaPS0tJUr149TZ8+/YZtT5kyRb1791aLFi1Urlw5DR8+XOfPn7crExsbq6eeekqtWrVSlSpVNHXqVG3bts32en76R+EyGf9ejLuYO3/+vPz9/XXu3DmVLl3a2eEAAAAAAAAAAAAnIm+QN8nJyTp06JCqV68ui8ViO261WjPtA1uYTCaT3N3dHdYf4CjZ/Y5lhRm+AAAAAAAAAAAAKBAkXwHHYw9fAAAAAAAAAAAAoIBMmDBBfn5+Wf5kLANd0G677bZs+5w3b16h9Imigxm+AAAAAAAAAAAAQAHp37+/unXrluVr3t7ehdLn119/rStXrmT5WsWKFQulTxQdJHwBAAAAAAAAAACAAhIYGKjAwECH9hkUFOTQ/lC0sKQzAAAAAAAAAAAAALgoEr4AAAAAAAAAAAAA4KJI+AIAAAAAAAAAAACAiyLhCwAAAAAAAAAAAAAuioQvAAAAAAAAAAAAALgoEr4AAAAAAAAAAAAoEFarVWlpaQ77sVqtzh6yS4mMjFTnzp0LvGxRlJf4g4ODFRcXVyjx/FtiYqJMJpN27tyZ77Y88h8OAAAAAAAAAAAASjqr1apHHuqsk6fPOazPcoH++vyLJXJ3d89xnbCwMDVu3LjAEnuRkZE6e/aslixZUiDtFaapU6fKMIwCL1sUFUb8iYmJql69unbs2KHGjRsXaNv5QcIXAAAAAAAAAAAA+WYYhk6ePqdZ95yRu6nw+7MaUp+1cumkZE4ZhiGr1SoPj/yl9vz9/QulbFHk6vHnBks6AwAAAAAAAAAAoMC4myQPt8L/yUtSOTIyUuvWrdPUqVNlMplkMpmUmJio3bt3q0OHDvLz81PFihXVs2dPnTx50lZv4cKFatCggby9vVW2bFm1bdtWFy9e1JgxYzR37lwtXbrU1l5CQsJ1Y8hYyvfTTz9VixYtZLFYVL9+fa1bt85WJiEhQSaTSd98842aNGkis9msjRs3Kj09XTExMapevbq8vb3VqFEjLVy40K79PXv26IEHHlDp0qVVqlQptWrVSgcPHrSN/9pljrMbV1ZlU1JS9Nxzz6lChQqyWCy6++67tWXLlkwxr169Wk2bNpWPj49atGihffv23fC6nDt3Tu7u7tq6daskKT09XYGBgbrrrrtsZT7++GNVq1bN9vx///ufunXrpoCAAAUGBioiIkKJiYm21/8d/4ULF/T444/L19dXlStX1ptvvqmwsDBFRUXZxXLp0iX17t1bpUqV0s0336z//ve/tteqV68uSQoJCZHJZFJYWJjttffff19169aVxWJRnTp1NGPGDLt2f/zxR4WEhMhisahp06basWPHDc9LTpHwBQAAAAAAAAAAQIkwdepUNW/eXP369dPRo0d19OhRlSpVSvfee69CQkK0detWrVixQseOHVO3bt0kSUePHlX37t3Vu3dv7d27VwkJCeratasMw1B0dLS6deum9u3b29pr0aJFjmIZOnSoXnjhBe3YsUPNmzdXp06ddOrUKbsyI0aM0Ouvv669e/eqYcOGiomJ0Ycffqh3331Xe/bs0eDBg/XEE0/YksVHjhxR69atZTabtWbNGm3btk29e/dWWlpapv6vN66sDBs2TF988YXmzp2r7du3q1atWgoPD9fp06ftyr388suKjY3V1q1b5eHhod69e9/wXPj7+6tx48a2ZPnPP/8sk8mkHTt2KCkpSZK0bt06hYaGSpKuXLmi8PBwlSpVShs2bNCmTZvk5+en9u3bKzU1Ncs+hgwZok2bNmnZsmX69ttvtWHDBm3fvj1TudjYWFtCdsCAAXrmmWdsSesff/xRkrRq1SodPXpUixYtkiTNmzdPo0aN0vjx47V3715NmDBBI0eO1Ny5cyVJSUlJeuCBB1SvXj1t27ZNY8aMUXR09A3PS06xpDMAAAAAAAAAAABKBH9/f3l5ecnHx0eVKlWSJL322msKCQnRhAkTbOU++OADVatWTfv371dSUpLS0tLUtWtXBQUFSZIaNGhgK+vt7a2UlBRbezk1aNAgPfTQQ5Kkd955RytWrNCsWbM0bNgwW5lx48bpvvvuk3R1hu2ECRO0atUqNW/eXJJUo0YNbdy4Ue+9955CQ0M1ffp0+fv769NPP5Wnp6ck6dZbb82y/6NHj153XNe6ePGi3nnnHc2ZM0cdOnSQJM2cOVPffvutZs2apaFDh9rKjh8/3paYHTFihO6//34lJyfLYrFc93yEhYUpISFB0dHRSkhI0H333adff/1VGzduVPv27ZWQkGA7NwsWLFB6erref/99mUxXp3rPnj1bAQEBSkhIULt27ezavnDhgubOnav58+erTZs2tvJVqlTJFEfHjh01YMAASdLw4cP15ptvau3atapdu7bKly8vSSpbtqzd9R49erRiY2PVtWtXSVdnAv/yyy9677331KtXL82fP1/p6emaNWuWLBaLbrvtNv3555965plnrntOcoqELwAAAAAAAAAAAEqsXbt2ae3atfLz88v02sGDB9WuXTu1adNGDRo0UHh4uNq1a6eHH35YZcqUyVe/GUlbSfLw8FDTpk21d+9euzJNmza1PT5w4IAuXbpkSwBnSE1NVUhIiCRp586datWqlS3Zez2NGjXK8bgOHjyoK1euqGXLlrZjnp6eatasWaaYGzZsaHtcuXJlSdLx48d18803Xzee0NBQzZo1S1arVevWrVO7du1UqVIlJSQkqGHDhjpw4IBtCeVdu3bpwIEDKlWqlF0bycnJtuWrr/X777/rypUratasme2Yv7+/ateunanstfGbTCZVqlRJx48fzzbuixcv6uDBg+rTp4/69etnO56WlmbbRzhjhva1Se9rr39+kfAFAAAAAAAAAABAiZWUlKROnTpp4sSJmV6rXLmy3N3d9e233+q7777TypUrNW3aNL388svavHmzbU/XwuLr62sXpyQtX75cVatWtStnNpslXZ1tnFOFNa5rk80Zs2/T09NvWK9169a6cOGCtm/frvXr12vChAmqVKmSXn/9dTVq1EhVqlTRLbfcIunquWjSpInmzZuXqZ2MWbgFEX/GGK4Xf8Z1mTlzpu68806719zd3fMVS06xhy8AAAAAAAAAAABKDC8vL1mtVtvz22+/XXv27FFwcLBq1apl95ORcDWZTGrZsqXGjh2rHTt2yMvLS4sXL86yvZz64YcfbI/T0tK0bds21a1bN9vy9erVk9ls1uHDhzPFWa1aNUlXZ6du2LBBV65cyVEM1xvXtWrWrCkvLy9t2rTJduzKlSvasmWL6tWrl9MhX1dAQIAaNmyot99+W56enqpTp45at26tHTt26KuvvrItEy1dvWa//fabKlSokOlcZMyqvVaNGjXk6empLVu22I6dO3dO+/fvz1WMXl5ekmR3vStWrKgqVaro999/zxRLRuK8bt26+umnn5ScnGyrd+31zy8SvgAAAAAAAAAAACgwVkNKSy/8H6uRt/iCg4O1efNmJSYm6uTJkxo4cKBOnz6t7t27a8uWLTp48KDi4+P11FNPyWq1avPmzZowYYK2bt2qw4cPa9GiRTpx4oQtORscHKyffvpJ+/bt08mTJ3OcbJ0+fboWL16sX3/9VQMHDtSZM2fUu3fvbMuXKlVK0dHRGjx4sObOnauDBw9q+/btmjZtmubOnSvp6r7A58+f12OPPaatW7fqt99+00cffaR9+/Zlau9G47qWr6+vnnnmGQ0dOlQrVqzQL7/8on79+unSpUvq06dPjsabE2FhYZo3b54tuRsYGKi6detqwYIFdgnfxx9/XOXKlVNERIQ2bNigQ4cOKSEhQc8995z+/PPPTO2WKlVKvXr10tChQ7V27Vrt2bNHffr0kZubm20Wck5UqFBB3t7eWrFihY4dO6Zz585JksaOHauYmBi99dZb2r9/v37++WfNnj1bU6ZMkST16NFDJpNJ/fr10y+//KKvv/5akydPzs+pssOSzgAAAAAAAAAAAMg3k8mkcoH+6rPWcX2WC/TPVcJOkqKjo9WrVy/Vq1dPly9f1qFDh7Rp0yYNHz5c7dq1U0pKioKCgtS+fXu5ubmpdOnSWr9+veLi4nT+/HkFBQUpNjZWHTp0kCT169dPCQkJatq0qZKSkrR27VrbXrPX8/rrr+v111/Xzp07VatWLS1btkzlypW7bp1XX31V5cuXV0xMjH7//XcFBATo9ttv10svvSRJKlu2rNasWaOhQ4cqNDRU7u7uaty4sd3euxluNK6s4k1PT1fPnj114cIFNW3aVPHx8fney/haoaGhiouLszt/YWFh2rVrl90xHx8frV+/XsOHD1fXrl114cIFVa1aVW3atFHp0qWzbHvKlCnq37+/HnjgAZUuXVrDhg3T//73P7t9dW/Ew8NDb731lsaNG6dRo0apVatWSkhIUN++feXj46NJkyZp6NCh8vX1VYMGDRQVFSVJ8vPz05dffqn+/fsrJCRE9erV08SJE/XQQw/l5TRlYjIMI4/3P+Tf+vXrNWnSJG3btk1Hjx7V4sWL1blz5+vWSUhI0JAhQ7Rnzx5Vq1ZNr7zyiiIjI3Pc5/nz5+Xv769z585le8EBAAAAAAAAAEDJQN4gb5KTk3Xo0CFVr17dLmFmtVrlyNSTyWRy2D6pBSUxMVHVq1fXjh071LhxY2eHU2JdvHhRVatWVWxsbIHOUi4o2f2OZcWpM3wvXryoRo0aqXfv3uratesNyx86dEj333+/+vfvr3nz5mn16tXq27evKleurPDwcAdEDAAAAAAAAAAAgOy4WvIVJceOHTv066+/qlmzZjp37pzGjRsnSYqIiHByZPnn1IRvhw4dsp0WnpV3331X1atXV2xsrKSrGxxv3LhRb775ZolP+BqGYbfRc27rpqSkSJLMZnOulz7IYLFY8lwXAAAAQMHgbwMAQH7+X5BRn/8fAACQdxMmTNCECROyfK1Vq1Z65513HBxR0XDbbbfpjz/+yPK19957T48//nihxzB58mTt27dPXl5eatKkiTZs2HDDZbRdgUvt4fv999+rbdu2dsfCw8Nt619nJSUlxfYBVbq6NENxlJyc7PSkd3x8vLy9vZ0aAwAAAFAc5OeL+uTkZKffnbx06dJc7YF0LZIDAJB/ReF7Isnx3xWV1EQ34857fcbtOuMGXE3//v3VrVu3LF/z9vZW1apVHbrsdVHx9ddf68qVK1m+VrFixULvPyQkRNu2bSv0fpzBpRK+f//9d6YLXrFiRZ0/f16XL1/O8gNkTEyMxo4d66gQAQAAACDfisoX9XmVn4QzN5ICAPKqqPz/09H/L2PczsW4AWQlMDBQgYGBzg6jyAkKCnJ2CMWWSyV88+LFF1/UkCFDbM/Pnz+vatWqOTGi7OV36bWlS5fmqW5ycrIeffRRSdKCBQvyfCe+YRi6fPlynupyRxgAAADwj5J4p3eGkjx2ACgoFotF8fHxea5/7WoR+V21AQAAAIXPpRK+lSpV0rFjx+yOHTt2TKVLl872biKz2Syz2eyI8PKtKNydlZH4dTTuCAMAAAD+ce22NCVNSkqKfHx8nB0GADhdfpdtLQryE39eJgeU1EQ3484bxu1a4wYAXJ9LJXybN2+ur7/+2u7Yt99+q+bNmzspIgAAAAAAAKDgFYWJAVL+lunPj7xMDjCZTAU2ocBisbjM5ATGnX+MGwDg6pya8E1KStKBAwdszw8dOqSdO3cqMDBQN998s1588UUdOXJEH374oaSrm1y//fbbGjZsmHr37q01a9bos88+0/Lly501hEJz8fbHJTcHXR7DkNLTrj5285ActbRyepp8t89zTF8AAACAC7l2laKLIT0kd08nRuMA1ivy3TFfklxmhSYAAAAAAIoKpyZ8t27dqnvuucf2PGOv3V69emnOnDk6evSoDh8+bHu9evXqWr58uQYPHqypU6fqpptu0vvvv18k7nYscG4eDv5Sx8uBfQEAAAC4HrslLN09i3/C9xq5Xb4TAEoCh04MkJgcAAAA4GKcmvANCwuTYRjZvj5nzpws6+zYsaMQowIAAAAAAACKEIdPDJCYHAAAyCur1Xrd3E9BM5lMcnd3d1h/BSExMVHVq1fXjh071Lhx4zy3ExkZqbNnz2rJkiUFFlthSEhI0D333KMzZ84oICDA2eEUSy61hy8AAAAAAAAAAACKJqvVqi4PddHZ02cd1mdAYIAWf7E4V0nfsLAwNW7cWHFxcQUSg6skXlF8kfAFAAAAAAAAAABAvhmGobOnz8raxSq5OaDDdOns4rMOnVGMkic1NVVeXkV79RNH/LoBAAAAAAAAAACgpHBz4E8uRUZGat26dZo6dapMJpNMJpMSExO1e/dudejQQX5+fqpYsaJ69uypkydP2uotXLhQDRo0kLe3t8qWLau2bdvq4sWLGjNmjObOnaulS5fa2ktISMhRLL/++qtatGghi8Wi+vXra926dbbXrFar+vTpo+rVq8vb21u1a9fW1KlTr9veihUrdPfddysgIEBly5bVAw88oIMHD9peT0xMlMlk0qJFi3TPPffIx8dHjRo10vfff2/XzqZNmxQWFiYfHx+VKVNG4eHhOnPmjCQpPT1dMTExtrgaNWqkhQsX2tX/+uuvdeutt8rb21v33HOPEhMTc3Q+JOnUqVPq3r27qlatKh8fHzVo0ECffPKJXZn09HS98cYbqlWrlsxms26++WaNHz/e9vqff/6p7t27KzAwUL6+vmratKk2b94s6er179y5s117UVFRCgsLsz0PCwvToEGDFBUVpXLlyik8PFySNGXKFDVo0EC+vr6qVq2aBgwYoKSkpByduw8//FBly5ZVSkqKXfnOnTurZ8+eOT4/2SHhCwAAAAAAAAAAgBJh6tSpat68ufr166ejR4/q6NGjKlWqlO69916FhIRo69atWrFihY4dO6Zu3bpJko4eParu3burd+/e2rt3rxISEtS1a1cZhqHo6Gh169ZN7du3t7XXokWLHMUydOhQvfDCC9qxY4eaN2+uTp066dSpU5KuJjVvuukmff755/rll180atQovfTSS/rss8+ybe/ixYsaMmSItm7dqtWrV8vNzU1dunRRenq6XbmXX35Z0dHR2rlzp2699VZ1795daWlpkqSdO3eqTZs2qlevnr7//ntt3LhRnTp1ktVqlSTFxMToww8/1Lvvvqs9e/Zo8ODBeuKJJ2zJ6v/973/q2rWrOnXqpJ07d6pv374aMWJEjq9PcnKymjRpouXLl2v37t36z3/+o549e+rHH3+0lXnxxRf1+uuva+TIkfrll180f/58VaxYUZKUlJSk0NBQHTlyRMuWLdOuXbs0bNiwTOfgRubOnSsvLy9t2rRJ7777riTJzc1Nb731lvbs2aO5c+dqzZo1GjZsmK3O9c7dI488IqvVqmXLltnKHz9+XMuXL1fv3r1zFVtWWNIZAAAAAAAAKGLslqa0XnFeII50zThZmhMAUFj8/f3l5eUlHx8fVapUSZL02muvKSQkRBMmTLCV++CDD1StWjXt379fSUlJSktLU9euXRUUFCRJatCgga2st7e3UlJSbO3l1KBBg/TQQw9Jkt555x2tWLFCs2bN0rBhw+Tp6amxY8faylavXl3ff/+9PvvsM1si+t8y2rp2DOXLl9cvv/yi+vXr245HR0fr/vvvlySNHTtWt912mw4cOKA6derojTfeUNOmTTVjxgxb+dtuu02SlJKSogkTJmjVqlVq3ry5JKlGjRrauHGj3nvvPYWGhuqdd95RzZo1FRsbK0mqXbu2fv75Z02cODFH56Rq1aqKjo62PX/22WcVHx+vzz77TM2aNdOFCxc0depUvf322+rVq5ckqWbNmrr77rslSfPnz9eJEye0ZcsWBQYGSpJq1aqVo76vdcstt+iNN96wOxYVFWV7HBwcrNdee039+/e3navrnTtJ6tGjh2bPnq1HHnlEkvTxxx/r5ptvtptdnFckfAEAAAAALs8wDCUnJ+e5bsayWmazWSaTKU/tWCyWPNdF7pTU611Sx11SXbvcn++O+U6MxDlSUlLk4+Pj7DAAACXErl27tHbtWvn5+WV67eDBg2rXrp3atGmjBg0aKDw8XO3atdPDDz+sMmXK5KvfjKSpJHl4eKhp06bau3ev7dj06dP1wQcf6PDhw7p8+bJSU1PVuHHjbNv77bffNGrUKG3evFknT560zWo9fPiwXcK3YcOGtseVK1eWdHW2aZ06dbRz505bQvLfDhw4oEuXLum+++6zO56amqqQkBBJ0t69e3XnnXdmO84bsVqtmjBhgj777DMdOXJEqampdp8L9u7dq5SUFLVp0ybL+jt37lRISIgt2ZtXTZo0yXRs1apViomJ0a+//qrz588rLS1NycnJunTpknx8fK577iSpX79+uuOOO3TkyBFVrVpVc+bMUWRkZIF8vibhW4SUuDs3uWszz/gjHwAAALCXnJxs21fJWeLj4+Xt7e3UGEqKknq9S+q4AQAACltSUpI6deqU5SzUypUry93dXd9++62+++47rVy5UtOmTdPLL7+szZs3q3r16oUS06effqro6GjFxsaqefPmKlWqlCZNmmTbizYrnTp1UlBQkGbOnKkqVaooPT1d9evXV2pqql05T09P2+OM7/kzksPX+6yXsV/t8uXLVbVqVbvXzGZz7gaYjUmTJmnq1KmKi4uz7ZcbFRVlG8ONPove6HU3N7dMOakrVzLn5Hx9fe2eJyYm6oEHHtAzzzyj8ePHKzAwUBs3blSfPn2UmpoqHx+fG/YdEhKiRo0a6cMPP1S7du20Z88eLV++/Lp1coqEbxFSku/c5K7N3OGPfAAAAAASN4MCxdm1X5peDOkhuXtep3QxYb1i+06soL40BgAgK15eXrY9aSXp9ttv1xdffKHg4GB5eGSdOjOZTGrZsqVatmypUaNGKSgoSIsXL9aQIUMytZdTP/zwg1q3bi1JSktL07Zt2zRo0CBJ0qZNm9SiRQsNGDDAVv7gwYPZtnXq1Cnt27dPM2fOVKtWrSRJGzduzHVMDRs21OrVq+2Wk85Qr149mc1mHT58WKGhoVnWr1u3rt0+tdLVcebUpk2bFBERoSeeeELS1UT0/v37Va9ePUlXl1r29vbW6tWr1bdv3yzjf//993X69OksZ/mWL19eu3fvtju2c+dOuyR4VrZt26b09HTFxsbKzc1NkjLtp3y9c5ehb9++iouL05EjR9S2bVtVq1btuv3mFAlfAAAAAIDLs1gsio+Pz1Pd5ORkRURESJKWLl0qi8WS5xgcraTeDFpSr3dJHXdJZXcjhbtnyUj4XqOk3UiSnxt48uvafp0VAzcPAcVQetHuJzg4WJs3b1ZiYqL8/Pw0cOBAzZw5U927d9ewYcMUGBioAwcO6NNPP9X777+vrVu3avXq1WrXrp0qVKigzZs368SJE6pbt66tvfj4eO3bt09ly5aVv7//DROI0tUlm2+55RbVrVtXb775ps6cOaPevXtLuprY/PDDDxUfH6/q1avro48+0pYtW7KdUVymTBmVLVtW//3vf1W5cmUdPnxYI0aMyPW5efHFF9WgQQMNGDBA/fv3l5eXl9auXatHHnlE5cqVU3R0tAYPHqz09HTdfffdOnfunDZt2qTSpUurV69e6t+/v2JjYzV06FD17dtX27Zt05w5c3Lc/y233KKFCxfqu+++U5kyZTRlyhQdO3bMlvC1WCwaPny4hg0bJi8vL7Vs2VInTpzQnj171KdPH3Xv3l0TJkxQ586dFRMTo8qVK2vHjh2qUqWKmjdvrnvvvVeTJk3Shx9+qObNm+vjjz/W7t27bUtSZ6dWrVq6cuWKpk2bpk6dOmnTpk169913c3XupKv7+EZHR2vmzJn68MMPc3dxroOEbxFS4u7cLIC7Nkvq3ez8kV+ylNT3OQAAQG6YTKYCSTpaLBZWsnEBJfV6l9Rxo2RyRuLRmYnPa7+vcSZnxZCf76jyypnXO+P7mvx8V5NXJPhR2EwmkwICA3R28VmH9RkQGJDr91R0dLR69eqlevXq6fLlyzp06JA2bdqk4cOHq127dkpJSVFQUJDat28vNzc3lS5dWuvXr1dcXJzOnz+voKAgxcbGqkOHDpKu7s2akJCgpk2bKikpSWvXrlVYWNgN43j99df1+uuva+fOnapVq5aWLVtmSww+/fTT2rFjhx599FGZTCZ1795dAwYM0DfffJNlW25ubvr000/13HPPqX79+qpdu7beeuutHMVxrVtvvVUrV67USy+9pGbNmsnb21t33nmnunfvLkl69dVXVb58ecXExOj3339XQECAbr/9dr300kuSpJtvvllffPGFBg8erGnTpqlZs2aaMGGCLZF9I6+88op+//13hYeHy8fHR//5z3/UuXNnnTt3zlZm5MiR8vDw0KhRo/TXX3+pcuXK6t+/v6Srs7dXrlypF154QR07dlRaWprq1aun6dOnS5LCw8M1cuRIDRs2TMnJyerdu7eefPJJ/fzzz9eNq1GjRpoyZYomTpyoF198Ua1bt1ZMTIyefPLJHJ87SfL399dDDz2k5cuXq3Pnzjk6JzlhMkrY5qnnz5+Xv7+/zp07p9KlSzs7HDuXL1+23Zl9sWmvkpHw3TpXUt7vCL/2nDmLqy1tfO05c7XYS2rik/c5AAAlD38bOPZzR0n9jFyQN4O60pe2rny986OkjtuVlbj/F0h2/z8AUHwVxf8PFeW8QVGWnJysQ4cOqXr16nafJa1Wa6Y9UguTyWSSu7u7w/oD8qtNmza67bbb9NZbb123XHa/Y1lhhi8Al1FSl6sDAAAAssOMTwAofqydrI791taQlLHtpLskR93Dkya5f0mCBiiOSL4CWTtz5owSEhKUkJCgGTNmFGjbJHzh0ljaGCUB73MAAFCSlLQlPDO42ixZAHCE6a3PyuzuuBlihiGl/v9ekF5ukqP+WU6xmjRwfcA/Bzzk+G9ti8AE8uGSvBzYnyHpyv8/9pTj8typkiZe8/zBxgPk4ea4C2AYhqzpaZIkdzcPh33+SEu/omU7Cza5ARRlEyZM0IQJE7J8rVWrVtkuy1wSdOjQQRs2bMjytZdeesm2NHRxFBISojNnzmjixImqXbt2gbZNwhcujbvZS5aSmvjkfQ4AAEoSZ+9f6Kz+S+JKMvlZjjo/nJ3gz1jekD0bgRszuxuyOHiSmHP+JS5RO+5ly0uSl8PSrleZHdpbBvvr7eHmKQ93R6a6JU8njRwoSfr3769u3bpl+VpJ+9z/b++//74uX76c5WuBgYEOjsaxEhMTC61tEr4AXAaJT+D68vulqSvvdQ0AAFxPUdiyxdk3GDgLNzYAAAAUrsDAwGKfvMyrqlWrOjuEYomELwAAxURR+NJU4os8AEDBcOQynkVmCU8AyM7/L7/qMIbxT59uHo77h9HR4wQAACgmSPgCAAAAAIocRy/jyRKezuXIfRuLyp6NkmP3bWTPRtfmu32es0MAAABAEUbCFwCAYiI/+1xLrr3XNQAArq4k7mV7bZ+O3rexKOzZKDl+30b2bAQAAACKJxK+AAAUEwW1z7XEXtcAADias/eSdXb/ADLLzw2d197M6Ux5uZG0qMQOAADgSkj4AgAAAAAAAEVMfm7ozO/qP4ZhKCUlRZJkNpvzvAS4xWLJdV3D+Gc2fIo1T926nJIyTgAAUHhI+AIAAAAAUERYO1kd95e6ISkjyeAux21mmya5f+nADZqBEqggVv/x8fEpoGhyJyPRLEkD15dxSgxwjlRJJWF/+9R/PU+zXsmyXHFz7TivvbEDxZPVanXodTaZTHJ3d73Pl7/++qsiIyO1c+dO1alTRzt37nR2SHbmzJmjqKgonT17Nsd1IiMjdfbsWS1ZsqTQ4rpWcHCwoqKiFBUV5ZD+ijISvigSnL1flDP6l/J2p6urMwyjRF7vjA84jr7ezh63VDLf5wAAAHnmIcf+pe7pwL4AADmT5uwAHORf45zonCicbtmuGc4OweFSUlKcdlMJCp/VatUjXbroZC6ShPlVLiBAny9enKukb1hYmBo3bqy4uLgCiSEvic7Ro0fL19dX+/btk5+fnyRp/PjxWr58uXbu3CkvL69cJVsL2qOPPqqOHTsWeLskaQsHCV8UCc7em8VZ/cfHx5e4PTKTk5MVHh7u1Bic/X5zFt7nAAAAAICizmw22x5Pb31GZtebsJVrKVb72cysggDAlRmGoZNnz2qkri4iU9iskl49e9YlZ44fPHhQ999/v4KCgmzHUlNT9cgjj6h58+aaNWuWE6OTvL29+V7XhZDwBQAAAAAAAFAkXLtClNldspD7LDGGS/JydhAOkCr72cwPNhogD/fiv+RGmvWKbTbztTd2oPhyl+TukD1Dcp/ojYyM1Lp167Ru3TpNnTpVknTo0CElJSVp6NCh2rBhg3x9fdWuXTu9+eabKleunCRp4cKFGjt2rA4cOCAfHx+FhIRo6dKlmjRpkubOnSvpn/+PrV27VmFhYdnGkFFu27ZtGjdunEaPHq0xY8Zo7Nixkq4up5xbTZs21WOPPabo6GhJUufOnbV8+XKdOXNGfn5++vPPP1WtWjX99ttvqlWrllJSUvTyyy/rk08+0dmzZ1W/fn1NnDjRFndWSzq/9tpreuutt3T58mU9+uijKleunFasWJFpOerJkycrNjZWqampeuyxxxQXFydPT0+FhYXpjz/+0ODBgzV48GBJ/6yOuXHjRr344ovaunWrypUrpy5duigmJka+vr6SpOPHj6tPnz5atWqVKlWqpNdeey3X56g4I+GLImV667MyuzvmThzDkFLTrz72cpMcteJsitWkgesDHNNZEefID/KGpIydQjzluO3J/v0hXpIebDxAHm6O+SBvGIas6VfXSHJ383DY0spp6Ve0bGfJW5IIAAAAAID8cuh+7s70rz3dvSR5OewbG2ey/+7Tw91THu4lIdX9D7b+grNNnTpV+/fvV/369TVu3DhJkqenp5o1a6a+ffvqzTff1OXLlzV8+HB169ZNa9as0dGjR9W9e3e98cYb6tKliy5cuKANGzbIMAxFR0dr7969On/+vGbPni1JCgwMvG4MR48eVdu2bdW+fXtFR0fblnTOj9DQUCUkJCg6OlqGYWjDhg0KCAjQxo0b1b59e61bt05Vq1ZVrVq1JEmDBg3SL7/8ok8//VRVqlTR4sWL1b59e/3888+65ZZbMrU/b948jR8/XjNmzFDLli316aefKjY2VtWrV7crt3btWlWuXFlr167VgQMH9Oijj6px48bq16+fFi1apEaNGuk///mP+vXrZ6tz8OBBtW/fXq+99po++OADnThxQoMGDdKgQYNs5zQyMlJ//fWX1q5dK09PTz333HM6fvx4vs9bcVESPjrAhZjdDYfeuemcxQj++VBXEveyvbZPR3+Qd869g5lvYPBwc+wHeU8njRwAAAAAAOSBo/dzB4ASxt/fX15eXvLx8VGlSpUkXZ25GhISogkTJtjKffDBB6pWrZr279+vpKQkpaWlqWvXrrYlmBs0aGAr6+3trZSUFFt7N1KpUiV5eHjIz88vx3VuJCwsTLNmzZLVatXu3bvl5eWlRx99VAkJCWrfvr0SEhIUGhoqSTp8+LBmz56tw4cPq0qVKpKk6OhorVixQrNnz7Y7DxmmTZumPn366KmnnpIkjRo1SitXrlRSUpJduTJlyujtt9+Wu7u76tSpo/vvv1+rV69Wv379FBgYKHd3d5UqVcpu3DExMXr88cdt+/recssteuuttxQaGqp33nlHhw8f1jfffKMff/xRd9xxhyRp1qxZqlu3boGcu+KAjw6AEzl7L1ln9w8AAABkJ8Xq7AgKX0kYY06lSsrLcnyuJDWLY2nWK1kcLV6uHaMr7q0HAABKhl27dmnt2rVZzrQ9ePCg2rVrpzZt2qhBgwYKDw9Xu3bt9PDDD6tMmTJZtOYcrVq10oULF7Rjxw599913Cg0NVVhYmF5//XVJ0rp16zR06FBJ0s8//yyr1apbb73Vro2UlBSVLVs2y/b37dunAQMG2B1r1qyZ1qxZY3fstttuk7v7PzP7KleurJ9//vm6se/atUs//fST5s2bZztmGIbS09N16NAh7d+/Xx4eHmrSpInt9Tp16iggIOC67ZYkJHwBAAAAAEXOwPVF54sTFL5/b4NSUmTsZVhSpKSkyMfHx9lhAAAAZJKUlKROnTpp4sTMn0wrV64sd3d3ffvtt/ruu++0cuVKTZs2TS+//LI2b96caUljZwkICFCjRo2UkJCg77//Xvfdd59at26tRx99VPv379dvv/1mm+GblJQkd3d3bdu2zS45Kynfy0t7etpvZ2gymZSenn7dOklJSXr66af13HPPZXrt5ptv1v79+/MVU0lAwhcoAhy6N4shKWMmgbsct5ntv/ZlAQAAAAAAAADAGby8vGS1/rPkzu23364vvvhCwcHB8vDI+st6k8mkli1bqmXLlho1apSCgoK0ePFiDRkyJFN7zhIaGqq1a9fqxx9/1Pjx4xUYGKi6detq/Pjxqly5sm1Gb0hIiKxWq44fP65WrVrlqO3atWtry5YtevLJJ23HtmzZkusYszpXt99+u3755Rfb/sL/VqdOHaWlpWnbtm22JZ337duns2fP5rr/4oqEL1AUOHpvFs8bFwEAAACcaXrrMzIX8/sFU6zMZM4wXJKXs4MoZKnKPJP5wUYD5OFevP9AS7Nesc1kNpvNTo4GAADgquDgYG3evFmJiYny8/PTwIEDNXPmTHXv3l3Dhg1TYGCgDhw4oE8//VTvv/++tm7dqtWrV6tdu3aqUKGCNm/erBMnTtj2kA0ODlZ8fLz27dunsmXLyt/fP9NM15w4fPiwTp8+rcOHD8tqtWrnzp2SpFq1auVo5m1YWJimTZum8uXLq06dOrZjb7/9th555BFbuVtvvVWPP/64nnzyScXGxiokJEQnTpzQ6tWr1bBhQ91///2Z2n722WfVr18/NW3aVC1atNCCBQv0008/qUaNGrkaY3BwsNavX6/HHntMZrNZ5cqV0/Dhw3XXXXdp0KBB6tu3r3x9ffXLL7/o22+/1dtvv63atWurffv2evrpp/XOO+/Iw8NDUVFR8vb2zlXfxRkJXwAAAABAkWN2lyzFPOGLf3hJ8nLY8kPOknn/Wg93T3m4F/dU9z9MpuJ+jQEAQIar8zczf/4pnH5yLzo6Wr169VK9evV0+fJlHTp0SJs2bdLw4cPVrl07paSkKCgoSO3bt5ebm5tKly6t9evXKy4uTufPn1dQUJBiY2PVoUMHSVK/fv2UkJCgpk2bKikpSWvXrlVYWFiu4xo1apTmzp1rex4SEiJJOW6vVatWSk9Pty3dLF1N+E6dOjVT/dmzZ+u1117TCy+8oCNHjqhcuXK666679MADD2TZ9uOPP67ff/9d0dHRSk5OVrdu3RQZGakff/wxV2McN26cnn76adWsWVMpKSkyDEMNGzbUunXr9PLLL6tVq1YyDEM1a9bUo48+ahdv3759FRoaqooVK+q1117TyJEjc9V3cUbCFwAAAACAoiLN2QE4QEkYIwAAQAllMplULiBArzpwqd1yAQG5vrHs1ltv1ffff5/p+KJFi7IsX7duXa1YsSLb9sqXL6+VK1fmKoaM2bvXmjNnjubMmZOrdq4VGBiYab/czp07yzAyJ989PT01duxYjR07Nsu2IiMjFRkZaXds5MiRdknW++67z24Z5qxij4uLs3t+1113adeuXZnK3XHHHdc9h5UqVdJXX31ld6xnz57Zli9pSPgCAAAAAFBEuH/JtGYAAAC4Lnd3d32+eHGWCcbCYjKZ5O7O5+jCdunSJb377rsKDw+Xu7u7PvnkE61atUrffvuts0ODJDdnBwAAAAAAAAAAAIDiwd3dXR4eHg77KYrJ3gkTJsjPzy/Ln4xloHOrf//+2bbZv3//Ah5BZiaTSV9//bVat26tJk2a6Msvv9QXX3yhtm3bFnrfuDFm+AIAAAAAUERYO1mL/1/qacxkBgAAQPHWv39/devWLcvXvL2989TmuHHjFB0dneVrpUuXzlObueHt7a1Vq1YVej/Im+L+ZyQAAAAAAK7DQ/ylDgAAALi4wMBABQYGFmibFSpUUIUKFQq0TRQfLOkMAAAAAAAAAAAAAC6KhC8AAAAAAAAAAAAAuCgSvgAAAAAAAAAAAADgokj4AgAAAAAAAAAAAICLIuELAAAAAAAAAAAAAC6KhC8AAAAAFGXpaZL1imN+0lKl1EtXf9JSHddvepqzzzIAAACAAmK1WpWWluawH6vV6uwhu5Tg4GDFxcXZnptMJi1ZssThcSQkJMhkMuns2bM5rjNmzBg1bty40GL6t7CwMEVFRTmsv/zwcHYAAAAAAIDs+W6f5+wQAAAAACBHrFarHur6sE6fOeWwPgPLlNUXixbK3d09x3XCwsLUuHFju8RnfkRGRurs2bNOSZy6qhYtWujo0aPy9/cv0HYL+tq6ChK+AAAAAAAAAAAAyDfDMHT6zCl1vT1KbqbCX2Q23UjXou1xMgyj0PsqbFeuXJGnp6ezw3AYLy8vVapUydlhFBskfAEAAACgiLFYLIqPj3d4v8nJyYqIiJAkLV26VBaLxWn9AwAAAHBdbiY3ubnlfMZtnqXnvkpkZKTWrVundevWaerUqZKkQ4cOKSkpSUOHDtWGDRvk6+urdu3a6c0331S5cuUkSQsXLtTYsWN14MAB+fj4KCQkREuXLtWkSZM0d+5cSVeXR5aktWvXKiwsLNsYEhMTVb16dX366aeaMWOGNm/erHfffVeRkZF6//33FRsbq0OHDik4OFjPPfecBgwYYKv7559/aujQoYqPj1dKSorq1q2r6dOn684779TBgwc1ZMgQ/fDDD7p48aLq1q2rmJgYtW3bNvcn6l8efvhhVapUSW+//bYkKSoqSlOnTtXevXtVp04dpaamqkyZMlq6dKnatm2r9PR0TZw4Uf/973/1999/69Zbb9XIkSP18MMPS7q6pPM999yjM2fOKCAgQJI0c+ZMjRs3TqdOnVJ4eLhatWqlcePGZVr2+aOPPtLIkSN15swZdejQQTNnzlSpUqWyvbbBwcHavXv3da/vxYsX9cwzz2jRokUqVaqUoqOj833OHImELwAAAAAUMSaTSd7e3k6NwWKxOD0GAAAAAChoU6dO1f79+1W/fn2NGzdOkuTp6almzZqpb9++evPNN3X58mUNHz5c3bp105o1a3T06FF1795db7zxhrp06aILFy5ow4YNMgxD0dHR2rt3r86fP6/Zs2dLkgIDA3MUy4gRIxQbG6uQkBBZLBbNmzdPo0aN0ttvv62QkBDt2LFD/fr1k6+vr3r16qWkpCSFhoaqatWqWrZsmSpVqqTt27crPf1q5jspKUkdO3bU+PHjZTab9eGHH6pTp07at2+fbr755nydt9DQUL333nu25+vWrVO5cuWUkJCgOnXqaMuWLbpy5YpatGghSYqJidHHH3+sd999V7fccovWr1+vJ554QuXLl1doaGim9jdt2qT+/ftr4sSJevDBB7Vq1SqNHDkyU7mDBw9qyZIl+uqrr3TmzBl169ZNr7/+usaPH5/ltS1fvrzOnj2re++9N9vrK0lDhw7VunXrtHTpUlWoUEEvvfSStm/f7tA9g/ODhC8AAAAAAAAAAABKBH9/f3l5ecnHx8e2pPBrr72mkJAQTZgwwVbugw8+ULVq1bR//34lJSUpLS1NXbt2VVBQkCSpQYMGtrLe3t5KSUnJ9RLFUVFR6tq1q+356NGjFRsbaztWvXp1/fLLL3rvvffUq1cvzZ8/XydOnNCWLVtsSeVatWrZ6jdq1EiNGjWyPX/11Ve1ePFiLVu2TIMGDcpVbP8WFham559/XidOnJCHh4d++eUXjRw5UgkJCerfv78SEhJ0xx13yMfHRykpKZowYYJWrVql5s2bS5Jq1KihjRs36r333ssy4Ttt2jR16NDBNrP21ltv1XfffaevvvrKrlx6errmzJmjUqVKSZJ69uyp1atXa/z48VleW0m2BHp217dKlSqaNWuWPv74Y7Vp00aSNHfuXN100035OmeORMIXAAAAAAAAAAAAJdauXbu0du1a+fn5ZXrt4MGDateundq0aaMGDRooPDxc7dq108MPP6wyZcrkq9+mTZvaHl+8eFEHDx5Unz591K9fP9vxtLQ0+fv7S5J27typkJCQbGcQJyUlacyYMVq+fLmOHj2qtLQ0Xb58WYcPH85XnJJUv359BQYGat26dfLy8lJISIgeeOABTZ8+XdLVGb8Zy1gfOHBAly5d0n333WfXRmpqqkJCQrJsf9++ferSpYvdsWbNmmVK+AYHB9uSvZJUuXJlHT9+/Lqx3+j6Xr58WampqbrzzjttxwMDA1W7du3rtluUkPAFAAAAAAAAAABAiZWUlKROnTpp4sSJmV6rXLmy3N3d9e233+q7777TypUrNW3aNL388svavHmzqlevnud+fX197WKQru5je23iUZLc3a/uh3yjbXeio6P17bffavLkyapVq5a8vb318MMPKzU1Nc8xZjCZTGrdurUSEhJkNpsVFhamhg0bKiUlRbt379Z3331nm52bMZbly5eratWqdu2YzeZ8xeHp6ZkprowlrbNzo+t74MCBfMVUFJDwBQCgCDEMQ8nJyU7p+9p+nRWDxWKRyWRySt8AAAAAAAAoGby8vGS1Wm3Pb7/9dn3xxRcKDg6Wh0fWqTOTyaSWLVuqZcuWGjVqlIKCgrR48WINGTIkU3t5UbFiRVWpUkW///67Hn/88SzLNGzYUO+//75Onz6d5SzfTZs2KTIy0jZTNikpSYmJifmK61qhoaGaOXOmzGazxo8fLzc3N7Vu3VqTJk1SSkqKWrZsKUmqV6+ezGazDh8+nOXyzVmpXbu2tmzZYnfs389zIqtrcaPrW7NmTXl6emrz5s22vY7PnDmj/fv35zh+ZyPhCwBAEZKcnKzw8HBnh6GIiAin9BsfH3/DOxUBAAAAAACA/AgODtbmzZuVmJgoPz8/DRw4UDNnzlT37t01bNgwBQYG6sCBA/r000/1/vvva+vWrVq9erXatWunChUqaPPmzTpx4oTq1q1ray8+Pl779u1T2bJl5e/vn2kmak6MHTtWzz33nPz9/dW+fXulpKRo69atOnPmjIYMGaLu3btrwoQJ6ty5s2JiYlS5cmXt2LFDVapUUfPmzXXLLbdo0aJF6tSpk0wmk0aOHHnD2a+5ERYWpsGDB8vLy0t333237Vh0dLTuuOMO24zlUqVKKTo6WoMHD1Z6erruvvtunTt3Tps2bVLp0qXVq1evTG0/++yzat26taZMmaJOnTppzZo1+uabb3I9OeTf1zYwMPCG19fPz099+vTR0KFDVbZsWVWoUEEvv/yy3Nzc8n/SHMR1IgUAAAAAAAAAAECRl26kKz3dWvg/Rt6SmdHR0XJ3d1e9evVUvnx5paamatOmTbJarWrXrp0aNGigqKgoBQQEyM3NTaVLl9b69evVsWNH3XrrrXrllVcUGxurDh06SJL69eun2rVrq2nTpipfvrw2bdqUp7j69u2r999/X7Nnz1aDBg0UGhqqOXPm2JaN9vLy0sqVK1WhQgV17NhRDRo00Ouvv25b8nnKlCkqU6aMWrRooU6dOik8PFy33357nmLJSoMGDRQQEKDGjRvb9sMNCwuT1Wq17d+b4dVXX9XIkSMVExOjunXrqn379lq+fHm2S2C3bNlS7777rqZMmaJGjRppxYoVGjx4sCwWS65i/Pe1PXz4sKpUqXLd6ytJkyZNUqtWrdSpUye1bdtWd999t5o0aZL7k+QkzPAFAKCIunj745KbA/9XbRhSetrVx24ekqOWVk5Pk+/2eY7pCwAAAAAAAIXGZDIpsExZLdoe57A+A8uUzfUs0FtvvVXff/99puOLFi3KsnzdunW1YsWKbNsrX768Vq5cmeP+g4ODZRhGlq/16NFDPXr0yLZuUFCQFi5cmG27a9assTs2cOBAu+f/XuI5uziy4ubmptOnT9sda9y4cZZtmEwmPf/883r++eezbCssLCxTvX79+qlfv352z2vVqmV7PmbMGI0ZM8auTlRUlKKiomzPs7u2GbOfs+Pn56ePPvpIH330ke3Y0KFDsy1f1JDwBQCgqHLzkNxzv/RL/ng5uD8AAAAAAAAUF+7u7vpi0cJcJRHzy2Qy2Wa4wrVNnjxZ9913n3x9ffXNN99o7ty5mjFjhrPDcgkkfAEAKELsPgxbrzgvEEe6ZpyO/GMAAAAAAAAABY/kqzRhwgRNmDAhy9datWqlb775xsER3VhRiPnHH3/UG2+8oQsXLqhGjRp666231Ldv30Lvtzgg4QsAQBGSkpJie+y7Y74TI3GOlJQU+fj4ODsMAAAAAAAAIM/69++vbt26Zfmat7e3g6PJmaIQ82effeaQfoojEr4AAAAAAAAA7GzatElxcXGKiopSy5YtnR0OAAAuJTAwUIGBgc4OI1dcMWb8g4QvAABFiNlstj2+GNLDCXv4OoH1im0287XjBwAAAOAcycnJio2N1cmTJxUbG6smTZrIYrE4OywAAABkg4QvAABFiMlk+ueJu2fJSPhew278AAAAAJzi448/1qlTpyRJp06d0rx589SnTx8nRwUAKKrS09OdHQJQLBmGkeOyJHxRpKRYnR1B4SsJYwQAAAAAAK7pzz//1Lx582xfMBqGoXnz5ik8PFw33XSTk6MDABQlXl5ecnNz019//aXy5cvLy8uLm/mBAmIYhk6cOCGTySRPzxtPCiLhiyJl4Poyzg4BAAAAAACgRDIMQ2+++Wa2xydPnswX+QAAGzc3N1WvXl1Hjx7VX3/95exwgGLHZDLppptukru7+w3LkvAFAAAAAAAAoD/++ENbtmzJdNxqtWrLli36448/FBwc7PjAAABFlpeXl26++WalpaXJamV5S6AgeXp65ijZK5HwRREzvfUZmXP23nVZKVZmMgMAAAAAgKInKChId9xxh7Zv3273pb27u7uaNGmioKAgJ0YHACiqMpaczcmyswAKBwlfFClmd8lSzBO++EeqJCnnm467otQsjqVZrzg8Dke7doy52VgeAAAAAOA8JpNJgwcPVs+ePbM8znLOAAAARRMJXwBOM9HZATjJsl0znB2CQ6WkpMjHx8fZYQAAAAAAcuCmm27S448/ro8++kiGYchkMunxxx9X1apVnR0aAAAAsuHm7AAAAAAAAAAAFB1PPPGEypYtK0kqV66cHn/8cSdHBAAAgOthhi8ApxkuycvZQRSyVGWeyfxgowHycC/e+1mkWa/YZjKbzWYnRwMAAAAAyA2LxaIXXnhBcXFxioqKksVicXZIAAAAuA4SvgCcxkuSl4r7/j+Z96/1cPeUh3txT3X/gz2eAAAAAMD1tGzZUi1btnR2GAAAAMgBEr4AAMClGYah5OTkfNVPSUmRdHVGel5vUrBYLNzgAAAAAAAAAMDhSPgCAACXlpycrPDwcGeHofj4eHl7ezs7DAAAAAAAAAAlDAnfoio9zXF9GcY//bl5SI6aneTIMRZ1JeFUlIQxAgAAAAAAAAAAOBgJ3yLKd/s8Z4cAB3L/0t3ZIQCAy7JYLIqPj89z/eTkZEVEREiSli5dKovFkuc4AAAAAAAAAMDRSPgCAACXZjKZCmwpZYvFwrLMAAAAAAAAAFwKCd8iJL8zlPKqoGY2FUT/JZW1k7X4/zamMZMZAAAAAAAAAACgoBX3FJNLKcgZSnnFzCYn8RC/jQAAAAAAAAAAAMg1UkwAAABAEWcYhpKTk/NVPyUlRZJkNptlMpny1I7FYslzXQAAAAAAABQOEr7FRH6+BLy2Xn6+SOQLQAAAgMKRnJys8PBwZ4eh+Ph4VoMBAAAAAAAoYkj4FhMF9SVgfvbS5QtAAABQ2JjpCgAAAAAAANgj4QsAAACXUVJnulosFsXHx+e5fnJysu3GvqVLl8piseQ5DgAAAAAAABQtJHyLifx8CViQM10AAABQ8EwmU4ElmC0WC6uyAAAAAAAAFCMkfIuJ/H4J6OPjU4DRAACAwlZSlzZmpisAAAAAAABgj4QvAACACyqpSxsz0xUAAAAAAACw5+bsAAAAAAAAAAAAAAAAecMMXwAAABfE0sYAAAAAAAAAJBK+AAAALomljQEAAAAAAABILOkMAAAAAAAAAAAAAC6LGb4AAAAAUIwYhqHk5OQ81b22Xl7bkK6uHGAymfJcHwAAAAAA5BwJXwAAAAAoRpKTkxUeHp7vdjL2+c6L+Ph4looHAAAAAMBBWNIZAAAAAAAAAAAAAFwUM3wBAAAAoBixWCyKj4/PU13DMJSSkiJJMpvNeV6W2WKx5KkeAAAAAADIPRK+AAAAAFCMmEymfC2n7OPjU4DRAACAXEtzcH+GJOv/P3aXlLf7vXLP0eMEAKAYI+ELAAAAAAAAoMhJsZp0NRvpGIYhpaZffezlJuVxoYtcuzrOf7h/6e6YjgEAQLFBwhcAAAAAAABAkTNwfYCzQwAAAHAJJHwBAAAAAAAAoAhYunSpLBZLruokJycrIiKikCLKOVeOHQAAV0fCFwAAAAAAAECRYLFYFB8f75S+r00+5iV5WRAsFotMuVxLOr/nzDAMpaSkSJLMZnOu+782jrzWBQAA+UPCFwAAAAAAAECRYDKZ5O3t7ewwZLFYikQcOVEQ58zHx6eAogEAAM7g5uwAAAAAAAAAAAAAAAB5Q8IXAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEkfAEAAAAAAAAAAADARZHwBQAAAAAAAAAAAAAX5fSE7/Tp0xUcHCyLxaI777xTP/74Y7Zlr1y5onHjxqlmzZqyWCxq1KiRVqxY4cBoAQAAAAAAAAAAAKDocGrCd8GCBRoyZIhGjx6t7du3q1GjRgoPD9fx48ezLP/KK6/ovffe07Rp0/TLL7+of//+6tKli3bs2OHgyAEAAAAAAAAAAADA+Zya8J0yZYr69eunp556SvXq1dO7774rHx8fffDBB1mW/+ijj/TSSy+pY8eOqlGjhp555hl17NhRsbGxDo4cAAAAAAAAAFBQUiWlynDYT4oMJf3/T4oD+0119okGABRLHs7qODU1Vdu2bdOLL75oO+bm5qa2bdvq+++/z7JOSkqKLBaL3TFvb29t3Lgx235SUlKUkpJie37+/Pl8Rg4AAAAAAAAAKEgTnR2Ak6SlX3Fof4ZhyJqeJklyd/OQyWRySL+OHicAlDROS/iePHlSVqtVFStWtDtesWJF/frrr1nWCQ8P15QpU9S6dWvVrFlTq1ev1qJFi2S1WrPtJyYmRmPHji3Q2AEAAAAAAAAAyK9lO2c4OwQAQDHgtIRvXkydOlX9+vVTnTp1ZDKZVLNmTT311FPZLgEtSS+++KKGDBlie37+/HlVq1bNEeECAAAAAAAAALJhsVgUHx/vlL6Tk5MVEREhSVq6dGmmlSUd1TcAAAXBaQnfcuXKyd3dXceOHbM7fuzYMVWqVCnLOuXLl9eSJUuUnJysU6dOqUqVKhoxYoRq1KiRbT9ms1lms7lAYwcAAAAAAAAA5I/JZJK3t7ezw5DFYnFoHCU10Z3BGX0CQHHntISvl5eXmjRpotWrV6tz586SpPT0dK1evVqDBg26bl2LxaKqVavqypUr+uKLL9StWzcHRAwAAAAAAAAAQP6U1EQ3AKDwOHVJ5yFDhqhXr15q2rSpmjVrpri4OF28eFFPPfWUJOnJJ59U1apVFRMTI0navHmzjhw5osaNG+vIkSMaM2aM0tPTNWzYMGcOAwAAAAAAAAAAAACcwqkJ30cffVQnTpzQqFGj9Pfff6tx48ZasWKFKlasKEk6fPiw3NzcbOWTk5P1yiuv6Pfff5efn586duyojz76SAEBAU4aAQAAAAAAAAAAAAA4j1MTvpI0aNCgbJdwTkhIsHseGhqqX375xQFRAQAAZ0hOTnZqn87oX7q6jJbJZHJK3wAAAAAAAABcm9MTvgAAABkiIiJKZP/x8fHsmwQAAAAAAAAgT9xuXAQAAAAAAAAAAAAAUBQxwxcAABQp01ufldndcFh/hiGlpl997OUmOWpl5RSrSQPXBzimMwAAAAAAAADFFglfAABQpJjdDVncHduncxZTdlxSGwAAAAAAAEDxxZLOAAAAAAAAAAAAAOCiSPgCAAAAAAAAAAAAgIsi4QsAAAAAAAAAAAAALoqELwAAAAAAAAAAAAC4KBK+AAAAAAAAAAAAAOCiSPgCAAAAAAAAAAAAgIsi4QsAAAAAAAAAAAAALsrD2QEAAACgZDEMQ8nJyU7p+9p+HR2DYRhKSUmR2WyWyWRyaN/OHHcGi8Xi8HEDAAAAAACUBCR8AQAA4FDJyckKDw93dhiKiIhwdghO4axxx8fHy9vb2yl9AwAAAAAAFGcs6QwAAAAAAAAAAAAALooZvgAAAHCa4ZK8HNifIenK/z/2lOSoBYZTJU285vmDjQfIw83TQb1fXU7amp4mSXJ383DY0spp6Ve0bOcMh/QFAAAAAABQUpHwBQAAgNN4SfJyWNr1KrNDe8tg2D3zcPOUh7sjU92Sp5NGDgAAAAAAgMLFks4AAAAAAAAAAAAA4KJI+AIAAAAAAAAAAACAiyLhCwAAAAAAAAAAAAAuioQvAAAAAAAAAAAAALgoEr4AAAAAAAAAAAAA4KJI+AIAAAAAAAAAAACAiyLhCwAAAAAAAAAAAAAuioQvAAAAAAAAAAAAALgoEr4AAAAAAAAAAAAA4KI8nB0AAABASZecnOzUPh3dvzPGCwAAAAAAABRXJHwBAACcLCIiokT3DwAAAAAAACDvWNIZAAAAAAAAAAAAAFwUM3wBAACKAGsnq2M/mRmSrP//2F2SyUH9pknuX7o7qDMAAAAAAACg+CPhCwAAUBR4yPGfzDwd3B8AAABQiAzDUHJycp7rX1s3P+1YLBaZTI66oxIAAICELwAAAAAAAIBiIDk5WeHh4QXSVkRERJ7rxsfHy9vbu0DiAAAAyAn28AUAAAAAAAAAAAAAF8UMXwAAAAAAAAAuz2KxKD4+Ps/1DcNQSkqKJMlsNud5WWaLxZLnGAAAAPKChC8AAEVVeppj+zOMf/p085ActeeUo8cJAAAAoFgymUz5XkrZx8engKIBAABwHBK+AAAUUb7b5zk7BAAAAAAAAABAEccevgAAAAAAAAAAAADgopjhCwBAEZLfPafyIzk5WREREZKkpUuXOnTfqWv7BgAAAAAAAADkHAlfAACKkILYc6ogWCyWIhEHAAAAAAAAAOD6WNIZAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEkfAEAAAAAAAAAAADARZHwBQAAAAAAAAAAAAAXRcIXAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEkfAEAAAAAAAAAAADARZHwBQAAAAAAAAAAAAAXRcIXAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEkfAEAAAAAAAAAAADARZHwBQAAAAAAAAAAAAAXRcIXAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEkfAEAAAAAAAAAAADARZHwBQAAAAAAAAAAAAAXRcIXAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEkfAEAAAAAAAAAAADARZHwBQAAAAAAAAAAAAAXRcIXAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEkfAEAAAAAAAAAAADARZHwBQAAAAAAAAAAAAAXRcIXAAAAAAAAAAAAAFyUh7MDAK6VYjVJMhzSl2FIqelXH3u5SSaTQ7r9/zECAAAAAAAAAAAA+UfCF0XKwPUBzg4BAAAAAAAAAAAAcBks6QwAAAAAAAAAAAAALooZvnA6i8Wi+Ph4h/ebnJysiIgISdLSpUtlsVic1j8AAAAAAAAAAACQFyR84XQmk0ne3t5OjcFisTg9BgAAAAAAAAAAACC3WNIZAAAAAAAAAAAAAFwUCV8AAAAAAAAAAAAAcFEs6QwAAAAAAAAAgAswDEPJycl5rn9t3fy0Y7FYZDKZ8lwfAFCwSPjCpeXnAw4fbgAAAAAAAAC4kuTkZIWHhxdIWxEREXmuGx8fL29v7wKJAwCQfyR84dIK6gMOH24AAAAAAAAAAADgikj4AgAAAAAAAADgAiwWi+Lj4/Nc3zAMpaSkSJLMZnOeVy60WCx5jgEAUPBI+MKl5ecDDh9uAAAAAAAAALgSk8mU79UGfXx8CigaAEBRQcIXLi2/H3D4cAMAAAAAAAAAAABX5ubsAAAAAAAAAAAAAAAAeUPCFwAAAAAAAAAAAABcFAlfAAAAAAAAAAAAAHBR7OELAEAxYRiGkpOT81z/2rr5acdischkMuW5PgAAAAAAAAAg50j4AgBQTCQnJys8PLxA2oqIiMhz3fj4eHl7exdIHAAAAAAAAACA62NJZwAAAAAAAAAAAABwUczwBQCgmLBYLIqPj89zfcMwlJKSIkkym815XpbZYrHkOQYAAAAAAAAAQO6Q8AUAoJgwmUz5XkrZx8engKIBAAAAAAAAADgCSzoDAAAAAAAAAAAAgIsi4QsAAAAAAAAAAAAALoolnQEAAAAAAAAALsUwDCUnJ+e5/rV189OOxWKRyWTKc30AAAoCCV8AAAAAAAAAgEtJTk5WeHh4gbQVERGR57rx8fHy9vYukDgAAMgrlnQGAAAAAAAAAAAAABfFDF8AAOB0hmHYHqdYnRiIA5WUcQIAAABAYbBYLIqPj89zfcMwlJKSIkkym815XpbZYrHkOQYAAAoKCV8AAOB0GX9kS9LA9WWcGAkAAAAAwBWYTKZ8L6Xs4+NTQNEAAOBcLOkMAAAAAAAAAAAAAC6KGb4AAMDpzGaz7fH01mdkdndiMA6SYmU2MwAAAAAAAID8I+ELAACc7tq9kszukqUEJHwBAAAAAAAAoCCwpDMAAAAAAAAAAAAAuCgSvgAAAAAAAAAAAADgokj4AgAAAAAAAAAAAICLIuELAAAAAAAAAAAAAC6KhC8AAAAAAAAAAAAAuCgSvgAAAAAAAAAAAADgokj4AgAAAAAAAAAAAICLIuELAAAAAAAAAAAAAC7K6Qnf6dOnKzg4WBaLRXfeead+/PHH65aPi4tT7dq15e3trWrVqmnw4MFKTk52ULQAAAAAAAAAAAAAUHQ4NeG7YMECDRkyRKNHj9b27dvVqFEjhYeH6/jx41mWnz9/vkaMGKHRo0dr7969mjVrlhYsWKCXXnrJwZEDAAAAAAAAAAAAgPM5NeE7ZcoU9evXT0899ZTq1aund999Vz4+Pvrggw+yLP/dd9+pZcuW6tGjh4KDg9WuXTt17979hrOCAQAAAAAAAAAAAKA4clrCNzU1Vdu2bVPbtm3/CcbNTW3bttX333+fZZ0WLVpo27ZttgTv77//rq+//lodO3bMtp+UlBSdP3/e7gcAAAAAAAAAAAAAigMPZ3V88uRJWa1WVaxY0e54xYoV9euvv2ZZp0ePHjp58qTuvvtuGYahtLQ09e/f/7pLOsfExGjs2LEFGjsAAAAAAAAAAAAAFAVOXdI5txISEjRhwgTNmDFD27dv16JFi7R8+XK9+uqr2dZ58cUXde7cOdvP//73PwdGDAAAAAAAAAAAAACFx2kzfMuVKyd3d3cdO3bM7vixY8dUqVKlLOuMHDlSPXv2VN++fSVJDRo00MWLF/Wf//xHL7/8stzcMuevzWazzGZzwQ8AAAAAAAAAAAAAAJzMaTN8vby81KRJE61evdp2LD09XatXr1bz5s2zrHPp0qVMSV13d3dJkmEYhRcsAAAAAAAAAAAAABRBTpvhK0lDhgxRr1691LRpUzVr1kxxcXG6ePGinnrqKUnSk08+qapVqyomJkaS1KlTJ02ZMkUhISG68847deDAAY0cOVKdOnWyJX4BAAAAAAAAAAAAoKRwasL30Ucf1YkTJzRq1Cj9/fffaty4sVasWKGKFStKkg4fPmw3o/eVV16RyWTSK6+8oiNHjqh8+fLq1KmTxo8f76whAAAAAAAAAAAAAIDTODXhK0mDBg3SoEGDsnwtISHB7rmHh4dGjx6t0aNHOyAyAAAAAAAAAAAAACjanLaHLwAAAAAAAAAAAAAgf0j4AgAAAAAAAAAAAICLIuELAAAAAAAAAAAAAC7K6Xv4AgAAXCvFapJkOKw/w5BS068+9nKTTCbH9Ht1nAAAAAAAAACQPyR8AQBAkTJwfYCzQwAAAAAAAAAAl8GSzgAAAAAAAAAAAADgopjhCwAAnM5isSg+Pt4pfScnJysiIkKStHTpUlksFqf0DQAAAAAAAAB5QcIXAAA4nclkkre3t7PDkMViKRJxAAAAAAAAAEBOsaQzAAAAAAAAAAAAALgoEr4AAAAAAAAAAAAA4KJI+AIAAAAAAAAAAACAi2IPXwBwsLT0Kw7ryzAMWdPTJEnubh4ymUwO6deRYwQAAAAAAAAAoCQj4QsADrZs5wxnhwAUK4ZhKDk5Oc/1r62bn3YsFovDbqoAAAAAAAAAgAwkfAEAgEtLTk5WeHh4gbQVERGR57rx8fHy9vYukDgAAAAAwJE2bdqkuLg4RUVFqWXLls4OBwAA5BIJXwBwkKVLl8pisTi0z+TkZFsCyxn9S3JKnwAAAAAAIGeSk5MVGxurkydPKjY2Vk2aNOFveQAAXAwJXwBwEIvF4tTZf87uHygsFotF8fHxea5vGIZSUlIkSWazOc/LMvOFCID/a+/u47ys63yPv38zwPxA7lJqYJF0zZusFBQEkWzphEvbHdZZ1nMORLKoW95silpydBVNpVoFH5U3lTfdYJu7m49w0xyLzU4ZhXiT1lGsTVE6grcwgs2gM7/zR9vkrGDMMMzFxTyfj8fv8WCu3/W9rs9FPfwpL67rBwBQRkuXLs2zzz6bJHn22Wdz4403Zt68eQVPBQB0heALAJRapVLZ4b/MMGjQoB6aBgAAoDzWrl2bG2+8MbVaLcnv/0LsjTfemOnTp2fvvfcueDoAYHvVFT0AAAAAAAC9q1arZcmSJdvc/ocIDADs+gRfAAAAAIA+Zs2aNbn77rvT1tbWaXtbW1vuvvvurFmzpqDJAICuEnwBAAAAAPqYffbZJ0cccUTq6+s7ba+vr8/EiROzzz77FDQZANBVgi8AAAAAQB9TqVRyxhlnbHN7pVIpYCoAoDsEXwAAAACAPmjvvffOrFmzOuJupVLJrFmzMnr06IInAwC6QvAFAAAAAOijZs+enb322itJMmLEiMyaNavgiQCArhJ8AQAAAAD6qGq1mjPPPDONjY2ZP39+qtVq0SMBAF3Ur+gBAAAAAAAozpQpUzJlypSixwAAuskdvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASfUregAAXlutVktLS0u31r5yXXePkSTVajWVSqXb6wEAAAAAgJ1D8AXYxbW0tGT69Ok7fJwZM2Z0e21TU1MGDhy4wzMAAAAAAAA9yyOdAQAAAAAAAErKHb4Au7hqtZqmpqZura3VamltbU2SNDQ0dPuxzNVqtVvrAAAAAACAnUvwBdjFVSqVHXqc8qBBg3pwGgAAAAAAYFfikc4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEn1K3oAoO/akiSp9cq5akle+s9f909S6ZWz/uEaAQAAAAAAdg7BFyjMZ4oeAAAAAAAAoOQ80hkAAAAAAACgpNzhC/S6ZcuWpVqt9uo5W1paMmPGjMLOn6SQcwIAAAAAALs3wRfoddVqNQMHDuyz5wcAAAAAAOgpHukMAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAl1a/oAQAAAOC/am2rJKn1yrlqtWRL++9/PaAuqVR65bT/eY0AAACwYwRfAAAAdjmn/J/hRY8AAAAApeCRzgAAAAAAAAAl5Q5fAAAAdgnVajVNTU29ft6WlpbMmDEjSbJs2bJUq9XCzg8AAABdJfjCruDlXjxXLUnbf/66PklvfW1YD1xjrVZLS0tLt9a+cl13j5H8/g8hK731pW4AAH1MpVLJwIEDC52hWq0WPgMAAAB0heALu4D6f6sveoRSaGlpyfTp03f4ODty90RTU5M/AAQAAAAAAHYZvsMXAAAAAAAAoKTc4QsF6avfT5ak2+fckd+zWq2W1tbWJElDQ0O3H8tcxO8XALufl9teKnqEXvHK66zVagVOAgAAALD7EnyhIL6frOt29Pds0KBBPTgNAHTfLT+/qugRel1ra6vPYgAAAICdwCOdAQAAAAAAAErKHb4AANDLPjD25PSr71/0GDvdy20vddzN3NDQUPA0AAAAALsnwRcAAHpZv/r+6Vc/oOgxelWlUil6BAAAAIDdkkc6AwAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASfUregAAAACAvujl9pd67Vy1Wi1t7S8nSerr+qVSqfTKeXvzGgEAoK8SfAEAAAAKcMv9VxU9AgAAsBvwSGcAAAAAAACAknKHLwAAAEAvWrZsWarVaq+es6WlJTNmzCjs/EkKOScAAPQFgi8AAABAL6pWqxk4cGCfPT8AANCzPNIZAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASmqXCL5XXnll9t1331Sr1UyaNCkrV67c5r5Tp05NpVJ51eu9731vL04MAAAAAAAAULzCg+9NN92U+fPn54ILLsi9996bsWPHZvr06Xnqqae2uv/NN9+cJ598suP1i1/8IvX19Zk5c2YvTw4AAAAAAABQrMKD7+LFi3PiiSdm7ty5ectb3pJrrrkmgwYNyvXXX7/V/ffcc8+MHDmy4/W9730vgwYNEnwBAAAAAACAPqfQ4Ltly5bcc889mTZtWse2urq6TJs2LStWrNiuY1x33XX5H//jf2SPPfbY6vutra1pbm7u9AIAAAAAAADYHRQafJ955pm0tbWlsbGx0/bGxsasW7fuT65fuXJlfvGLX+SEE07Y5j6LFi3KsGHDOl5jxozZ4bkBAAAAAAAAdgWFP9J5R1x33XU55JBDMnHixG3us2DBgmzcuLHj9cQTT/TihAAA21ar1f74w8t96AUAAAAA9Jh+RZ58xIgRqa+vz/r16zttX79+fUaOHPmaazdv3pxvfvObueiii15zv4aGhjQ0NOzwrAAAPa21tbXj1/X/Vl/gJAAAAABAWRV6h++AAQMyfvz4LF++vGNbe3t7li9fnsmTJ7/m2n/5l39Ja2trZs+evbPHBAAAAAAAANglFXqHb5LMnz8/H/nIRzJhwoRMnDgxV1xxRTZv3py5c+cmSebMmZPRo0dn0aJFndZdd911OfbYY7PXXnsVMTYAwA575VNI2t7ftgv8m1kveNndzAAAAADQkwr/Y8XjjjsuTz/9dM4///ysW7cu48aNy+23357GxsYkyeOPP566us43Iq9evTo//vGPc8cddxQxMgBAj6hUKn/8oV92gX8zAwAAAADKZpf4Y8VTTz01p5566lbfu/POO1+17aCDDkqtVtvJUwEAAAAAAADs2gr9Dl8AAAAAAAAAuk/wBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASqpf0QMAANB3bUmS1AqeYufbUvQAAAAAAOy2BF8AAArzmaIHAAAAAICS80hnAAAAAAAAgJJyhy8AAIX5ZJIBRQ/RC7bE3cwAAAAA7ByCLwAAhRmQZEAqRY/RC3b/7ykGAAAAoBge6QwAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBS/YoeAAAAAOjbtiRJar1yrlqSl/7z1/2TVHrlrH+4RgAAgJ4n+AIAAACF+kzRAwAAAJSY4AsAAEDp1Wq1tLS0dGvtK9d19xhJUq1WU6n01v2iAAAA8HuCLwAAAKXX0tKS6dOn7/BxZsyY0e21TU1NGThw4A7P0JcsW7Ys1Wq1V8/Z0tLS8b9zEedPUsg5AQCA3ZfgCwAAABSiWq0WGsmLPj8AAEBPEHwBAAAovWq1mqampm6trdVqaW1tTZI0NDR0+7HM7toEAACgCIIvAAAApVepVHboTs1Bgwb14DQAAADQe+qKHgAAAAAAAACA7hF8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASqpf0QMAAAAA/+nlXjxXLUnbf/66Pkmll87bm9cIAADQBwi+AAAAsIuo/7f6okcAAACgZDzSGQAAAAAAAKCk3OELALAr6O3HW3qMJ8Auo1qtpqmpqdfP29LSkhkzZiRJli1blmq12uszFHFOAACA3Y3gCwCwC/AIT4C+q1KpZODAgYXOUK1WC58BAACA7vFIZwAAAAAAAICScocvAEBBinqEZ1LsYzxfeW4AAAAAYMcIvgAABdkVHuGZeIwnAAAAAJRZlx/p/Lvf/S4vvvhix89r1qzJFVdckTvuuKNHBwMAAAAAAADgtXU5+M6YMSNf+9rXkiQbNmzIpEmTcvnll2fGjBm5+uqre3xAAAAAAAAAALauy8H33nvvzdFHH50k+dd//dc0NjZmzZo1+drXvpbPfe5zPT4gAAAAAAAAAFvX5eD74osvZsiQIUmSO+64Ix/60IdSV1eXI488MmvWrOnxAQEAAAAAAADYui4H3/333z/f/va388QTT6SpqSl/+Zd/mSR56qmnMnTo0B4fEAAAAAAAAICt63LwPf/883PWWWdl3333zcSJEzN58uQkv7/b97DDDuvxAQEAAAAAAADYun5dXfDXf/3Xefvb354nn3wyY8eO7dj+rne9Kx/84Ad7dDgAAAAAAAAAtq3Ld/gmyciRIzNkyJB873vfy+9+97skyRFHHJE3v/nNPTocAAAAAAAAANvW5eD77LPP5l3velcOPPDAvOc978mTTz6ZJJk3b17OPPPMHh8QAAAAAAAAgK3rcvA944wz0r9//zz++OMZNGhQx/bjjjsut99+e48OBwAAAAAAAMC2dfk7fO+44440NTVl77337rT9gAMOyJo1a3psMAAAAAD+qFarpaWlpVtrX7muu8dIkmq1mkql0u31AABAz+ty8N28eXOnO3v/4LnnnktDQ0OPDAUAAABAZy0tLZk+ffoOH2fGjBndXtvU1JSBAwfu8AwAAEDP6fIjnY8++uh87Wtf6/i5Uqmkvb09n/3sZ/POd76zR4cDAAAAAAAAYNu6fIfvZz/72bzrXe/KqlWrsmXLlnziE5/IL3/5yzz33HO56667dsaMAAA71V133ZUrrrgip59+eqZMmVL0OAAAW1WtVtPU1NSttbVaLa2trUmShoaGbj+WuVqtdmsdAACw83Q5+L7tbW/LI488ki984QsZMmRINm3alA996EM55ZRTMmrUqJ0xIwDATtPS0pLLL788zzzzTC6//PKMHz/eH2QCALukSqWyQ49T3tpXdAEAAOXX5eCbJMOGDcu5557b07MAAPS6pUuX5tlnn02SPPvss7nxxhszb968gqcCAAAAANg+XQ6+/+f//J/XfP8d73hHt4cBAOhNa9euzY033pharZbk9486vPHGGzN9+vTsvffeBU8HAAAAAPCndTn4Tp069VXbXvm9L21tbTs0EABAb6jValmyZMk2t1922WXd/m47AAAAAIDeUtfVBc8//3yn11NPPZXbb789RxxxRO64446dMSMAQI9bs2ZN7r777lf9ZbW2trbcfffdWbNmTUGTAQAAAABsvy7f4Tts2LBXbTvmmGMyYMCAzJ8/P/fcc0+PDAYAsDPts88+OeKII3Lvvfd2ir719fUZP3589tlnnwKnAwAAAADYPl2+w3dbGhsbs3r16p46HADATlWpVHLGGWdsc7vHOQMAAAAAZdDlO3wfeOCBTj/XarU8+eST+fSnP51x48b11FwAADvd3nvvnVmzZuXrX/96arVaKpVKZs2aldGjRxc9GgAAAADAduly8B03blwqlUpqtVqn7UceeWSuv/76HhsMAKA3zJ49O7fddlueeeaZjBgxIrNmzSp6JAAAAACA7dbl4Pvoo492+rmuri6vf/3rU61We2woAIDeUq1Wc+aZZ+aKK67I6aef7t9pAAAAAIBS6XLw3WeffXbGHAAAhZkyZUqmTJlS9BgAAAAAAF22XcH3c5/73HYf8O///u+7PQwAAPQFL7e/1Kvnq9VqaWt/OUlSX9cvlUqlV87b29cJAAAA0BdtV/BdsmTJdh2sUqkIvgAA8Cfccv9VRY8AAAAAwG5iu4Lvf/3eXgAAAAAAAACK1+Xv8AUAALpv2bJlqVarvXrOlpaWzJgxo7DzJynknAAAAAB9QbeC79q1a3PLLbfk8ccfz5YtWzq9t3jx4h4ZDAAAdkfVajUDBw7ss+cHAAAAoGd1OfguX748H/jAB7Lffvvl4Ycfztve9rY89thjqdVqOfzww3fGjAAAAAAAAABsRV1XFyxYsCBnnXVWHnzwwVSr1XzrW9/KE088kb/4i7/IzJkzd8aMAAAAAAAAAGxFl4PvQw89lDlz5iRJ+vXrl9/97ncZPHhwLrroonzmM5/p8QEBAAAAAAAA2LouB9899tij43t7R40alf/4j//oeO+ZZ57puckAAAAAAAAAeE1d/g7fI488Mj/+8Y9z8MEH5z3veU/OPPPMPPjgg7n55ptz5JFH7owZAQAAAAAAANiKLgffxYsXZ9OmTUmSCy+8MJs2bcpNN92UAw44IIsXL+7xAQEAAAAAAADYui4H30svvTSzZ89O8vvHO19zzTU9PhQAAAAAAAAAf1qXv8P36aefzrvf/e6MGTMmZ599dn7+85/vjLkAAAAAAAAA+BO6HHyXLVuWJ598Mv/wD/+Qu+++O4cffnje+ta35tJLL81jjz22E0YEAAAAAAAAYGu6HHyT5HWve11OOumk3HnnnVmzZk2OP/74fP3rX8/+++/f0/MBAAAAAAAAsA3dCr5/8NJLL2XVqlX52c9+lsceeyyNjY09NRcAAAAAAAAAf0K3gu8PfvCDnHjiiWlsbMzxxx+foUOH5jvf+U7Wrl3b0/MBAAAAAAAAsA39urpg9OjRee655/Lud787X/rSl/L+978/DQ0NO2M2AAAAAAAAAF5Dl4PvwoULM3PmzAwfPnwnjAMAAAAAAADA9upy8D3xxBN3xhwAAAAAAAAAdFG3vsMXAAAAAAAAgOIVHnyvvPLK7LvvvqlWq5k0aVJWrlz5mvtv2LAhp5xySkaNGpWGhoYceOCBue2223ppWgAAetKWJFtS67VXa2rZ9J+v1l4875aif6MBAAAA2G11+ZHOPemmm27K/Pnzc80112TSpEm54oorMn369KxevTpveMMbXrX/li1bcswxx+QNb3hD/vVf/zWjR4/OmjVrfJ8wAEBJfaboAQAAAACg5AoNvosXL86JJ56YuXPnJkmuueaa3Hrrrbn++utzzjnnvGr/66+/Ps8991x+8pOfpH///kmSfffdtzdHBgAAAAAAANhlFBZ8t2zZknvuuScLFizo2FZXV5dp06ZlxYoVW11zyy23ZPLkyTnllFOybNmyvP71r8//+l//K5/85CdTX1+/1TWtra1pbW3t+Lm5ublnLwQAgC6pVqtpamoq5NwtLS2ZMWNGkmTZsmWpVqu9PkMR5wQAAABg91VY8H3mmWfS1taWxsbGTtsbGxvz8MMPb3XNb37zm/z7v/97Zs2aldtuuy2//vWvc/LJJ+ell17KBRdcsNU1ixYtyoUXXtjj8wMA0D2VSiUDBw4seoxUq9VdYg4AAAAA2BF1RQ/QFe3t7XnDG96QL33pSxk/fnyOO+64nHvuubnmmmu2uWbBggXZuHFjx+uJJ57oxYkBAAAAAAAAdp7C7vAdMWJE6uvrs379+k7b169fn5EjR251zahRo9K/f/9Oj28++OCDs27dumzZsiUDBgx41ZqGhoY0NDT07PAAAAAAAAAAu4DC7vAdMGBAxo8fn+XLl3dsa29vz/LlyzN58uStrpkyZUp+/etfp729vWPbI488klGjRm019gIAAAAAAADszgp9pPP8+fPz5S9/OV/96lfz0EMP5WMf+1g2b96cuXPnJknmzJmTBQsWdOz/sY99LM8991w+/vGP55FHHsmtt96aSy+9NKecckpRlwAAAAAAAABQmMIe6Zwkxx13XJ5++umcf/75WbduXcaNG5fbb789jY2NSZLHH388dXV/bNJjxoxJU1NTzjjjjBx66KEZPXp0Pv7xj+eTn/xkUZcAAAAAAAAAUJhCg2+SnHrqqTn11FO3+t6dd975qm2TJ0/OT3/60508FQAAAAAAAMCur9BHOgMAAAAAAADQfYIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEn1K3oAAAAAoHtqtVpaWlq6tfaV67p7jCSpVqupVCrdXg8AAMCOEXwBAACgpFpaWjJ9+vQdPs6MGTO6vbapqSkDBw7c4RkAAADoHsEXAAAAKBV3NgMAAPyR4AsAAAAlVa1W09TU1K21tVotra2tSZKGhoZux8tqtdqtdTvCnc0AAAB/JPgCAABASVUqlR2KjoMGDerBaQAAACiC4AsAAACUSl+9sxkAAGBrBF8AAACgVNzZDAAA8Ed1RQ8AAAAAAAAAQPcIvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFK7RPC98sors++++6ZarWbSpElZuXLlNvf9yle+kkql0ulVrVZ7cVoAAAAAAACAXUPhwfemm27K/Pnzc8EFF+Tee+/N2LFjM3369Dz11FPbXDN06NA8+eSTHa81a9b04sQAAAAAAAAAu4Z+RQ+wePHinHjiiZk7d26S5Jprrsmtt96a66+/Puecc85W11QqlYwcObI3xwQA2KXUarW0tLR0e/0r1+7IcarVaiqVSrfXAwAAAAA7ptDgu2XLltxzzz1ZsGBBx7a6urpMmzYtK1as2Oa6TZs2ZZ999kl7e3sOP/zwXHrppXnrW9+61X1bW1vT2tra8XNzc3PPXQAAQEFaWloyffr0HjnWjBkzur22qakpAwcO7JE5AAAAAICuK/SRzs8880za2trS2NjYaXtjY2PWrVu31TUHHXRQrr/++ixbtixLly5Ne3t7jjrqqKxdu3ar+y9atCjDhg3reI0ZM6bHrwMAAAAAAACgCIU/0rmrJk+enMmTJ3f8fNRRR+Xggw/OF7/4xXzqU5961f4LFizI/PnzO35ubm4WfQGA0qtWq2lqaur2+lqt1vEUlIaGhm4/lrlarXZ7BgAAAABgxxUafEeMGJH6+vqsX7++0/b169dv93f09u/fP4cddlh+/etfb/X9hoaGNDQ07PCsAAC7kkqlssOPUh40aFAPTQMAAAAAFKXQRzoPGDAg48ePz/Llyzu2tbe3Z/ny5Z3u4n0tbW1tefDBBzNq1KidNSYAAAAAAADALqnwRzrPnz8/H/nIRzJhwoRMnDgxV1xxRTZv3py5c+cmSebMmZPRo0dn0aJFSZKLLrooRx55ZPbff/9s2LAh//iP/5g1a9bkhBNOKPIyAAAAAAAAAHpd4cH3uOOOy9NPP53zzz8/69aty7hx43L77bensbExSfL444+nru6PNyI///zzOfHEE7Nu3bq87nWvy/jx4/OTn/wkb3nLW4q6BAAAAAAAAIBCFB58k+TUU0/NqaeeutX37rzzzk4/L1myJEuWLOmFqQAAAAAAAAB2bYV+hy8AAAAAAAAA3Sf4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACXVr+gBAACA11ar1dLS0tLt9a9cuyPHqVarqVQq3V4PAAAAQM8TfAEAYBfX0tKS6dOn98ixZsyY0e21TU1NGThwYI/MAQAAAEDP8EhnAAAAAAAAgJJyhy8AAOziqtVqmpqaur2+VqultbU1SdLQ0NDtxzJXq9VuzwAAAADAziH4AgDALq5Sqezwo5QHDRrUQ9MAAAAAsCvxSGcAAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBdnPXXnttpk6dmmuvvbboUQAAAAAAgB4m+ALsxjZs2JClS5emvb09S5cuzYYNG4oeCQAAAAAA6EGCL8Bu7Nxzz017e3uSpL29Peedd17BEwEAAAAAAD1J8AXYTa1atSoPPvhgp20PPPBAVq1aVdBEAAAAAABATxN8AXZD7e3tWbhw4VbfW7hwYcddvwAAAAAAQLkJvgC7oRUrVqS5uXmr7zU3N2fFihW9PBEAAAAAALAzCL4Au6HJkydn6NChW31v2LBhmTx5ci9PBAAAAAAA7AyCL8BuqK6ubpuPdL7wwgtTV+cf/wAAAAAAsDvwJ/4Au6kJEybkkEMO6bTt0EMPzeGHH17QRAAAAAAAQE8TfAF2Y5dccknH3bx1dXW5+OKLC54IAAAAAADoSYIvwG5s+PDhmT17durq6jJ79uwMHz686JEAAAAAAIAe1K/oAQDYuU444YSccMIJRY8BAAAAAADsBO7wBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF+gz7j22mszderUXHvttUWPAgAAAAAA0CMEX6BP2LBhQ5YuXZr29vYsXbo0GzZsKHokAAAAAACAHSb4An3Cueeem/b29iRJe3t7zjvvvIInAgAAAAAA2HGCL7DbW7VqVR588MFO2x544IGsWrWqoIkAAAAAAAB6huAL7Nba29uzcOHCrb63cOHCjrt+AQAAAAAAykjwBXZrK1asSHNz81bfa25uzooVK3p5IgAAAAAAgJ4j+AK7tcmTJ2fo0KFbfW/YsGGZPHlyL08EAAAAAADQcwRfYLdWV1e3zUc6X3jhhamr849BAAAAAACgvJQOYLc3YcKEHHLIIZ22HXrooTn88MMLmggAAAAAAKBnCL5An3DJJZd03M1bV1eXiy++uOCJAAAAAAAAdpzgC/QJw4cPz+zZs1NXV5fZs2dn+PDhRY8EAAAAAACww/oVPQBAbznhhBNywgknFD0GAAAAAABAj3GHLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgS5927bXXZurUqbn22muLHgUAAAAAAAC6rF/RA0BRNmzYkKVLl6a9vT1Lly7NX//1X2f48OFFjwUAvIZarZaWlpZur3/l2h05TrVaTaVS6fZ6AAAAAOgpgi991rnnnpv29vYkSXt7e84777x84QtfKHgqAOC1tLS0ZPr06T1yrBkzZnR7bVNTUwYOHNgjcwAAAADAjvBIZ/qkVatW5cEHH+y07YEHHsiqVasKmggAAAAAAAC6zh2+9Dnt7e1ZuHDhVt9buHBhbrnlltTV+bsQALArqlaraWpq6vb6Wq2W1tbWJElDQ0O3H8tcrVa7PQMAAAAA9CTBlz5nxYoVaW5u3up7zc3NWbFiRaZMmdLLUwEA26NSqezwo5QHDRrUQ9MAAAAAQPHcxkifM3ny5AwdOnSr7w0bNiyTJ0/u5YkAAAAAAACgewRf+py6urptPtL5wgsv9DhnAAAAAAAASkPZok+aMGFCDjnkkE7bDj300Bx++OEFTQQAAAAAAABdJ/jSZ11yySUdd/PW1dXl4osvLngiAAAAAAAA6JpdIvheeeWV2XfffVOtVjNp0qSsXLlyu9Z985vfTKVSybHHHrtzB2S3NHz48MyePTt1dXWZPXt2hg8fXvRIAAAAAAAA0CWFB9+bbrop8+fPzwUXXJB77703Y8eOzfTp0/PUU0+95rrHHnssZ511Vo4++uhempTd0QknnJA777wzJ5xwQtGjAAAAAAAAQJcVHnwXL16cE088MXPnzs1b3vKWXHPNNRk0aFCuv/76ba5pa2vLrFmzcuGFF2a//fZ7zeO3tramubm50wsAAAAAAABgd1Bo8N2yZUvuueeeTJs2rWNbXV1dpk2blhUrVmxz3UUXXZQ3vOENmTdv3p88x6JFizJs2LCO15gxY3pkdgAAAAAAAICiFRp8n3nmmbS1taWxsbHT9sbGxqxbt26ra3784x/nuuuuy5e//OXtOseCBQuycePGjtcTTzyxw3MDAAAAAAAA7Ar6FT1AV7zwwgv58Ic/nC9/+csZMWLEdq1paGhIQ0PDTp4MAAAAAAAAoPcVGnxHjBiR+vr6rF+/vtP29evXZ+TIka/a/z/+4z/y2GOP5f3vf3/Htvb29iRJv379snr16rzpTW/auUMDAAAAAAAA7CIKfaTzgAEDMn78+CxfvrxjW3t7e5YvX57Jkye/av83v/nNefDBB3P//fd3vD7wgQ/kne98Z+6//37fzwsAAAAAAAD0KYU/0nn+/Pn5yEc+kgkTJmTixIm54oorsnnz5sydOzdJMmfOnIwePTqLFi1KtVrN2972tk7rhw8fniSv2g4AAAAAAACwuys8+B533HF5+umnc/7552fdunUZN25cbr/99jQ2NiZJHn/88dTVFXojMgAAAAAAAMAuqVKr1WpFD9GbmpubM2zYsGzcuDFDhw4tehzodb/73e8yffr0JElTU1MGDhxY8EQAAAAAAMXRDYCyc+ssAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlFS/ogcAuq5Wq6WlpaVba1+5rrvHSJJqtZpKpdLt9QAAAAAAAOw4wRdKqKWlJdOnT9/h48yYMaPba5uamjJw4MAdngEAAAAAAIDu80hnAAAAAAAAgJJyhy+UULVaTVNTU7fW1mq1tLa2JkkaGhq6/VjmarXarXUAAAAAAAD0HMEXSqhSqezQ45QHDRrUg9MAAAAAAABQFI90BgD6vLvuuiszZ87MXXfdVfQoAAAAAABdIvgCAH1aS0tLLr/88qxfvz6XX355Wlpaih4JAAAAAGC7Cb4AQJ+2dOnSPPvss0mSZ599NjfeeGPBEwEAAAAAbD/BFwDos9auXZsbb7wxtVotSVKr1XLjjTdm7dq1BU8GAAAAALB9BF8AoE+q1WpZsmTJNrf/IQIDAAAAAOzKBF8AoE9as2ZN7r777rS1tXXa3tbWlrvvvjtr1qwpaDIAAAAAgO0n+AIAfdI+++yTI444IvX19Z2219fXZ+LEidlnn30KmgwAAAAAYPsJvgBAn1SpVHLGGWdsc3ulUilgKgAAAACArhF8AYA+a++9986sWbM64m6lUsmsWbMyevTogicDAAAAANg+gi8A0KfNnj07e+21V5JkxIgRmTVrVsETAQAAAABsP8EXAOjTqtVqzjzzzDQ2Nmb+/PmpVqtFjwQAAAAAsN0qtVqtVvQQvam5uTnDhg3Lxo0bM3To0KLHAQAAAAAACqQbAGXnDl8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJLaJYLvlVdemX333TfVajWTJk3KypUrt7nvzTffnAkTJmT48OHZY489Mm7cuHz961/vxWkBAAAAAAAAdg2FB9+bbrop8+fPzwUXXJB77703Y8eOzfTp0/PUU09tdf8999wz5557blasWJEHHnggc+fOzdy5c9PU1NTLkwMAAAAAAAAUq1Kr1WpFDjBp0qQcccQR+cIXvpAkaW9vz5gxY3LaaaflnHPO2a5jHH744Xnve9+bT33qU39y3+bm5gwbNiwbN27M0KFDd2h2AAAAAACg3HQDoOwKvcN3y5YtueeeezJt2rSObXV1dZk2bVpWrFjxJ9fXarUsX748q1evzjve8Y6t7tPa2prm5uZOLwAAAAAAAIDdQaHB95lnnklbW1saGxs7bW9sbMy6deu2uW7jxo0ZPHhwBgwYkPe+9735/Oc/n2OOOWar+y5atCjDhg3reI0ZM6ZHrwEAAAAAAACgKIV/h293DBkyJPfff3/uvvvuXHLJJZk/f37uvPPOre67YMGCbNy4seP1xBNP9O6wAAAAAAAAADtJvyJPPmLEiNTX12f9+vWdtq9fvz4jR47c5rq6urrsv//+SZJx48bloYceyqJFizJ16tRX7dvQ0JCGhoYenRsAAAAAAABgV1DoHb4DBgzI+PHjs3z58o5t7e3tWb58eSZPnrzdx2lvb09ra+vOGBEAAAAAAABgl1XoHb5JMn/+/HzkIx/JhAkTMnHixFxxxRXZvHlz5s6dmySZM2dORo8enUWLFiX5/XfyTpgwIW9605vS2tqa2267LV//+tdz9dVXF3kZAAAAAAAAAL2u8OB73HHH5emnn87555+fdevWZdy4cbn99tvT2NiYJHn88cdTV/fHG5E3b96ck08+OWvXrs3AgQPz5je/OUuXLs1xxx1X1CUAAAAAAAAAFKJSq9VqRQ/Rm5qbmzNs2LBs3LgxQ4cOLXocAAAAAACgQLoBUHaFfocvAAAAAAAAAN0n+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvgAAAAAAAAAlJfgCAAAAAAAAlJTgCwAAAAAAAFBSgi8AAAAAAABASQm+AAAAAAAAACUl+AIAAAAAAACUlOALAAAAAAAAUFKCLwAAAAAAAEBJCb4AAAAAAAAAJSX4kiS59tprM3Xq1Fx77bVFjwIAAAAAAABsJ8GXbNiwIUuXLk17e3uWLl2aDRs2FD0SAAAAAAAAsB0EX3Luueemvb09SdLe3p7zzjuv4IkAAAAAAACA7SH49nGrVq3Kgw8+2GnbAw88kFWrVhU0EQAAAAAAALC9BN8+rL29PQsXLtzqewsXLuy46xcAAAAAAADYNQm+fdiKFSvS3Ny81feam5uzYsWKXp4IAAAAAAAA6ArBtw+bPHlyhg4dutX3hg0blsmTJ/fyRAAAAAAAAEBXCL59WF1d3TYf6XzhhRemrs7/PQAAAAAAAGBXpuj1cRMmTMghhxzSaduhhx6aww8/vKCJAAAAAAAAgO0l+JJLLrmk427eurq6XHzxxQVPBAAAAAAAAGwPwZcMHz48s2fPTl1dXWbPnp3hw4cXPRIAAAAAAACwHSq1Wq1W9BC9qbm5OcOGDcvGjRszdOjQoscBAAAAAAAKpBsAZecOXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAAAAAAAAgJISfAEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEqqX9ED9LZarZYkaW5uLngSAAAAAACgaH/oBX/oBwBl0+eC7wsvvJAkGTNmTMGTAAAAAAAAu4oXXnghw4YNK3oMgC6r1PrYX1lpb2/P//t//y9DhgxJpVIpehwoRHNzc8aMGZMnnngiQ4cOLXocAAri8wAAnwUAJD4PoFar5YUXXsif/dmfpa7ON2EC5dPn7vCtq6vL3nvvXfQYsEsYOnSof4kHwOcBAD4LAEji84C+zZ29QJn5qyoAAAAAAAAAJSX4AgAAAAAAAJSU4At9UENDQy644II0NDQUPQoABfJ5AIDPAgASnwcAUHaVWq1WK3oIAAAAAAAAALrOHb4AAAAAAAAAJSX4AgAAAAAAAJSU4AsAAAAAAABQUoIvAAAAAAAAQEkJvrAbO/7441OpVFKpVNK/f//8+Z//eT7xiU+kpaWlY58/vP/K19vf/vYCpwagu9atW5ePf/zj2X///VOtVtPY2JgpU6bk6quvzosvvpgk2XfffVOpVPLTn/6009rTTz89U6dO7fh54cKFnT4bhg0blqOPPjo//OEPe/OSAOiCtra2HHXUUfnQhz7UafvGjRszZsyYnHvuuR3bvvWtb+W//bf/lte97nUZOHBgDjrooPzt3/5t7rvvvo59vvKVr3T6LBg8eHDGjx+fm2++udeuCYDfO/7443PsscfutONPnTq145/31Wo1Bx54YBYtWpRarbbTzgkA9BzBF3Zz7373u/Pkk0/mN7/5TZYsWZIvfvGLueCCCzrtc8MNN+TJJ5/seN1yyy0FTQtAd/3mN7/JYYcdljvuuCOXXnpp7rvvvqxYsSKf+MQn8p3vfCff//73O/atVqv55Cc/+SeP+da3vrXjs2HFihU54IAD8r73vS8bN27cmZcCQDfV19fnK1/5Sm6//fbceOONHdtPO+207Lnnnh3/HfDJT34yxx13XMaNG5dbbrklq1evzje+8Y3st99+WbBgQadjDh06tOOz4L777sv06dPzN3/zN1m9enWvXhsAO9+JJ56YJ598MqtXr86CBQty/vnn55prril6LABgOwi+sJtraGjIyJEjM2bMmBx77LGZNm1avve973XaZ/jw4Rk5cmTHa8899yxoWgC66+STT06/fv2yatWq/M3f/E0OPvjg7LfffpkxY0ZuvfXWvP/97+/Y96STTspPf/rT3Hbbba95zH79+nV8NrzlLW/JRRddlE2bNuWRRx7Z2ZcDQDcdeOCB+fSnP53TTjstTz75ZJYtW5ZvfvOb+drXvpYBAwbkpz/9aT772c9m8eLFWbx4cY4++ui88Y1vzPjx43Peeeflu9/9bqfjVSqVjs+CAw44IBdffHHq6urywAMPFHSFAPxXP/zhDzNx4sQ0NDRk1KhROeecc/Lyyy93vP/CCy9k1qxZ2WOPPTJq1KgsWbIkU6dOzemnn97pOIMGDcrIkSOzzz77ZO7cuTn00EM7/RlSa2trzjrrrIwePTp77LFHJk2alDvvvLPTMb785S9nzJgxGTRoUD74wQ9m8eLFGT58+E68egAgEXyhT/nFL36Rn/zkJxkwYEDRowDQg5599tnccccdOeWUU7LHHntsdZ9KpdLx6z//8z/PRz/60SxYsCDt7e3bdY7W1tbccMMNGT58eA466KAemRuAneO0007L2LFj8+EPfzgnnXRSzj///IwdOzZJ8k//9E8ZPHhwTj755K2ufeXnxX/V1taWr371q0mSww8/vOcHB6DLfvvb3+Y973lPjjjiiPz85z/P1Vdfneuuuy4XX3xxxz7z58/PXXfdlVtuuSXf+9738qMf/Sj33nvvNo9Zq9Xyox/9KA8//HCnP0M69dRTs2LFinzzm9/MAw88kJkzZ+bd7353fvWrXyVJ7rrrrnz0ox/Nxz/+8dx///055phjcskll+y8iwcAOgi+sJv7zne+k8GDB6dareaQQw7JU089lbPPPrvTPv/zf/7PDB48uOP17W9/u5hhAeiWX//616nVaq8KsSNGjOj4Z/t/fYTzeeedl0cffbTTIz//qwcffLBj/cCBA3PZZZfln/7pnzJ06NCdch0A9IxKpZKrr746y5cvT2NjY84555yO9x555JHst99+6devX8e2xYsXd/rvgVc+un/jxo0d2wcMGJCPfexj+dKXvpQ3velNvXpNAGzdVVddlTFjxuQLX/hC3vzmN+fYY4/NhRdemMsvvzzt7e154YUX8tWvfjWXXXZZ3vWud+Vtb3tbbrjhhrS1tW31WIMHD05DQ0Pe8Y53pL29PX//93+fJHn88cdzww035F/+5V9y9NFH501velPOOuusvP3tb88NN9yQJPn85z+fv/qrv8pZZ52VAw88MCeffHL+6q/+qld/PwCgr+r3p3cByuyd73xnrr766mzevDlLlixJv3798t//+3/vtM+SJUsybdq0jp9HjRrV22MCsBOsXLky7e3tmTVrVlpbWzu99/rXvz5nnXVWzj///Bx33HFbXX/QQQd1fK/7Cy+8kJtuuikzZ87MD37wg0yYMGGnzw9A911//fUZNGhQHn300axduzb77rvvNvf927/923zgAx/Iz372s8yePTu1Wq3jvSFDhnTcBfbiiy/m+9//fj760Y9mr7326vR1AQAU46GHHsrkyZM7PaFhypQp2bRpU9auXZvnn38+L730UiZOnNjx/rBhw7b61J5Zs2bl3HPPzfPPP58LLrggRx11VI466qgkv//LoG1tbTnwwAM7rWltbc1ee+2VJFm9enU++MEPdnp/4sSJ+c53vtNj1wsAbJ3gC7u5PfbYI/vvv3+S3/+hz9ixY3Pddddl3rx5HfuMHDmyYx8Aymf//fdPpVLJ6tWrO23fb7/9kiQDBw7c6rr58+fnqquuylVXXbXV9wcMGNDp8+Gwww7Lt7/97VxxxRVZunRpD00PQE/7yU9+kiVLluSOO+7IxRdfnHnz5uX73/9+KpVKDjjggPz4xz/OSy+9lP79+ydJhg8fnuHDh2ft2rWvOlZdXV2nz4JDDz00d9xxRz7zmc8IvgC7mWHDhnX8M/+f//mfs//+++fII4/MtGnTsmnTptTX1+eee+5JfX19p3WDBw8uYlwA4BU80hn6kLq6uvzv//2/c9555+V3v/td0eMA0EP22muvHHPMMfnCF76QzZs3b/e6wYMH5x/+4R9yySWX5IUXXtiuNfX19T5DAHZhL774Yo4//vh87GMfyzvf+c5cd911WblyZa655pokv/86l02bNm3zL/tsD58FALuOgw8+OCtWrOj0dIa77rorQ4YMyd5775399tsv/fv3z913393x/saNG/PII4+85nEHDx6cj3/84znrrLNSq9Vy2GGHpa2tLU899VT233//Tq+RI0cm+f0Tgl55niSv+hkA2DkEX+hjZs6cmfr6+lx55ZVFjwJAD7rqqqvy8ssvZ8KECbnpppvy0EMPZfXq1Vm6dGkefvjhV/0t/D846aSTMmzYsHzjG9941Xsvv/xy1q1bl3Xr1uVXv/pVLr744vzf//t/M2PGjJ19OQB004IFC1Kr1fLpT386SbLvvvvmsssuyyc+8Yk89thjmTx5cs4888yceeaZmT9/fn784x9nzZo1+elPf5rrrrsulUoldXV//KOCWq3W8Vnw6KOP5ktf+lKampp8FgAUYOPGjbn//vs7vU466aQ88cQTOe200/Lwww9n2bJlueCCCzJ//vzU1dVlyJAh+chHPpKzzz47P/jBD/LLX/4y8+bNS11dXafHQG/N3/3d3+WRRx7Jt771rRx44IGZNWtW5syZk5tvvjmPPvpoVq5cmUWLFuXWW29Nkpx22mm57bbbsnjx4vzqV7/KF7/4xXz3u9/9k+cBAHac4At9TL9+/XLqqafms5/9bJfuAgNg1/amN70p9913X6ZNm5YFCxZk7NixmTBhQj7/+c/nrLPOyqc+9amtruvfv38+9alPpaWl5VXv/fKXv8yoUaMyatSojBs3Lv/8z/+cq6++OnPmzNnZlwNAN/zwhz/MlVdemRtuuCGDBg3q2P53f/d3OeqoozJv3rzUarVcdtll+cY3vpH77rsv73vf+3LAAQdk5syZaW9vz4oVKzJ06NCOtc3NzR2fBQcffHAuv/zyXHTRRTn33HOLuESAPu3OO+/MYYcd1un1qU99KrfddltWrlyZsWPH5qMf/WjmzZuX8847r2Pd4sWLM3ny5Lzvfe/LtGnTMmXKlBx88MGpVquveb4999wzc+bMycKFC9Pe3p4bbrghc+bMyZlnnpmDDjooxx57bO6+++688Y1vTPL77w6+5pprsnjx4owdOza33357zjjjjD95HgBgx1Vqr3zeBwAAAAAAu63Nmzdn9OjRufzyyzNv3rydeq4TTzwxDz/8cH70ox/t1PMAQF/Xr+gBAAAAAADYOe677748/PDDmThxYjZu3JiLLrooSXbK4/kvu+yyHHPMMdljjz3y3e9+N1/96ld36HvjAYDtI/gCAAAAAOzGLrvssqxevToDBgzI+PHj86Mf/SgjRozo8fOsXLkyn/3sZ/PCCy9kv/32y+c+97mccMIJPX4eAKAzj3QGAAAAAAAAKKm6ogcAAAAAAAAAoHsEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpARfAACA/2Lq1Kk5/fTTt3v/r3zlKxk+fPhOmwcAAABgWwRfAAAAAAAAgJISfAEAAAAAAABKSvAFAABKY+rUqTnttNNy+umn53Wve10aGxvz5S9/OZs3b87cuXMzZMiQ7L///vnud7/bseaHP/xhJk6cmIaGhowaNSrnnHNOXn755Y73N2/enDlz5mTw4MEZNWpULr/88ledt7W1NWeddVZGjx6dPfbYI5MmTcqdd97ZG5cMAAAA8JoEXwAAoFS++tWvZsSIEVm5cmVOO+20fOxjH8vMmTNz1FFH5d57781f/uVf5sMf/nBefPHF/Pa3v8173vOeHHHEEfn5z3+eq6++Otddd10uvvjijuOdffbZ+eEPf5hly5bljjvuyJ133pl777230zlPPfXUrFixIt/85jfzwAMPZObMmXn3u9+dX/3qV719+QAAAACdVGq1Wq3oIQAAALbH1KlT09bWlh/96EdJkra2tgwbNiwf+tCH8rWvfS1Jsm7duowaNSorVqzIv/3bv+Vb3/pWHnrooVQqlSTJVVddlU9+8pPZuHFjXnzxxey1115ZunRpZs6cmSR57rnnsvfee+ekk07KFVdckccffzz77bdfHn/88fzZn/1ZxyzTpk3LxIkTc+mll+YrX/lKTj/99GzYsKF3f0MAAACAPq9f0QMAAAB0xaGHHtrx6/r6+uy111455JBDOrY1NjYmSZ566qk89NBDmTx5ckfsTZIpU6Zk06ZNWbt2bZ5//vls2bIlkyZN6nh/zz33zEEHHdTx84MPPpi2trYceOCBneZobW3NXnvt1ePXBwAAANAVgi8AAFAq/fv37/RzpVLptO0Pcbe9vb1Hzrdp06bU19fnnnvuSX19faf3Bg8e3CPnAAAAAOguwRcAANhtHXzwwfnWt76VWq3WEYLvuuuuDBkyJHvvvXf23HPP9O/fPz/72c/yxje+MUny/PPP55FHHslf/MVfJEkOO+ywtLW15amnnsrRRx9d2LUAAAAAbE1d0QMAAADsLCeffHKeeOKJnHbaaXn44YezbNmyXHDBBZk/f37q6uoyePDgzJs3L2effXb+/d//Pb/4xS9y/PHHp67uj/+pdOCBB2bWrFmZM2dObr755jz66KNZuXJlFi1alFtvvbXAqwMAAABwhy8AALAbGz16dG677bacffbZGTt2bPbcc8/Mmzcv5513Xsc+//iP/5hNmzbl/e9/f4YMGZIzzzwzGzdu7HScG264IRdffHHOPPPM/Pa3v82IESNy5JFH5n3ve19vXxIAAABAJ5VarVYreggAAAAAAAAAus4jnQEAAAAAAABKSvAFAAAAAAAAKCnBFwAAAAAAAKCkBF8AAAAAAACAkhJ8AQAAAAAAAEpK8AUAAAAAAAAoKcEXAAAAAAAAoKQEXwAAAAAAAICSEnwBAAAAAAAASkrwBQAAAAAAACgpwRcAAAAAAACgpP4/YC3cMrrRhKcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67da277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_fit)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Fit and Score Time')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2daaa554",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "819a3bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_roc_auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_f1_weighted</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_precision_weighted</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_recall_weighted</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_balanced_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GNB</th>\n",
       "      <td>0.059756</td>\n",
       "      <td>0.914567</td>\n",
       "      <td>0.185115</td>\n",
       "      <td>0.701352</td>\n",
       "      <td>0.167013</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.157099</td>\n",
       "      <td>0.734207</td>\n",
       "      <td>0.149215</td>\n",
       "      <td>0.724588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.018029</td>\n",
       "      <td>0.984225</td>\n",
       "      <td>0.060238</td>\n",
       "      <td>0.941920</td>\n",
       "      <td>0.046155</td>\n",
       "      <td>0.950771</td>\n",
       "      <td>0.057403</td>\n",
       "      <td>0.942903</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>0.941413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.307230</td>\n",
       "      <td>0.834022</td>\n",
       "      <td>0.222987</td>\n",
       "      <td>0.819738</td>\n",
       "      <td>0.228602</td>\n",
       "      <td>0.829122</td>\n",
       "      <td>0.210987</td>\n",
       "      <td>0.828205</td>\n",
       "      <td>0.237660</td>\n",
       "      <td>0.808168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.030217</td>\n",
       "      <td>0.976915</td>\n",
       "      <td>0.202831</td>\n",
       "      <td>0.835196</td>\n",
       "      <td>0.145709</td>\n",
       "      <td>0.875150</td>\n",
       "      <td>0.157514</td>\n",
       "      <td>0.863454</td>\n",
       "      <td>0.204160</td>\n",
       "      <td>0.834063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_roc_auc           test_f1_weighted            \\\n",
       "                std      mean              std      mean   \n",
       "model                                                      \n",
       "GNB        0.059756  0.914567         0.185115  0.701352   \n",
       "LogReg     0.018029  0.984225         0.060238  0.941920   \n",
       "RF         0.307230  0.834022         0.222987  0.819738   \n",
       "XGB        0.030217  0.976915         0.202831  0.835196   \n",
       "\n",
       "       test_precision_weighted           test_recall_weighted            \\\n",
       "                           std      mean                  std      mean   \n",
       "model                                                                     \n",
       "GNB                   0.167013  0.782733             0.157099  0.734207   \n",
       "LogReg                0.046155  0.950771             0.057403  0.942903   \n",
       "RF                    0.228602  0.829122             0.210987  0.828205   \n",
       "XGB                   0.145709  0.875150             0.157514  0.863454   \n",
       "\n",
       "       test_balanced_accuracy            \n",
       "                          std      mean  \n",
       "model                                    \n",
       "GNB                  0.149215  0.724588  \n",
       "LogReg               0.067505  0.941413  \n",
       "RF                   0.237660  0.808168  \n",
       "XGB                  0.204160  0.834063  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = list(set(results_long_nofit.metrics.values))\n",
    "bootstrap_df.groupby(['model'])[metrics].agg([np.std, np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a495be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">score_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GNB</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.020254</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.022681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.009717</td>\n",
       "      <td>0.031297</td>\n",
       "      <td>36.378952</td>\n",
       "      <td>96.034527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.023786</td>\n",
       "      <td>0.023855</td>\n",
       "      <td>0.804588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.037449</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.779592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score_time             fit_time           \n",
       "              std      mean        std       mean\n",
       "model                                            \n",
       "GNB      0.001387  0.020254   0.001159   0.022681\n",
       "LogReg   0.009717  0.031297  36.378952  96.034527\n",
       "RF       0.002597  0.023786   0.023855   0.804588\n",
       "XGB      0.001586  0.037449   0.014776   0.779592"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_metrics = list(set(results_long_fit.metrics.values))\n",
    "bootstrap_df.groupby(['model'])[time_metrics].agg([np.std, np.mean])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74976342-0409-40f7-9a66-6fba19753cb1",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8d45ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "for i, clf in enumerate([logreg_hyperparams.best_estimator_, rf_hyperparams.best_estimator_, gnb_hyperparams.best_estimator_, xgb_hyperparams.best_estimator_]):\n",
    "    prediction = cross_val_predict(clf, X, y, cv=cv, groups=group)\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y, prediction, display_labels=np.unique(y), normalize='true')\n",
    "    disp.plot(ax=axes[i], colorbar=True, cmap='coolwarm')\n",
    "    disp.ax_.set_title(f\"Model {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dcc2fcc",
   "metadata": {},
   "source": [
    "### McNemar's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2992dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = cross_val_predict(logreg, X, y, cv=cv, groups=group)\n",
    "xgb_pred = cross_val_predict(xgb, X, y, cv=cv, groups=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d71ec4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[26535  1580]\n",
      " [ 1081   745]]\n",
      "chi-squared: 93.19954904171364\n",
      "p-value: 4.727888564316315e-22\n"
     ]
    }
   ],
   "source": [
    "tb = mcnemar_table(y_target=y, \n",
    "                   y_model1=logreg_pred, \n",
    "                   y_model2=xgb_pred )\n",
    "\n",
    "print(tb)\n",
    "\n",
    "chi2, p = mcnemar(ary=tb, corrected=True)\n",
    "print('chi-squared:', chi2)\n",
    "print('p-value:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f8f86",
   "metadata": {},
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "581570d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explainer = shap.Explainer(logreg, X)\n",
    "shap_values = explainer(X)\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2ecf6cd-8a73-4054-a03c-cb92973106e5",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9a114bca-858d-47ac-9454-2e4dd865be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    classmap = {\n",
    "        0: 'Baseline',\n",
    "        1: 'Stress'\n",
    "    }\n",
    "    c_code = port(logreg_hyperparams.best_estimator_, classmap=classmap)\n",
    "\n",
    "    with open('C:/Users/aless/OneDrive - Universit√† degli Studi di Catania/tesi/codes/arduinocode/Final_code/Classifier.h', 'w') as file:\n",
    "        file.write(c_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25a53023",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/Users/aless/OneDrive - Universit√† degli Studi di Catania/tesi/codes/ML and DL - Python/ML/classifier.sav'\n",
    "pickle.dump(logreg_hyperparams.best_estimator_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da538524",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "110a4ad9b3b23ac6a757cfb6c77f1e39e8d0496598f07ec14a944919c025e818"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
