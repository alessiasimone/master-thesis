{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47737138-e04c-4ce6-8d20-bed805d73508",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7108ae7f-e30e-4f11-a4ae-05c253044225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data mining\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "path = 'C:/Users/aless/OneDrive - Universit√† degli Studi di Catania/tesi/dataset/scaled_dataset.csv'\n",
    "\n",
    "#training\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import cross_validate, StratifiedGroupKFold, HalvingGridSearchCV, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#selection\n",
    "from mlxtend.evaluate import mcnemar_table, mcnemar\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "#interpretability\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "import shap\n",
    "\n",
    "#deployment\n",
    "from micromlgen import port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98b25b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_hr</th>\n",
       "      <th>max_hr</th>\n",
       "      <th>mean_hr</th>\n",
       "      <th>median_hr</th>\n",
       "      <th>var_hr</th>\n",
       "      <th>std_hr</th>\n",
       "      <th>skew_hr</th>\n",
       "      <th>kurt_hr</th>\n",
       "      <th>min_st</th>\n",
       "      <th>max_st</th>\n",
       "      <th>mean_st</th>\n",
       "      <th>median_st</th>\n",
       "      <th>var_st</th>\n",
       "      <th>std_st</th>\n",
       "      <th>skew_st</th>\n",
       "      <th>kurt_st</th>\n",
       "      <th>target</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.447531</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.469939</td>\n",
       "      <td>0.464876</td>\n",
       "      <td>0.008988</td>\n",
       "      <td>0.094470</td>\n",
       "      <td>0.531569</td>\n",
       "      <td>0.035987</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.944060</td>\n",
       "      <td>0.937919</td>\n",
       "      <td>0.937014</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.048639</td>\n",
       "      <td>0.504285</td>\n",
       "      <td>0.051480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.447658</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.471027</td>\n",
       "      <td>0.466061</td>\n",
       "      <td>0.008589</td>\n",
       "      <td>0.092343</td>\n",
       "      <td>0.527895</td>\n",
       "      <td>0.037719</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.944060</td>\n",
       "      <td>0.937961</td>\n",
       "      <td>0.937014</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.048661</td>\n",
       "      <td>0.503165</td>\n",
       "      <td>0.051407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.447722</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.472097</td>\n",
       "      <td>0.467611</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.089878</td>\n",
       "      <td>0.524656</td>\n",
       "      <td>0.039461</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>0.937979</td>\n",
       "      <td>0.937014</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.048870</td>\n",
       "      <td>0.504175</td>\n",
       "      <td>0.051732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.448104</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.473156</td>\n",
       "      <td>0.469282</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.087072</td>\n",
       "      <td>0.522211</td>\n",
       "      <td>0.040991</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.944667</td>\n",
       "      <td>0.938063</td>\n",
       "      <td>0.937014</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.049017</td>\n",
       "      <td>0.502161</td>\n",
       "      <td>0.051341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.449060</td>\n",
       "      <td>0.44192</td>\n",
       "      <td>0.474201</td>\n",
       "      <td>0.470771</td>\n",
       "      <td>0.007106</td>\n",
       "      <td>0.083957</td>\n",
       "      <td>0.520813</td>\n",
       "      <td>0.042076</td>\n",
       "      <td>0.928227</td>\n",
       "      <td>0.948555</td>\n",
       "      <td>0.938160</td>\n",
       "      <td>0.937014</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.050240</td>\n",
       "      <td>0.508913</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     min_hr   max_hr   mean_hr  median_hr    var_hr    std_hr   skew_hr  \\\n",
       "0  0.447531  0.44192  0.469939   0.464876  0.008988  0.094470  0.531569   \n",
       "1  0.447658  0.44192  0.471027   0.466061  0.008589  0.092343  0.527895   \n",
       "2  0.447722  0.44192  0.472097   0.467611  0.008139  0.089878  0.524656   \n",
       "3  0.448104  0.44192  0.473156   0.469282  0.007640  0.087072  0.522211   \n",
       "4  0.449060  0.44192  0.474201   0.470771  0.007106  0.083957  0.520813   \n",
       "\n",
       "    kurt_hr    min_st    max_st   mean_st  median_st    var_st    std_st  \\\n",
       "0  0.035987  0.928227  0.944060  0.937919   0.937014  0.002369  0.048639   \n",
       "1  0.037719  0.928227  0.944060  0.937961   0.937014  0.002371  0.048661   \n",
       "2  0.039461  0.928227  0.944667  0.937979   0.937014  0.002392  0.048870   \n",
       "3  0.040991  0.928227  0.944667  0.938063   0.937014  0.002406  0.049017   \n",
       "4  0.042076  0.928227  0.948555  0.938160   0.937014  0.002527  0.050240   \n",
       "\n",
       "    skew_st   kurt_st  target  ID  \n",
       "0  0.504285  0.051480     0.0   0  \n",
       "1  0.503165  0.051407     0.0   0  \n",
       "2  0.504175  0.051732     0.0   0  \n",
       "3  0.502161  0.051341     0.0   0  \n",
       "4  0.508913  0.054240     0.0   0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04ca0fb6-73db-47ec-9363-345d3fcad8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['ID', 'target'], axis=1, inplace=False)\n",
    "y = df.target\n",
    "groups = df.ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a157671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18780\n",
      "11220\n"
     ]
    }
   ],
   "source": [
    "false = (y == 0).sum()\n",
    "true = (y == 1).sum()\n",
    "\n",
    "print(false)\n",
    "print(true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20aae746",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb1e1615",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2c06d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 370\n",
      "max_resources_: 30000\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 180\n",
      "n_resources: 370\n",
      "Fitting 15 folds for each of 180 candidates, totalling 2700 fits\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.200, test=0.309) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.750, test=0.631) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.699, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.689, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.623, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.587, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.709, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.647, test=0.450) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.580, test=0.689) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.604, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.682, test=0.637) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.448) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.698, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.645, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.689, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.592, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.556, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.630, test=0.399) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=liblinear;, score=(train=0.585, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.750, test=0.631) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.699, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.692, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.750, test=0.631) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.699, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.692, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.678, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.698, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.688, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.715, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.750, test=0.631) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.696, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.710, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.750, test=0.631) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.699, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.692, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.200, test=0.309) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.750, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.699, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.692, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.642, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.604, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.706, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.669, test=0.450) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.591, test=0.882) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.640, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.682, test=0.637) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.735, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.696, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.659, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.689, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.595, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.594, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.647, test=0.478) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=liblinear;, score=(train=0.601, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.750, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.699, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.692, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cg;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.750, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.699, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.692, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.698, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.688, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.750, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.696, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.692, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.750, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.699, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.692, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.698, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.200, test=0.309) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.673, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.747, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.696, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.695, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.710, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=lbfgs;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.669, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.643, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.698, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.634, test=0.959) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.678, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.682, test=0.637) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.684, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.677, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.692, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.621, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.618, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.667, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.636, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.673, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.747, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.696, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.695, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.710, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.673, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.747, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.696, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.695, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.710, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=newton-cholesky;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.747, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.696, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.695, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.741, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=sag;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.673, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.683, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.691, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.747, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.696, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.695, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.710, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.200, test=0.309) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.688, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.684, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.744, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.715, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=lbfgs;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.669, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.647, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.698, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.670, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.676, test=0.917) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.691, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.685, test=0.580) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.741, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.678, test=0.450) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.706, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.646, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.648, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.693, test=0.612) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.681, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.688, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.684, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.744, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.698, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.715, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.688, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.684, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.744, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.715, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.688, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.684, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.744, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.698, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.715, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.698, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.688, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.684, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.744, test=0.575) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.661, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.698, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.715, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.701, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.200, test=0.309) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.747, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.656, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.678, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.668, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.698, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.679, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.680, test=0.767) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.685, test=0.580) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.744, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.679, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.681, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.704, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.674, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.774) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.709, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.747, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.656, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.698, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.747, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.656, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.701, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.747, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.656, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.698, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.680, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.701, test=0.480) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.747, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.656, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.698, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.739, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=liblinear;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l1, solver=saga;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.678, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.688, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.703, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.682, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.704, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.718, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.690, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.750, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.664, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.710, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.703, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.678, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.677, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.698, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.703, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.682, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.750, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.673, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.704, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.701, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.733, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.706, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.678, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.688, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.703, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.682, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.704, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.718, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.690, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.750, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.664, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.710, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.703, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.678, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.688, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.703, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.682, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.704, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.718, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.690, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.750, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.664, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.710, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.703, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.678, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.688, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.703, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.682, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.701, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.718, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.690, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.750, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.664, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.712, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.703, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.678, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.688, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.703, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.682, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.704, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.718, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.690, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.750, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.664, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.710, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.703, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.709, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.697, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.736, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.688, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.718, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.726, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.729, test=0.791) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.481) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.726, test=0.915) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.713, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.721, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.686, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.645, test=0.236) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.750, test=0.774) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.712, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.670, test=0.920) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.671, test=0.532) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.672, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.696, test=0.652) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.721, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.624, test=0.422) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.761, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.647, test=0.833) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.710, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.666, test=0.644) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.707, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.678, test=0.025) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.744, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=saga;, score=(train=0.704, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.691, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.685, test=0.580) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.670, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.718, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.753, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.681, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.688, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.698, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.688, test=0.580) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.706, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.709, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.676, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.752, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.673, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.704, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.710, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.692, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.712, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.691, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.685, test=0.580) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.670, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.718, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.753, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.691, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.685, test=0.580) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.670, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.718, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.753, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.691, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.701, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.685, test=0.580) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.701, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.670, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.718, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.753, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.691, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.701, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.685, test=0.580) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.701, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.670, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.718, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.753, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.701, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.697, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.706, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.691, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.721, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.729, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.693, test=0.601) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.693, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.705, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.712, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.689, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.750, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.698, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.688, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.712, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.699, test=0.652) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.712, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.735, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.693, test=0.422) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.775, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.679, test=0.915) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.702, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.695, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.715, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.747, test=0.822) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.743, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.693, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.709, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.688, test=0.546) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.718, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.702, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.752, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.667, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.712, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.692, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.736, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.693, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.698, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.688, test=0.580) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.729, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.679, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.761, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.670, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.709, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.710, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.736, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.693, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.709, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.688, test=0.546) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.718, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.702, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.752, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.667, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.712, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.692, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.736, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.693, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.709, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.688, test=0.546) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.718, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.702, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.752, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.667, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.692, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.736, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.693, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.709, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.688, test=0.546) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.721, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.702, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.752, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.667, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.701, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.712, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.692, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.736, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.693, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.709, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.688, test=0.546) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.718, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.702, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.752, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.667, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.699, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.701, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.712, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.692, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.736, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.704, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.697, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.698, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.691, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.724, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.735, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.702, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.764, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.705, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.706, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.715, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.706, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.747, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.710, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.691, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.721, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.699, test=0.652) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.712, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.735, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.696, test=0.422) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.772, test=0.373) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.673, test=0.915) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.710, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.698, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.710, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.701, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.750, test=0.780) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.749, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.695, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.709, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.688, test=0.601) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.718, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.705, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.758, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.670, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.707, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.695, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.715, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.738, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.693, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.700, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.706, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.694, test=0.546) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.726, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.732, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.702, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.764, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.679, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.705, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.701, test=0.803) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.715, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.701, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.738, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.732, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.695, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.709, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.688, test=0.601) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.718, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.705, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.758, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.670, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.707, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.695, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.715, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.738, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.695, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.709, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.688, test=0.601) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.718, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.705, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.758, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.670, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.707, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.695, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.715, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.738, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.695, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.709, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.688, test=0.601) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.718, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.705, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.758, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.670, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.707, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.695, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.715, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.738, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.695, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.709, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.688, test=0.601) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.718, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.705, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.758, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.670, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.707, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.695, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.715, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.695, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.738, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.749, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.734, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.752, test=0.814) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.714, test=0.791) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.749, test=0.959) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.736, test=0.601) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.798, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.705, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.733, test=0.739) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.749, test=0.920) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.738, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.740, test=0.492) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.787, test=0.783) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.744, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.725, test=0.532) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.749, test=0.814) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.702, test=0.833) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.744, test=0.959) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.755, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.722, test=0.546) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.792, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.713, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.736, test=0.637) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.741, test=0.878) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.736, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.743, test=0.492) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.767, test=0.783) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.763, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.710, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.703, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.729, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.694, test=0.652) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.726, test=0.871) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.713, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.696, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.722, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.878) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.718, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.704, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.747, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.741, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.704, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.700, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.723, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.694, test=0.652) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.726, test=0.822) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.710, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.767, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.716, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.698, test=0.878) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.701, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.747, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.741, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.710, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.703, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.729, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.694, test=0.652) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.726, test=0.871) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.713, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.696, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.722, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.878) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.718, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.704, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.747, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.741, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.710, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.703, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.729, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.694, test=0.652) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.726, test=0.871) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.713, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.696, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.722, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.878) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.718, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.704, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.747, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.741, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.710, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.703, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.729, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.694, test=0.652) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.726, test=0.871) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.713, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.696, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.722, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.701, test=0.878) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.718, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.704, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.747, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.741, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.710, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.703, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.729, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.694, test=0.652) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.726, test=0.871) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.738, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.713, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.696, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.722, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.701, test=0.878) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.718, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.704, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.747, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.741, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=liblinear;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=newton-cholesky;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=sag;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=elasticnet, solver=saga;, score=(train=nan, test=nan) total time=   0.0s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 60\n",
      "n_resources: 1110\n",
      "Fitting 15 folds for each of 60 candidates, totalling 900 fits\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.690, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.679, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.680, test=0.712) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.727, test=0.626) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.748, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.737, test=0.414) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.683, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.391) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.702, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.704, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.727, test=0.410) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.725, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=newton-cholesky;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.685, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.680, test=0.245) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.703, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.684, test=0.697) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.727, test=0.574) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.706, test=0.579) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.734, test=0.521) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.683, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.698, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.698, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.701, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.726, test=0.390) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.714, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=saga;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.685, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.680, test=0.245) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.703, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.684, test=0.697) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.727, test=0.574) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.706, test=0.579) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.734, test=0.521) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.683, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.698, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.726, test=0.390) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.714, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=newton-cholesky;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.689, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.681, test=0.273) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.702, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.682, test=0.697) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.725, test=0.574) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.708, test=0.562) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.736, test=0.437) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.684, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.697, test=0.391) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.703, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.702, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.725, test=0.390) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.718, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=saga;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.690, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.679, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.680, test=0.712) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.727, test=0.626) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.748, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.712, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.737, test=0.414) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.683, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.698, test=0.391) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.702, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.704, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.727, test=0.410) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.725, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.689, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.681, test=0.273) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.702, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.682, test=0.697) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.725, test=0.574) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.708, test=0.562) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.737, test=0.437) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.684, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.697, test=0.391) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.703, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.702, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.725, test=0.390) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.718, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.685, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.680, test=0.245) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.703, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.684, test=0.697) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.727, test=0.574) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.706, test=0.579) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.734, test=0.521) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.683, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.698, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.726, test=0.390) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.714, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=lbfgs;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.690, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.680, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.701, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.680, test=0.712) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.727, test=0.626) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.748, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.712, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.737, test=0.414) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.683, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.698, test=0.391) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.702, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.704, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.727, test=0.410) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.725, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=sag;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.690, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.680, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.701, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.680, test=0.712) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.727, test=0.626) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.748, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.712, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.737, test=0.414) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.683, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.699, test=0.391) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.702, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.704, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.727, test=0.410) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.725, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=saga;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.682, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.682, test=0.245) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.706, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.686, test=0.682) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.727, test=0.546) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.705, test=0.627) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.733, test=0.541) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.683, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.698, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.695, test=0.777) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.701, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.727, test=0.347) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.716, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=sag;, score=(train=0.743, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.685, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.680, test=0.245) total time=   0.0s\n",
      "[CV 3/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.703, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.685, test=0.697) total time=   0.0s\n",
      "[CV 5/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.727, test=0.574) total time=   0.0s\n",
      "[CV 6/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.706, test=0.579) total time=   0.0s\n",
      "[CV 8/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.734, test=0.521) total time=   0.0s\n",
      "[CV 9/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.683, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.698, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.698, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.701, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.726, test=0.390) total time=   0.0s\n",
      "[CV 14/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.714, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.0021544346900318843, penalty=l2, solver=sag;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.683, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.682, test=0.245) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.701, test=0.625) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.686, test=0.682) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.728, test=0.546) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.705, test=0.627) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.733, test=0.541) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.683, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.699, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.694, test=0.777) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.701, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.727, test=0.347) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.716, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=saga;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.683, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.682, test=0.245) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.686, test=0.682) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.728, test=0.546) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.705, test=0.627) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.733, test=0.541) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.683, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.699, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.695, test=0.777) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.729, test=0.347) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.716, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=lbfgs;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.683, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.682, test=0.245) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.686, test=0.682) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.728, test=0.546) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.705, test=0.627) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.733, test=0.541) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.683, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.699, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.695, test=0.777) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.729, test=0.347) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.716, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=newton-cholesky;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.683, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.682, test=0.245) total time=   0.0s\n",
      "[CV 3/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.686, test=0.682) total time=   0.0s\n",
      "[CV 5/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.728, test=0.546) total time=   0.0s\n",
      "[CV 6/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.705, test=0.627) total time=   0.0s\n",
      "[CV 8/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.733, test=0.541) total time=   0.0s\n",
      "[CV 9/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.683, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.699, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.695, test=0.777) total time=   0.0s\n",
      "[CV 12/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.729, test=0.347) total time=   0.0s\n",
      "[CV 14/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.716, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.001, penalty=l2, solver=newton-cg;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.662, test=0.883) total time=   0.0s\n",
      "[CV 2/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.666, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.692, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.665, test=0.697) total time=   0.0s\n",
      "[CV 5/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.688, test=0.808) total time=   0.0s\n",
      "[CV 6/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.714, test=0.546) total time=   0.0s\n",
      "[CV 7/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.711, test=0.562) total time=   0.0s\n",
      "[CV 8/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.687, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.682, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.332) total time=   0.0s\n",
      "[CV 14/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.686, test=0.678) total time=   0.0s\n",
      "[CV 15/15] END C=0.004641588833612777, penalty=l2, solver=liblinear;, score=(train=0.700, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.693, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.680, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.700, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.682, test=0.742) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.726, test=0.650) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.751, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.712, test=0.492) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.736, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.703, test=0.434) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.704, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.733, test=0.430) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.725, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=saga;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.693, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.680, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.700, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.682, test=0.742) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.726, test=0.650) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.751, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.712, test=0.492) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.736, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.703, test=0.434) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.704, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.733, test=0.430) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.725, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=lbfgs;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.693, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.680, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.700, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.682, test=0.742) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.726, test=0.650) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.751, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.712, test=0.492) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.736, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.703, test=0.434) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.704, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.733, test=0.430) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.725, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=sag;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.693, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.680, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.700, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.682, test=0.742) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.726, test=0.650) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.751, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.712, test=0.492) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.736, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.703, test=0.434) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.704, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.733, test=0.430) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.725, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.693, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.680, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.700, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.682, test=0.742) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.726, test=0.650) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.751, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=0.492) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.736, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.703, test=0.434) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.704, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.733, test=0.430) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.725, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=newton-cholesky;, score=(train=0.745, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.682, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.675, test=0.327) total time=   0.0s\n",
      "[CV 3/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.699, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.677, test=0.712) total time=   0.0s\n",
      "[CV 5/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.713, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.727, test=0.546) total time=   0.0s\n",
      "[CV 7/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.715, test=0.562) total time=   0.0s\n",
      "[CV 8/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.734, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.686, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.693, test=0.391) total time=   0.0s\n",
      "[CV 11/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.698, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.693, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.709, test=0.377) total time=   0.0s\n",
      "[CV 14/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.713, test=0.742) total time=   0.0s\n",
      "[CV 15/15] END C=0.01, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.685, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.684, test=0.352) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.702, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.684, test=0.716) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.728, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.713, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.730, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.680, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.704, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.700, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.730, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.723, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=sag;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.685, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.685, test=0.352) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.702, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.684, test=0.716) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.728, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.713, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.730, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.680, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.704, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.700, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.730, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.724, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=newton-cg;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.685, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.685, test=0.352) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.702, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.684, test=0.716) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.728, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.713, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.730, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.680, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.704, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.700, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.730, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.724, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=saga;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.685, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.685, test=0.352) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.702, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.684, test=0.716) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.728, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.713, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.730, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.680, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.704, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.700, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.730, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.723, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=lbfgs;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.685, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.685, test=0.352) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.702, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.684, test=0.716) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.728, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.713, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.730, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.680, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.704, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.700, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.730, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.724, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=newton-cholesky;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.680, test=0.352) total time=   0.0s\n",
      "[CV 3/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.702, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.679, test=0.742) total time=   0.0s\n",
      "[CV 5/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.733, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.716, test=0.562) total time=   0.0s\n",
      "[CV 8/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.736, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.703, test=0.434) total time=   0.0s\n",
      "[CV 11/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.706, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.699, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.728, test=0.460) total time=   0.0s\n",
      "[CV 14/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.021544346900318832, penalty=l2, solver=liblinear;, score=(train=0.735, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.718, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.732, test=0.424) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.728, test=0.845) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.703, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.731, test=0.825) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.760, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.736, test=0.551) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.771, test=0.367) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.704, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.724, test=0.494) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.729, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.712, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.753, test=0.505) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.732, test=0.761) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.767, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.752, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.765, test=0.468) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.761, test=0.896) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.729, test=0.852) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.760, test=0.888) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.802, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.764, test=0.534) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.792, test=0.315) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.740, test=0.906) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.750, test=0.639) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.755, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.745, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.786, test=0.601) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.770, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.800, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.696, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.706, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.686, test=0.744) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.723, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.716, test=0.454) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.734, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.683, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.707, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.697, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.701, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.728, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.721, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=lbfgs;, score=(train=0.755, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.696, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.701, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.705, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.686, test=0.744) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.723, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.716, test=0.454) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.734, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.684, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.707, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.697, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.701, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.728, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.721, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=sag;, score=(train=0.755, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.696, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.706, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.686, test=0.744) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.723, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.716, test=0.454) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.734, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.683, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.707, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.697, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.701, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.728, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.721, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=newton-cholesky;, score=(train=0.755, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.696, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.701, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.706, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.686, test=0.744) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.723, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.716, test=0.454) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.734, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.683, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.707, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.697, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.701, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.728, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.721, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=saga;, score=(train=0.755, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.696, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.706, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.686, test=0.744) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.723, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.716, test=0.454) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.734, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.683, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.707, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.697, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.701, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.728, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.721, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=newton-cg;, score=(train=0.755, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.685, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.686, test=0.352) total time=   0.0s\n",
      "[CV 3/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.702, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.683, test=0.716) total time=   0.0s\n",
      "[CV 5/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.722, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.736, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.717, test=0.528) total time=   0.0s\n",
      "[CV 8/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.733, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.706, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.709, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.701, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.450) total time=   0.0s\n",
      "[CV 14/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.046415888336127774, penalty=l2, solver=liblinear;, score=(train=0.736, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.704, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.714, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.708, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.685, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.726, test=0.791) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.753, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.720, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.737, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.689, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.712, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.700, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.702, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.737, test=0.487) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.717, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=newton-cholesky;, score=(train=0.761, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.704, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.714, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.708, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.685, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.726, test=0.791) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.754, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.720, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.737, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.689, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.712, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.700, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.702, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.737, test=0.487) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.717, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=sag;, score=(train=0.761, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.704, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.714, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.708, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.685, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.726, test=0.791) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.754, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.720, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.737, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.689, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.712, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.700, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.702, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.737, test=0.487) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.717, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=saga;, score=(train=0.761, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.704, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.714, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.708, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.685, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.726, test=0.791) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.753, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.720, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.737, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.689, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.712, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.700, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.702, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.737, test=0.487) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.717, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=lbfgs;, score=(train=0.761, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.704, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.714, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.708, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.685, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.726, test=0.791) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.753, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.720, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.737, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.689, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.712, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.700, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.702, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.737, test=0.487) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.717, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=newton-cg;, score=(train=0.761, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.714, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.715, test=0.754) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.692, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.727, test=0.808) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.756, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.731, test=0.492) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.748, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.706, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.723, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.707, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.742, test=0.523) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.720, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.703, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.710, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.709, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.690, test=0.785) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.727, test=0.773) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.750, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.723, test=0.492) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.689, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.710, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.705, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.703, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.738, test=0.487) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.719, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.757, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.698, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.701, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.705, test=0.670) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.689, test=0.730) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.723, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.742, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.716, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.736, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.687, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.708, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.703, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.703, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.732, test=0.469) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l2, solver=liblinear;, score=(train=0.746, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.713, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.719, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.717, test=0.754) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.690, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.726, test=0.808) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.759, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.730, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.748, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.699, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.720, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.709, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.707, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.742, test=0.523) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.717, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.713, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.719, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.717, test=0.754) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.690, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.726, test=0.808) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.759, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.730, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.748, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.699, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.720, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.709, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.707, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.742, test=0.523) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.717, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.713, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.719, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.717, test=0.754) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.689, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.726, test=0.808) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.759, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.730, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.748, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.699, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.720, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.709, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.707, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.742, test=0.523) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.717, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.713, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.719, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.717, test=0.754) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.690, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.726, test=0.808) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.759, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.730, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.748, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.699, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.720, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.709, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.707, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.742, test=0.523) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.717, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.713, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.719, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.717, test=0.754) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.690, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.726, test=0.808) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.758, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.730, test=0.474) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.748, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.699, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.720, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.709, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.707, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.742, test=0.523) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.717, test=0.790) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.751, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.762, test=0.446) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.761, test=0.896) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.729, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.756, test=0.888) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.803, test=0.574) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.762, test=0.534) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.794, test=0.315) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.743, test=0.933) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.752, test=0.639) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.757, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.742, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.785, test=0.568) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.762) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.796, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.724, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.729, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.721, test=0.845) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.696, test=0.759) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.730, test=0.841) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.760, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.737, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.764, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.708, test=0.973) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.723, test=0.475) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.722, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.717, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.753, test=0.505) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.723, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.723, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.729, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.721, test=0.845) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.696, test=0.759) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.730, test=0.841) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.760, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.737, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.764, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.708, test=0.973) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.723, test=0.475) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.722, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.717, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.753, test=0.505) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.723, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.724, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.729, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.721, test=0.845) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.696, test=0.759) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.730, test=0.841) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.760, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.737, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.764, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.708, test=0.973) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.723, test=0.475) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.722, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.717, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.753, test=0.505) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.724, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.724, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.729, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.721, test=0.845) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.696, test=0.759) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.730, test=0.841) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.760, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.737, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.764, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.708, test=0.973) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.723, test=0.475) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.722, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.717, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.753, test=0.505) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.723, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.724, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.729, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.721, test=0.845) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.696, test=0.759) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.730, test=0.841) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.760, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.737, test=0.510) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.764, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.708, test=0.973) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.723, test=0.475) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.722, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.717, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.753, test=0.505) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.723, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.766, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.699, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.700, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.716, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.687, test=0.730) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.721, test=0.808) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.731, test=0.546) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.726, test=0.523) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.750, test=0.373) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.706, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.722, test=0.455) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.712, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.712, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.730, test=0.487) total time=   0.0s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.789) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.725, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.729, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.845) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.697, test=0.772) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.825) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.528) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.766, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.714, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.726, test=0.475) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.725, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.717, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.753, test=0.505) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.727, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.767, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.726, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.733, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.735, test=0.820) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.706, test=0.798) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.742, test=0.808) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.763, test=0.546) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.744, test=0.551) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.382) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.713, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.734, test=0.494) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.725, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.723, test=0.921) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.760, test=0.523) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.744, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.762, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.755, test=0.934) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.769, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.767, test=0.882) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.731, test=0.812) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.765, test=0.888) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.801, test=0.673) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.773, test=0.567) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.793, test=0.315) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.750, test=0.866) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.761, test=0.642) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.760, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.748, test=0.921) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.789, test=0.601) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.773, test=0.762) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.796, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.754, test=0.934) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.771, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.765, test=0.882) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.732, test=0.852) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.765, test=0.888) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.801, test=0.626) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.567) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.794, test=0.315) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.750, test=0.893) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.764, test=0.675) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.750, test=0.921) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.790, test=0.601) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.770, test=0.762) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.799, test=0.516) total time=   0.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 20\n",
      "n_resources: 3330\n",
      "Fitting 15 folds for each of 20 candidates, totalling 300 fits\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.877) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.731, test=0.337) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.730, test=0.767) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.715, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.727, test=0.777) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.749, test=0.589) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.744, test=0.502) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.755, test=0.319) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.718, test=0.995) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.744, test=0.450) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.723, test=0.779) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.721, test=0.889) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.744, test=0.602) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.727, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.750, test=0.926) total time=   0.0s\n",
      "[CV 2/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.760, test=0.345) total time=   0.0s\n",
      "[CV 3/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.752, test=0.841) total time=   0.0s\n",
      "[CV 4/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.742, test=0.802) total time=   0.0s\n",
      "[CV 5/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.750, test=0.843) total time=   0.0s\n",
      "[CV 6/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.779, test=0.554) total time=   0.0s\n",
      "[CV 7/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.762, test=0.589) total time=   0.0s\n",
      "[CV 8/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.782, test=0.311) total time=   0.0s\n",
      "[CV 9/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.743, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.534) total time=   0.0s\n",
      "[CV 11/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.757, test=0.788) total time=   0.0s\n",
      "[CV 12/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.736, test=0.912) total time=   0.1s\n",
      "[CV 13/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.619) total time=   0.2s\n",
      "[CV 14/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.756, test=0.778) total time=   0.0s\n",
      "[CV 15/15] END C=0.1, penalty=l1, solver=liblinear;, score=(train=0.783, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.732, test=0.877) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.742, test=0.337) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.735, test=0.820) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.724, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.735, test=0.838) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.758, test=0.656) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.748, test=0.519) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.766, test=0.313) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.726, test=0.995) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.750, test=0.463) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.737, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.728, test=0.889) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.752, test=0.627) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=saga;, score=(train=0.769, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.732, test=0.877) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.742, test=0.337) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.735, test=0.820) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.724, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.735, test=0.838) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.758, test=0.656) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.748, test=0.519) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.766, test=0.313) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.726, test=0.995) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.750, test=0.463) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.737, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.728, test=0.889) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.753, test=0.627) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cg;, score=(train=0.769, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.732, test=0.877) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.742, test=0.337) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.735, test=0.820) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.724, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.735, test=0.838) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.758, test=0.656) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.748, test=0.519) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.765, test=0.313) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.726, test=0.995) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.750, test=0.463) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.737, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.728, test=0.889) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.753, test=0.627) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.739, test=0.755) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=sag;, score=(train=0.769, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.732, test=0.877) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.742, test=0.337) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.735, test=0.820) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.724, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.735, test=0.838) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.758, test=0.656) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.748, test=0.519) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.766, test=0.313) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.726, test=0.995) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.750, test=0.463) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.737, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.728, test=0.889) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.753, test=0.627) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=newton-cholesky;, score=(train=0.769, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.732, test=0.877) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.742, test=0.337) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.735, test=0.820) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.724, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.735, test=0.838) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.758, test=0.656) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.748, test=0.519) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.766, test=0.313) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.726, test=0.995) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.750, test=0.463) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.737, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.728, test=0.889) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.753, test=0.627) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=lbfgs;, score=(train=0.769, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.734, test=0.877) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.743, test=0.328) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.738, test=0.824) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.724, test=0.830) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.735, test=0.838) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.760, test=0.629) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.752, test=0.525) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.766, test=0.322) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.728, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.751, test=0.470) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.737, test=0.779) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.729, test=0.903) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.753, test=0.618) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.739, test=0.750) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l2, solver=liblinear;, score=(train=0.769, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.926) total time=   0.1s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.753, test=0.362) total time=   0.1s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.747, test=0.850) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.739, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.748, test=0.843) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.767, test=0.646) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.758, test=0.559) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.777, test=0.243) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.739, test=0.991) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.755, test=0.528) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.751, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.745, test=0.912) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.762, test=0.653) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.755, test=0.769) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cg;, score=(train=0.774, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.745, test=0.926) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.754, test=0.362) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.748, test=0.850) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.739, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.748, test=0.843) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.767, test=0.646) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.758, test=0.559) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.777, test=0.243) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.739, test=0.991) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.755, test=0.528) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.751, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.744, test=0.912) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.762, test=0.653) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.755, test=0.769) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=sag;, score=(train=0.774, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.745, test=0.926) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.753, test=0.362) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.748, test=0.850) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.739, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.748, test=0.843) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.767, test=0.646) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.758, test=0.559) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.777, test=0.243) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.739, test=0.991) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.755, test=0.528) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.751, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.745, test=0.912) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.762, test=0.653) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.755, test=0.769) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=lbfgs;, score=(train=0.774, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.745, test=0.926) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.753, test=0.362) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.747, test=0.850) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.739, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.748, test=0.843) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.767, test=0.646) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.758, test=0.559) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.777, test=0.243) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.739, test=0.991) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.755, test=0.528) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.751, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.745, test=0.912) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.762, test=0.653) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.755, test=0.769) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=saga;, score=(train=0.774, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.745, test=0.926) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.753, test=0.362) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.747, test=0.850) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.739, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.748, test=0.843) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.767, test=0.646) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.758, test=0.559) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.777, test=0.243) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.739, test=0.991) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.755, test=0.528) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.751, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.745, test=0.912) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.762, test=0.653) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.755, test=0.769) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=newton-cholesky;, score=(train=0.774, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.749, test=0.926) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.753, test=0.362) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.750, test=0.850) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.738, test=0.830) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.748, test=0.843) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.768, test=0.646) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.760, test=0.570) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.780, test=0.279) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.740, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.757, test=0.534) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.755, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.744, test=0.912) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.763, test=0.653) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.756, test=0.764) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.774, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.768, test=0.939) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.772, test=0.411) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.772, test=0.891) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.754, test=0.848) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.769, test=0.884) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.795, test=0.684) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.776, test=0.568) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.797, test=0.243) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.757, test=0.937) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.768, test=0.608) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.774, test=0.788) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.758, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.783, test=0.659) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.773, test=0.792) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.801, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.768, test=0.939) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.773, test=0.387) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.891) total time=   0.0s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.756, test=0.821) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.889) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.797, test=0.668) total time=   0.0s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.584) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.797, test=0.261) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.757, test=0.959) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.608) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.775, test=0.788) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.758, test=0.912) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.784, test=0.659) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.773, test=0.792) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.800, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.766, test=0.939) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.464) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.774, test=0.886) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.759, test=0.816) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.880) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.797, test=0.710) total time=   0.0s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.589) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.793, test=0.281) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.757, test=0.915) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.640) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.774, test=0.788) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.756, test=0.912) total time=   0.1s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.787, test=0.685) total time=   0.1s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.770, test=0.792) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.805, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.766, test=0.943) total time=   0.0s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.774, test=0.485) total time=   0.0s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.774, test=0.886) total time=   0.0s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.757, test=0.821) total time=   0.0s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.768, test=0.880) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.796, test=0.712) total time=   0.1s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.777, test=0.589) total time=   0.0s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.791, test=0.281) total time=   0.0s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.757, test=0.892) total time=   0.0s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.770, test=0.635) total time=   0.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.775, test=0.783) total time=   0.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.755, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.785, test=0.685) total time=   0.0s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.768, test=0.787) total time=   0.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.805, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.762, test=0.935) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.778, test=0.499) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.776, test=0.871) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.758, test=0.816) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.768, test=0.880) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.793, test=0.664) total time=   0.1s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.778, test=0.573) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.790, test=0.296) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.752, test=0.892) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.767, test=0.656) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.773, test=0.778) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.754, test=0.912) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.787, test=0.708) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.768, test=0.792) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.805, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.762, test=0.935) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.499) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.876) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.758, test=0.812) total time=   0.1s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.768, test=0.880) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.793, test=0.664) total time=   0.1s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.573) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.789, test=0.288) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.752, test=0.892) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.766, test=0.651) total time=   0.1s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.773, test=0.778) total time=   0.1s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.754, test=0.912) total time=   0.3s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.786, test=0.708) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.792) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.805, test=0.496) total time=   0.1s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 7\n",
      "n_resources: 9990\n",
      "Fitting 15 folds for each of 7 candidates, totalling 105 fits\n",
      "[CV 1/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.757, test=0.932) total time=   0.0s\n",
      "[CV 2/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.778, test=0.372) total time=   0.0s\n",
      "[CV 3/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.765, test=0.882) total time=   0.0s\n",
      "[CV 4/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.765, test=0.820) total time=   0.0s\n",
      "[CV 5/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.767, test=0.879) total time=   0.0s\n",
      "[CV 6/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.788, test=0.660) total time=   0.0s\n",
      "[CV 7/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.774, test=0.602) total time=   0.0s\n",
      "[CV 8/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.794, test=0.252) total time=   0.0s\n",
      "[CV 9/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.759, test=0.908) total time=   0.0s\n",
      "[CV 10/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.774, test=0.676) total time=   0.0s\n",
      "[CV 11/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.769, test=0.793) total time=   0.0s\n",
      "[CV 12/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.763, test=0.906) total time=   0.0s\n",
      "[CV 13/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.770, test=0.735) total time=   0.0s\n",
      "[CV 14/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.765, test=0.810) total time=   0.0s\n",
      "[CV 15/15] END C=1.0, penalty=l2, solver=liblinear;, score=(train=0.794, test=0.462) total time=   0.0s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.762, test=0.939) total time=   0.1s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.445) total time=   0.2s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.775, test=0.854) total time=   0.2s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.766, test=0.809) total time=   0.2s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.876) total time=   0.2s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.786, test=0.707) total time=   0.2s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.597) total time=   0.1s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.792, test=0.296) total time=   0.1s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.763, test=0.872) total time=   0.2s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.779, test=0.682) total time=   0.1s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.773, test=0.801) total time=   0.2s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.766, test=0.922) total time=   0.1s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.771, test=0.754) total time=   0.2s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.805) total time=   0.2s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=liblinear;, score=(train=0.798, test=0.462) total time=   0.4s\n",
      "[CV 1/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.761, test=0.942) total time=   0.0s\n",
      "[CV 2/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.779, test=0.452) total time=   0.0s\n",
      "[CV 3/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.774, test=0.851) total time=   0.1s\n",
      "[CV 4/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.766, test=0.809) total time=   0.0s\n",
      "[CV 5/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.769, test=0.876) total time=   0.0s\n",
      "[CV 6/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.786, test=0.721) total time=   0.1s\n",
      "[CV 7/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.776, test=0.594) total time=   0.0s\n",
      "[CV 8/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.793, test=0.296) total time=   0.0s\n",
      "[CV 9/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.763, test=0.868) total time=   0.0s\n",
      "[CV 10/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.778, test=0.681) total time=   0.0s\n",
      "[CV 11/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.772, test=0.798) total time=   0.0s\n",
      "[CV 12/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.765, test=0.919) total time=   0.0s\n",
      "[CV 13/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.771, test=0.755) total time=   0.0s\n",
      "[CV 14/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.769, test=0.805) total time=   0.0s\n",
      "[CV 15/15] END C=0.21544346900318823, penalty=l1, solver=saga;, score=(train=0.797, test=0.462) total time=   0.0s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.765, test=0.947) total time=   0.3s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.786, test=0.474) total time=   1.2s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.780, test=0.838) total time=   1.0s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.773, test=0.821) total time=   8.3s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.773, test=0.879) total time=   1.3s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.790, test=0.716) total time=   2.5s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.779, test=0.610) total time=   0.7s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.797, test=0.305) total time=  33.7s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.827) total time=  15.3s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.782, test=0.685) total time=   4.1s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.794) total time=   1.9s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.771, test=0.918) total time=   5.1s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.779, test=0.768) total time=   0.9s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.806) total time=   0.7s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.802, test=0.465) total time=   1.9s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.764, test=0.950) total time=   0.3s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.786, test=0.474) total time=   0.3s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.780, test=0.839) total time=   0.3s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.773, test=0.821) total time=   0.3s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.772, test=0.879) total time=   0.3s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.789, test=0.705) total time=   0.3s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.780, test=0.614) total time=   0.3s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.797, test=0.307) total time=   0.4s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.766, test=0.854) total time=   0.4s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.782, test=0.686) total time=   0.2s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.776, test=0.794) total time=   0.3s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.770, test=0.918) total time=   0.4s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.777, test=0.769) total time=   0.3s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.771, test=0.807) total time=   0.3s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.802, test=0.465) total time=   0.4s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.764, test=0.942) total time=   0.1s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.782, test=0.467) total time=   0.1s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.777, test=0.846) total time=   0.2s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.769, test=0.818) total time=   0.3s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.770, test=0.877) total time=   0.0s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.786, test=0.703) total time=   0.1s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.777, test=0.598) total time=   0.2s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.794, test=0.310) total time=   0.3s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.764, test=0.865) total time=   0.1s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.779, test=0.682) total time=   0.1s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.775, test=0.796) total time=   0.2s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.767, test=0.919) total time=   0.3s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.775, test=0.766) total time=   0.4s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.769, test=0.806) total time=   0.1s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.800, test=0.465) total time=   0.3s\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.764, test=0.940) total time=   0.8s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.782, test=0.467) total time=   2.2s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.846) total time=   0.6s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.769, test=0.814) total time=   2.1s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.770, test=0.877) total time=   0.6s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.786, test=0.699) total time=   0.4s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.600) total time=   1.4s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.792, test=0.310) total time=   1.3s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.764, test=0.865) total time=   0.3s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.778, test=0.682) total time=   0.5s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.775, test=0.798) total time=   1.0s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.767, test=0.919) total time=   1.9s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.775, test=0.765) total time=   1.7s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.770, test=0.802) total time=   1.0s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=liblinear;, score=(train=0.800, test=0.465) total time=   2.1s\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 3\n",
      "n_resources: 29970\n",
      "Fitting 15 folds for each of 3 candidates, totalling 45 fits\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.772, test=0.944) total time= 1.4min\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.791, test=0.505) total time= 1.6min\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.786, test=0.808) total time= 1.2min\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.777, test=0.826) total time= 1.6min\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.776, test=0.897) total time= 1.5min\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.793, test=0.711) total time=  57.4s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.788, test=0.644) total time= 1.2min\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.801, test=0.314) total time= 1.0min\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.778, test=0.806) total time= 1.1min\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.792, test=0.722) total time= 1.9min\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.782, test=0.787) total time=  35.5s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.775, test=0.920) total time= 1.1min\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.779, test=0.775) total time=  51.8s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.779, test=0.806) total time= 1.3min\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=liblinear;, score=(train=0.812, test=0.486) total time= 1.0min\n",
      "[CV 1/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.768, test=0.945) total time=   2.4s\n",
      "[CV 2/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.790, test=0.488) total time=   1.7s\n",
      "[CV 3/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.783, test=0.811) total time=   1.6s\n",
      "[CV 4/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.774, test=0.824) total time=   1.8s\n",
      "[CV 5/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.773, test=0.897) total time=   1.8s\n",
      "[CV 6/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.791, test=0.709) total time=   2.1s\n",
      "[CV 7/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.786, test=0.635) total time=   1.6s\n",
      "[CV 8/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.798, test=0.321) total time=   1.9s\n",
      "[CV 9/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.775, test=0.841) total time=   1.5s\n",
      "[CV 10/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.788, test=0.708) total time=   2.0s\n",
      "[CV 11/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.779, test=0.787) total time=   2.5s\n",
      "[CV 12/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.771, test=0.918) total time=   3.5s\n",
      "[CV 13/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.778, test=0.768) total time=   4.3s\n",
      "[CV 14/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.776, test=0.811) total time=   3.3s\n",
      "[CV 15/15] END C=0.46415888336127775, penalty=l1, solver=saga;, score=(train=0.809, test=0.485) total time=   1.8s\n",
      "[CV 1/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.772, test=0.944) total time=   2.1s\n",
      "[CV 2/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.791, test=0.507) total time=   1.1s\n",
      "[CV 3/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.787, test=0.812) total time=   1.2s\n",
      "[CV 4/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.777, test=0.826) total time=   1.2s\n",
      "[CV 5/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.775, test=0.896) total time=   1.2s\n",
      "[CV 6/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.794, test=0.712) total time=   1.2s\n",
      "[CV 7/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.789, test=0.644) total time=   1.2s\n",
      "[CV 8/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.801, test=0.315) total time=   1.2s\n",
      "[CV 9/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.780, test=0.817) total time=   1.2s\n",
      "[CV 10/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.792, test=0.719) total time=   1.2s\n",
      "[CV 11/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.783, test=0.788) total time=   1.4s\n",
      "[CV 12/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.776, test=0.920) total time=   1.1s\n",
      "[CV 13/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.780, test=0.779) total time=   1.3s\n",
      "[CV 14/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.779, test=0.804) total time=   1.4s\n",
      "[CV 15/15] END C=1.0, penalty=l1, solver=saga;, score=(train=0.813, test=0.486) total time=   1.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                 random_state=46),\n",
       "                    param_grid={&#x27;C&#x27;: array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                &#x27;penalty&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;),\n",
       "                                &#x27;solver&#x27;: (&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                           &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;)},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                 random_state=46),\n",
       "                    param_grid={&#x27;C&#x27;: array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                &#x27;penalty&#x27;: (&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;),\n",
       "                                &#x27;solver&#x27;: (&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                           &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;)},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=46)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, random_state=46)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=LogisticRegression(class_weight='balanced',\n",
       "                                                 random_state=46),\n",
       "                    param_grid={'C': array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ]),\n",
       "                                'penalty': ('l1', 'l2', 'elasticnet'),\n",
       "                                'solver': ('lbfgs', 'liblinear', 'newton-cg',\n",
       "                                           'newton-cholesky', 'sag', 'saga')},\n",
       "                    random_state=46, scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_logreg = {'penalty':('l1', 'l2', 'elasticnet'), \n",
    "                     'solver':('lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'),\n",
    "                     'C': np.logspace(-3, 0, 10)}\n",
    "logreg = LogisticRegression(random_state=46, class_weight = 'balanced')\n",
    "cv = StratifiedGroupKFold(n_splits=15, shuffle=True, random_state=46)\n",
    "logreg_hyperparams = HalvingGridSearchCV(logreg, parameters_logreg, cv = cv, scoring = 'f1_weighted', random_state=46, verbose=3)\n",
    "logreg_hyperparams.fit(X, y, groups = groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f27f1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'penalty': 'l1', 'solver': 'saga'}\n",
      "0.7313092110846856\n"
     ]
    }
   ],
   "source": [
    "print(logreg_hyperparams.best_params_)\n",
    "print(logreg_hyperparams.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37518221",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = logreg_hyperparams.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b08d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=46, class_weight = 'balanced', C = 1.0, penalty = 'l1', solver = 'saga')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1752669",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "438a2b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 4\n",
      "n_required_iterations: 4\n",
      "n_possible_iterations: 4\n",
      "min_resources_: 1111\n",
      "max_resources_: 30000\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 72\n",
      "n_resources: 1111\n",
      "Fitting 15 folds for each of 72 candidates, totalling 1080 fits\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.928, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.907, test=0.446) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.923, test=0.889) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.910, test=0.550) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.921, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.939, test=0.082) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.904, test=0.618) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.915, test=0.713) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.909, test=0.672) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.901, test=0.794) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.923, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.903, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.943, test=0.634) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.909, test=0.721) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=5;, score=(train=0.934, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.943, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.906, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.949, test=0.889) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.919, test=0.321) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.934, test=0.712) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.937, test=0.106) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.924, test=0.645) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.916, test=0.726) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.931, test=0.663) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.926, test=0.865) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.931, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.916, test=0.935) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.950, test=0.649) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.926, test=0.748) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=10;, score=(train=0.942, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.938, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.917, test=0.510) total time=   0.1s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.944, test=0.903) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.927, test=0.321) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.936, test=0.763) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.944, test=0.074) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.926, test=0.689) total time=   0.1s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.926, test=0.713) total time=   0.1s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.929, test=0.743) total time=   0.1s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.929, test=0.795) total time=   0.1s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.933, test=0.819) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.924, test=0.961) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.945, test=0.662) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.939, test=0.776) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=20;, score=(train=0.943, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.939, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.928, test=0.510) total time=   0.1s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.946, test=0.903) total time=   0.1s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.931, test=0.391) total time=   0.1s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.939, test=0.763) total time=   0.1s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.944, test=0.106) total time=   0.1s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.921, test=0.717) total time=   0.1s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.933, test=0.713) total time=   0.1s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.936, test=0.745) total time=   0.1s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.927, test=0.782) total time=   0.1s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.933, test=0.849) total time=   0.1s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.927, test=0.974) total time=   0.1s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.949, test=0.688) total time=   0.1s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.941, test=0.776) total time=   0.1s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=30;, score=(train=0.946, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.940, test=0.922) total time=   0.2s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.926, test=0.530) total time=   0.2s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.937, test=0.918) total time=   0.2s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.940, test=0.413) total time=   0.2s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.946, test=0.763) total time=   0.2s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.942, test=0.067) total time=   0.2s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.921, test=0.703) total time=   0.2s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.936, test=0.713) total time=   0.2s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.938, test=0.771) total time=   0.2s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.929, test=0.766) total time=   0.2s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.933, test=0.819) total time=   0.2s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.927, test=0.974) total time=   0.2s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.948, test=0.661) total time=   0.2s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.941, test=0.789) total time=   0.2s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=50;, score=(train=0.938, test=0.516) total time=   0.2s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.945, test=0.922) total time=   0.5s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.922, test=0.530) total time=   0.5s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.944, test=0.889) total time=   0.5s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.941, test=0.391) total time=   0.5s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.948, test=0.763) total time=   0.5s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.940, test=0.162) total time=   0.5s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.924, test=0.717) total time=   0.5s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.934, test=0.713) total time=   0.5s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.934, test=0.691) total time=   0.5s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.929, test=0.766) total time=   0.5s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.936, test=0.819) total time=   0.5s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.923, test=0.961) total time=   0.5s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.943, test=0.662) total time=   0.5s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.940, test=0.789) total time=   0.5s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=2, n_estimators=100;, score=(train=0.941, test=0.516) total time=   0.5s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.930, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.907, test=0.424) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.917, test=0.903) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.911, test=0.568) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.929, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.949, test=0.082) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.904, test=0.618) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.919, test=0.713) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.905, test=0.623) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.896, test=0.766) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.934, test=0.849) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.897, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.943, test=0.634) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.911, test=0.721) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=5;, score=(train=0.933, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.939, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.914, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.954, test=0.903) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.923, test=0.368) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.938, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.948, test=0.106) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.924, test=0.645) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.918, test=0.726) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.936, test=0.635) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.928, test=0.852) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.931, test=0.803) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.921, test=0.961) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.952, test=0.649) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.923, test=0.762) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=10;, score=(train=0.942, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.936, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.917, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.944, test=0.903) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.932, test=0.216) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.942, test=0.731) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.946, test=0.074) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.924, test=0.689) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.925, test=0.713) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.938, test=0.782) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.926, test=0.795) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.933, test=0.849) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.930, test=0.974) total time=   0.1s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.946, test=0.662) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.933, test=0.762) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=20;, score=(train=0.943, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.940, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.923, test=0.510) total time=   0.1s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.941, test=0.918) total time=   0.1s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.930, test=0.345) total time=   0.1s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.941, test=0.731) total time=   0.1s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.947, test=0.125) total time=   0.1s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.923, test=0.717) total time=   0.1s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.932, test=0.713) total time=   0.1s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.938, test=0.745) total time=   0.1s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.923, test=0.811) total time=   0.1s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.933, test=0.849) total time=   0.1s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.930, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.949, test=0.675) total time=   0.1s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.936, test=0.762) total time=   0.1s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=30;, score=(train=0.947, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.938, test=0.922) total time=   0.2s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.926, test=0.510) total time=   0.2s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.944, test=0.932) total time=   0.2s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.943, test=0.391) total time=   0.2s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.945, test=0.763) total time=   0.2s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.941, test=0.162) total time=   0.2s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.923, test=0.716) total time=   0.2s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.937, test=0.713) total time=   0.2s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.938, test=0.732) total time=   0.2s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.931, test=0.766) total time=   0.2s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.932, test=0.849) total time=   0.2s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.932, test=0.974) total time=   0.2s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.947, test=0.688) total time=   0.2s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.936, test=0.789) total time=   0.2s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.939, test=0.516) total time=   0.2s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.944, test=0.922) total time=   0.5s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.920, test=0.530) total time=   0.5s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.945, test=0.903) total time=   0.5s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.941, test=0.391) total time=   0.6s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.943, test=0.763) total time=   0.5s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.938, test=0.162) total time=   0.5s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.922, test=0.717) total time=   0.6s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.933, test=0.713) total time=   0.5s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.937, test=0.635) total time=   0.5s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.928, test=0.766) total time=   0.5s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.936, test=0.834) total time=   0.5s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.924, test=0.974) total time=   0.5s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.944, test=0.675) total time=   0.5s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.937, test=0.789) total time=   0.5s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=100;, score=(train=0.939, test=0.516) total time=   0.5s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.924, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.897, test=0.587) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.911, test=0.903) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.909, test=0.568) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.929, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.932, test=0.106) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.899, test=0.658) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.916, test=0.713) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.904, test=0.682) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.902, test=0.723) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.933, test=0.849) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.903, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.938, test=0.636) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.908, test=0.761) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=5;, score=(train=0.934, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.941, test=0.934) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.917, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.946, test=0.917) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.919, test=0.345) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.941, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.934, test=0.106) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.920, test=0.658) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.930, test=0.726) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.925, test=0.645) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.930, test=0.866) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.937, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.923, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.942, test=0.596) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.919, test=0.762) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=10;, score=(train=0.932, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.934, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.920, test=0.510) total time=   0.1s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.936, test=0.932) total time=   0.0s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.930, test=0.270) total time=   0.0s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.941, test=0.731) total time=   0.0s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.939, test=0.106) total time=   0.0s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.918, test=0.672) total time=   0.0s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.926, test=0.713) total time=   0.0s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.928, test=0.692) total time=   0.0s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.927, test=0.811) total time=   0.0s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.937, test=0.864) total time=   0.0s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.931, test=0.961) total time=   0.0s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.942, test=0.661) total time=   0.0s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.932, test=0.776) total time=   0.0s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=20;, score=(train=0.937, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.935, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.925, test=0.510) total time=   0.1s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.933, test=0.918) total time=   0.1s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.929, test=0.345) total time=   0.1s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.941, test=0.731) total time=   0.1s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.943, test=0.162) total time=   0.1s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.920, test=0.730) total time=   0.1s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.932, test=0.713) total time=   0.1s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.927, test=0.745) total time=   0.1s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.921, test=0.839) total time=   0.1s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.936, test=0.864) total time=   0.1s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.932, test=0.974) total time=   0.1s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.947, test=0.661) total time=   0.1s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.936, test=0.789) total time=   0.1s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.941, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.934, test=0.922) total time=   0.2s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.925, test=0.530) total time=   0.2s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.938, test=0.932) total time=   0.2s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.942, test=0.434) total time=   0.2s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.945, test=0.763) total time=   0.2s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.941, test=0.106) total time=   0.2s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.921, test=0.716) total time=   0.2s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.936, test=0.713) total time=   0.2s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.933, test=0.745) total time=   0.2s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.925, test=0.768) total time=   0.2s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.933, test=0.864) total time=   0.2s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.927, test=0.974) total time=   0.2s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.947, test=0.661) total time=   0.2s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.940, test=0.789) total time=   0.2s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.937, test=0.516) total time=   0.2s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.941, test=0.922) total time=   0.5s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.921, test=0.530) total time=   0.5s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.942, test=0.932) total time=   0.5s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.939, test=0.434) total time=   0.5s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.941, test=0.763) total time=   0.5s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.943, test=0.144) total time=   0.5s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.920, test=0.730) total time=   0.5s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.935, test=0.713) total time=   0.5s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.929, test=0.606) total time=   0.5s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.922, test=0.824) total time=   0.5s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.936, test=0.849) total time=   0.5s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.919, test=0.961) total time=   0.5s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.942, test=0.661) total time=   0.5s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.938, test=0.789) total time=   0.5s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.940, test=0.516) total time=   0.5s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.988, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.988, test=0.537) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.988, test=0.887) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.984, test=0.434) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.991, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.988, test=0.067) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.988, test=0.732) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.986, test=0.697) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.981, test=0.689) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.985, test=0.688) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.984, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.983, test=0.935) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.988, test=0.700) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.986, test=0.692) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=5;, score=(train=0.992, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.996, test=0.934) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.991, test=0.549) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.996, test=0.887) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.994, test=0.434) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.087) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.989, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.713) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.584) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.811) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.819) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.994, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.992, test=0.618) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.996, test=0.746) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=10;, score=(train=0.994, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=0.934) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=0.587) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.889) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.345) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.995, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.106) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.992, test=0.772) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.996, test=0.713) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.995, test=0.638) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.905) total time=   0.1s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.994, test=0.819) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.935) total time=   0.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.993, test=0.672) total time=   0.1s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.761) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.568) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.887) total time=   0.2s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.455) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.996, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.144) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.994, test=0.745) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.759) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.691) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.892) total time=   0.2s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.997, test=0.803) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.997, test=0.674) total time=   0.2s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.761) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.997, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.999, test=0.549) total time=   0.3s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.889) total time=   0.3s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.998, test=0.434) total time=   0.3s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.999, test=0.690) total time=   0.3s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.999, test=0.162) total time=   0.3s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.995, test=0.772) total time=   0.3s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.999, test=0.759) total time=   0.3s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.998, test=0.584) total time=   0.3s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.997, test=0.892) total time=   0.3s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.999, test=0.819) total time=   0.3s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.935) total time=   0.3s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.999, test=0.660) total time=   0.3s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.776) total time=   0.3s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=50;, score=(train=0.999, test=0.516) total time=   0.3s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.922) total time=   0.7s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.549) total time=   0.7s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.999, test=0.902) total time=   0.6s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.999, test=0.455) total time=   0.6s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.690) total time=   0.6s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.189) total time=   0.6s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.995, test=0.745) total time=   0.6s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.759) total time=   0.7s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.999, test=0.637) total time=   0.6s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.998, test=0.864) total time=   0.6s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.834) total time=   0.7s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.961) total time=   0.6s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.648) total time=   0.6s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.776) total time=   0.6s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.516) total time=   0.6s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.989, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.987, test=0.446) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.978, test=0.903) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.975, test=0.391) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.984, test=0.783) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.988, test=0.089) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.984, test=0.759) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.977, test=0.742) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.978, test=0.731) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.985, test=0.768) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.980, test=0.787) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.983, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.726) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.980, test=0.802) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=5;, score=(train=0.984, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.990, test=0.934) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.549) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.990, test=0.931) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.413) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.990, test=0.761) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.197) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.759) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.742) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.992, test=0.611) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.989, test=0.839) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.988, test=0.819) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.992, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.709) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.761) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.990, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.993, test=0.934) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.994, test=0.549) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.889) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.993, test=0.368) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.992, test=0.690) total time=   0.1s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.995, test=0.087) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.990, test=0.758) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.994, test=0.713) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.995, test=0.597) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.993, test=0.865) total time=   0.1s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.994, test=0.849) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.987) total time=   0.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.994, test=0.687) total time=   0.1s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.994, test=0.761) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=20;, score=(train=0.994, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.510) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.887) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.475) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.994, test=0.679) total time=   0.2s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.144) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.992, test=0.745) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.744) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.992, test=0.611) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.994, test=0.865) total time=   0.1s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.864) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.974) total time=   0.2s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.997, test=0.686) total time=   0.1s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.776) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.997, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.510) total time=   0.3s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.903) total time=   0.3s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.475) total time=   0.3s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.992, test=0.679) total time=   0.3s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.995, test=0.144) total time=   0.3s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.991, test=0.785) total time=   0.3s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.729) total time=   0.3s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.996, test=0.597) total time=   0.3s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.995, test=0.865) total time=   0.3s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.996, test=0.849) total time=   0.3s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.974) total time=   0.3s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.660) total time=   0.3s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.789) total time=   0.3s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.516) total time=   0.3s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.999, test=0.922) total time=   0.7s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.999, test=0.530) total time=   0.6s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.999, test=0.889) total time=   0.6s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.475) total time=   0.6s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.679) total time=   0.6s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.995, test=0.162) total time=   0.6s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.991, test=0.758) total time=   0.6s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.998, test=0.759) total time=   0.7s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.994, test=0.556) total time=   0.7s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.995, test=0.837) total time=   0.6s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.998, test=0.864) total time=   0.6s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.948) total time=   0.6s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.997, test=0.648) total time=   0.7s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.776) total time=   0.6s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=100;, score=(train=0.998, test=0.516) total time=   0.6s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.978, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.969, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.974, test=0.804) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.971, test=0.368) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.975, test=0.773) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.982, test=0.074) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.979, test=0.799) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.964, test=0.681) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.964, test=0.603) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.970, test=0.720) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.967, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.969, test=0.909) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.981, test=0.622) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.976, test=0.803) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=5;, score=(train=0.972, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.908) total time=   0.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.986, test=0.902) total time=   0.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.984, test=0.345) total time=   0.0s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.230) total time=   0.0s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.812) total time=   0.0s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.729) total time=   0.0s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.984, test=0.575) total time=   0.0s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.979, test=0.782) total time=   0.0s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.980, test=0.819) total time=   0.0s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.976, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.674) total time=   0.0s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.984, test=0.762) total time=   0.0s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=10;, score=(train=0.980, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.989, test=0.934) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.988, test=0.510) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.991, test=0.902) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.988, test=0.321) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.984, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.990, test=0.125) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.983, test=0.758) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.986, test=0.713) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.988, test=0.554) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.987, test=0.810) total time=   0.1s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.985, test=0.834) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.991, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.989, test=0.636) total time=   0.1s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.986, test=0.762) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=20;, score=(train=0.984, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.989, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.991, test=0.489) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.887) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.989, test=0.413) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.988, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.991, test=0.162) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.986, test=0.744) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.989, test=0.744) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.987, test=0.717) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.989, test=0.766) total time=   0.1s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.990, test=0.864) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.994, test=0.948) total time=   0.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.990, test=0.688) total time=   0.1s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.987, test=0.776) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=30;, score=(train=0.989, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.989, test=0.922) total time=   0.3s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.510) total time=   0.3s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.874) total time=   0.3s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.990, test=0.413) total time=   0.3s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.679) total time=   0.3s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.990, test=0.144) total time=   0.3s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.986, test=0.730) total time=   0.3s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.989, test=0.744) total time=   0.3s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.989, test=0.514) total time=   0.3s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.824) total time=   0.3s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.864) total time=   0.3s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.995, test=0.948) total time=   0.3s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.986, test=0.660) total time=   0.3s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.990, test=0.776) total time=   0.3s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=50;, score=(train=0.986, test=0.516) total time=   0.3s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.993, test=0.922) total time=   0.6s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.993, test=0.530) total time=   0.6s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.993, test=0.889) total time=   0.6s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.992, test=0.455) total time=   0.6s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.987, test=0.679) total time=   0.6s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.988, test=0.144) total time=   0.6s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.985, test=0.730) total time=   0.6s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.989, test=0.744) total time=   0.6s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.990, test=0.593) total time=   0.7s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.990, test=0.852) total time=   0.6s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.992, test=0.864) total time=   0.6s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.948) total time=   0.6s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.990, test=0.660) total time=   0.7s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.992, test=0.776) total time=   0.6s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=10, n_estimators=100;, score=(train=0.990, test=0.516) total time=   0.6s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.989, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.991, test=0.518) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.993, test=0.917) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.990, test=0.513) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.993, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.067) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.745) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.989, test=0.697) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.989, test=0.678) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.990, test=0.810) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.992, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.909) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.776) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.991, test=0.746) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.993, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.996, test=0.934) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.549) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.887) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.991, test=0.494) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.067) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.772) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.744) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.611) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.801) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.689) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.745) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=10;, score=(train=0.994, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.530) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.902) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.391) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=0.714) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=0.106) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.798) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.759) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.597) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.791) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.864) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.685) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.746) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.549) total time=   0.2s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.887) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.475) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.144) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.812) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.759) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.650) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.789) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.849) total time=   0.2s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.672) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.746) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.530) total time=   0.3s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.902) total time=   0.3s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.434) total time=   0.3s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.690) total time=   0.3s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.162) total time=   0.3s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.785) total time=   0.3s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.759) total time=   0.3s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.688) total time=   0.3s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.776) total time=   0.3s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.849) total time=   0.3s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.948) total time=   0.3s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.660) total time=   0.3s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.761) total time=   0.3s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.516) total time=   0.3s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.922) total time=   0.7s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.530) total time=   0.7s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.902) total time=   0.6s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.455) total time=   0.7s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.690) total time=   0.6s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.179) total time=   0.6s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.785) total time=   0.6s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.744) total time=   0.7s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.584) total time=   0.7s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.764) total time=   0.7s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.864) total time=   0.6s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.961) total time=   0.7s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.660) total time=   0.7s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.761) total time=   0.6s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.516) total time=   0.6s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.883) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.986, test=0.673) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.987, test=0.842) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.984, test=0.550) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.987, test=0.754) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.992, test=0.089) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.983, test=0.799) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.984, test=0.697) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.981, test=0.692) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.983, test=0.768) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.986, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.989, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.991, test=0.738) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.987, test=0.830) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.510) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.605) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.887) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.494) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.987, test=0.754) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.106) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.799) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.744) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.638) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.785) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.992, test=0.849) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.709) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.530) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.874) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.995, test=0.391) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.993, test=0.690) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.087) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.785) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.729) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.665) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.810) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.849) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.974) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.723) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.760) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.549) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.889) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.494) total time=   0.2s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.125) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.772) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.744) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.678) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.751) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.849) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.974) total time=   0.2s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.661) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.760) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.530) total time=   0.3s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.889) total time=   0.3s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.475) total time=   0.3s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.679) total time=   0.3s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.162) total time=   0.3s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.758) total time=   0.3s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.744) total time=   0.3s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.664) total time=   0.3s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.776) total time=   0.3s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.849) total time=   0.3s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.961) total time=   0.3s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.660) total time=   0.3s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.746) total time=   0.3s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.516) total time=   0.3s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.922) total time=   0.7s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.568) total time=   0.7s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.889) total time=   0.6s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=0.999, test=0.455) total time=   0.7s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.679) total time=   0.7s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.162) total time=   0.7s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=0.999, test=0.772) total time=   0.6s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.759) total time=   0.7s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.584) total time=   0.6s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.764) total time=   0.6s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.864) total time=   0.6s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.961) total time=   0.7s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.660) total time=   0.7s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.761) total time=   0.7s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.516) total time=   0.6s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.975, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.973, test=0.530) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.982, test=0.931) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.974, test=0.434) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.978, test=0.773) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.984, test=0.115) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.984, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.973, test=0.729) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.968, test=0.745) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.971, test=0.748) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.977, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.975, test=0.961) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.983, test=0.662) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.980, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.980, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.981, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.468) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.992, test=0.902) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.434) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.230) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.799) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.986, test=0.757) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.678) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.892) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.819) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.661) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.990, test=0.934) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.995, test=0.468) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.902) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.993, test=0.345) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.990, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.993, test=0.125) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.992, test=0.772) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.989, test=0.729) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.991, test=0.663) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.991, test=0.791) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.990, test=0.849) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.988, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.989, test=0.648) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.989, test=0.776) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=20;, score=(train=0.987, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.489) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.994, test=0.887) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.321) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.995, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.144) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.989, test=0.758) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.990, test=0.759) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.990, test=0.591) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.990, test=0.781) total time=   0.2s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.864) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.935) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.991, test=0.687) total time=   0.2s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.989, test=0.776) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=30;, score=(train=0.991, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.934) total time=   0.3s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.530) total time=   0.3s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.887) total time=   0.3s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.321) total time=   0.3s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.679) total time=   0.3s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.144) total time=   0.3s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.772) total time=   0.3s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.759) total time=   0.3s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.524) total time=   0.3s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.852) total time=   0.3s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.849) total time=   0.3s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.996, test=0.948) total time=   0.3s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.674) total time=   0.3s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.761) total time=   0.3s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.516) total time=   0.3s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.922) total time=   0.7s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.530) total time=   0.6s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.903) total time=   0.6s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.475) total time=   0.6s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.991, test=0.679) total time=   0.6s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.144) total time=   0.6s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.990, test=0.758) total time=   0.6s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.744) total time=   0.7s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.991, test=0.557) total time=   0.6s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.865) total time=   0.6s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.995, test=0.849) total time=   0.6s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.948) total time=   0.7s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.993, test=0.660) total time=   0.6s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.776) total time=   0.6s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.516) total time=   0.6s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.989, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.991, test=0.518) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.993, test=0.917) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.990, test=0.513) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.993, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.067) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.745) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.989, test=0.697) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.989, test=0.678) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.990, test=0.810) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.992, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.909) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.776) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.991, test=0.746) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.993, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.996, test=0.934) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.999, test=0.549) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.887) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.991, test=0.494) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.067) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.772) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.998, test=0.744) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.611) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.801) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.993, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.995, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.689) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.997, test=0.745) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=10;, score=(train=0.994, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.530) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.902) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.391) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=0.714) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.997, test=0.106) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.798) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.759) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.597) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.791) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.864) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=1.000, test=0.685) total time=   0.1s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.999, test=0.746) total time=   0.1s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=20;, score=(train=0.998, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.549) total time=   0.2s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.887) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.475) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.144) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.812) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.759) total time=   0.2s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.650) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.789) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.849) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.672) total time=   0.1s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.746) total time=   0.1s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.530) total time=   0.3s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.902) total time=   0.3s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.413) total time=   0.3s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.690) total time=   0.3s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.162) total time=   0.3s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.785) total time=   0.3s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.759) total time=   0.3s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.688) total time=   0.3s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.776) total time=   0.3s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.849) total time=   0.3s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.948) total time=   0.3s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.660) total time=   0.3s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.761) total time=   0.3s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.516) total time=   0.3s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.922) total time=   0.7s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.530) total time=   0.7s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.902) total time=   0.6s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.413) total time=   0.6s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.690) total time=   0.6s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.179) total time=   0.7s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.785) total time=   0.7s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.744) total time=   0.7s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.584) total time=   0.7s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.764) total time=   0.6s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.864) total time=   0.7s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.961) total time=   0.9s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.660) total time=   1.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.761) total time=   0.9s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=100;, score=(train=1.000, test=0.516) total time=   0.9s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.883) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.986, test=0.673) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.987, test=0.842) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.984, test=0.550) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.987, test=0.754) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.992, test=0.089) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.983, test=0.799) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.984, test=0.697) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.981, test=0.692) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.983, test=0.768) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.986, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.989, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.991, test=0.738) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.987, test=0.830) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.510) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.605) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.887) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.494) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.987, test=0.754) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.106) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.799) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.744) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.638) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.785) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.992, test=0.849) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.709) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=1.000, test=0.530) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.874) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.995, test=0.391) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.993, test=0.690) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.087) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.785) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.729) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.665) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.998, test=0.810) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.849) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.999, test=0.974) total time=   0.1s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.723) total time=   0.1s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.997, test=0.760) total time=   0.1s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=20;, score=(train=0.996, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.549) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.889) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.494) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.125) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.772) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.744) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.678) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.751) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.849) total time=   0.2s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.974) total time=   0.2s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.661) total time=   0.2s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.760) total time=   0.2s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.530) total time=   0.3s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.889) total time=   0.3s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.475) total time=   0.3s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.679) total time=   0.3s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.162) total time=   0.3s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.758) total time=   0.3s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.744) total time=   0.3s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.664) total time=   0.3s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.776) total time=   0.3s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.849) total time=   0.3s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.961) total time=   0.3s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.660) total time=   0.3s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.746) total time=   0.3s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=50;, score=(train=1.000, test=0.516) total time=   0.3s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.922) total time=   0.7s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.568) total time=   0.7s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.889) total time=   0.7s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=0.999, test=0.455) total time=   0.7s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.679) total time=   0.7s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.162) total time=   0.7s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=0.999, test=0.772) total time=   0.6s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.759) total time=   0.7s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.584) total time=   0.7s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.764) total time=   0.7s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.864) total time=   0.6s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.961) total time=   0.7s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.660) total time=   0.7s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.761) total time=   0.7s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=100;, score=(train=1.000, test=0.516) total time=   0.7s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.975, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.973, test=0.530) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.982, test=0.931) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.974, test=0.434) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.978, test=0.773) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.984, test=0.115) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.984, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.973, test=0.729) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.968, test=0.745) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.971, test=0.748) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.977, test=0.834) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.975, test=0.961) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.983, test=0.662) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.980, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.980, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.981, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.468) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.992, test=0.902) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.990, test=0.434) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.988, test=0.230) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.799) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.986, test=0.757) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.989, test=0.678) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.892) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.819) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.661) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.987, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.985, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.990, test=0.934) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.995, test=0.468) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.996, test=0.902) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.993, test=0.345) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.990, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.993, test=0.125) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.992, test=0.772) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.989, test=0.729) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.991, test=0.663) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.991, test=0.791) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.990, test=0.849) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.988, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.989, test=0.648) total time=   0.1s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.989, test=0.776) total time=   0.1s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=20;, score=(train=0.987, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.922) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.998, test=0.489) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.994, test=0.887) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.321) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.995, test=0.679) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.144) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.989, test=0.758) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.990, test=0.759) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.990, test=0.591) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.990, test=0.781) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.864) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.993, test=0.935) total time=   0.2s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.991, test=0.687) total time=   0.1s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.989, test=0.776) total time=   0.1s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=30;, score=(train=0.991, test=0.516) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.934) total time=   0.3s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.530) total time=   0.3s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.997, test=0.887) total time=   0.3s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.321) total time=   0.3s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.679) total time=   0.3s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.144) total time=   0.3s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.772) total time=   0.3s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.759) total time=   0.3s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.524) total time=   0.3s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.991, test=0.852) total time=   0.3s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.849) total time=   0.3s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.996, test=0.948) total time=   0.3s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.988, test=0.674) total time=   0.3s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.994, test=0.761) total time=   0.3s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=50;, score=(train=0.992, test=0.516) total time=   0.3s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.922) total time=   0.6s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.530) total time=   0.8s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.903) total time=   0.7s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.475) total time=   0.8s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.991, test=0.679) total time=   0.7s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.144) total time=   0.7s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.990, test=0.758) total time=   0.6s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.744) total time=   0.7s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.991, test=0.557) total time=   0.6s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.865) total time=   0.6s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.995, test=0.849) total time=   0.7s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.997, test=0.948) total time=   0.7s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.993, test=0.660) total time=   0.6s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.776) total time=   0.6s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=100;, score=(train=0.994, test=0.516) total time=   0.6s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 24\n",
      "n_resources: 3333\n",
      "Fitting 15 folds for each of 24 candidates, totalling 360 fits\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.948) total time=   0.5s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.471) total time=   0.6s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.884) total time=   0.5s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.369) total time=   0.5s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.728) total time=   0.5s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.323) total time=   0.5s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.838) total time=   0.5s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.701) total time=   0.5s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.557) total time=   0.5s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.712) total time=   0.5s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.864) total time=   0.5s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.970) total time=   0.5s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.659) total time=   0.5s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.794) total time=   0.5s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.496) total time=   0.5s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.948) total time=   0.5s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.471) total time=   0.6s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.884) total time=   0.5s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.369) total time=   0.5s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.728) total time=   0.5s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.323) total time=   0.5s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.838) total time=   0.5s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.701) total time=   0.5s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.557) total time=   0.5s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.712) total time=   0.6s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.864) total time=   0.5s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.970) total time=   0.5s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.659) total time=   0.5s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=1.000, test=0.794) total time=   0.5s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.496) total time=   0.5s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.913, test=0.935) total time=   1.3s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.918, test=0.449) total time=   1.3s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.924, test=0.918) total time=   1.3s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.916, test=0.346) total time=   1.3s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.925, test=0.741) total time=   1.4s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.918, test=0.353) total time=   1.3s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.911, test=0.762) total time=   1.4s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.920, test=0.757) total time=   1.3s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.924, test=0.659) total time=   1.3s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.913, test=0.787) total time=   1.4s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.917, test=0.834) total time=   1.3s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.911, test=0.961) total time=   1.3s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.929, test=0.661) total time=   1.4s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.927, test=0.784) total time=   1.3s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=100;, score=(train=0.919, test=0.496) total time=   1.3s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.948) total time=   1.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.434) total time=   1.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.883) total time=   1.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.516) total time=   1.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.734) total time=   1.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.287) total time=   1.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.829) total time=   1.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.752) total time=   1.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.571) total time=   1.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.805) total time=   1.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.862) total time=   1.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.957) total time=   1.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.697) total time=   1.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.768) total time=   1.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.496) total time=   0.9s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.995, test=0.939) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.540) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.910) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.414) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.423) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.780) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.631) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.463) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.818) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.825) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.935) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.681) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=0.752) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.995, test=0.939) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.540) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.910) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.999, test=0.414) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.423) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.780) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.631) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.463) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.818) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.996, test=0.825) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.935) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.997, test=0.681) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.998, test=0.752) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=5;, score=(train=0.994, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.939) total time=   0.5s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.992, test=0.464) total time=   0.5s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.864) total time=   0.5s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.588) total time=   0.5s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.728) total time=   0.5s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.997, test=0.353) total time=   0.5s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.993, test=0.816) total time=   0.5s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.993, test=0.676) total time=   0.5s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.994, test=0.586) total time=   0.5s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.997, test=0.764) total time=   0.5s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.999, test=0.864) total time=   0.5s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.974) total time=   0.5s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.997, test=0.659) total time=   0.5s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.997, test=0.759) total time=   0.5s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.496) total time=   0.5s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.939) total time=   0.9s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.993, test=0.457) total time=   0.9s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.999, test=0.879) total time=   1.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.547) total time=   0.9s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.734) total time=   0.9s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.278) total time=   0.9s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.996, test=0.821) total time=   0.9s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.994, test=0.691) total time=   0.9s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.995, test=0.581) total time=   0.9s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.764) total time=   0.9s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.859) total time=   0.9s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.965) total time=   0.9s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.676) total time=   0.9s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.998, test=0.761) total time=   0.9s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=50;, score=(train=0.997, test=0.496) total time=   0.9s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.943) total time=   0.5s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.426) total time=   0.6s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.882) total time=   0.5s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.576) total time=   0.5s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.728) total time=   0.5s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.296) total time=   0.5s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.821) total time=   0.5s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.758) total time=   0.5s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.576) total time=   0.5s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.814) total time=   0.5s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.845) total time=   0.5s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.961) total time=   0.5s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.700) total time=   0.5s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.773) total time=   0.5s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.496) total time=   0.5s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.943) total time=   0.5s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.449) total time=   0.6s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.882) total time=   0.5s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.576) total time=   0.5s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.728) total time=   0.5s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.296) total time=   0.5s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.821) total time=   0.5s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.758) total time=   0.5s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.576) total time=   0.6s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.814) total time=   0.5s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.845) total time=   0.5s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.961) total time=   0.5s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.700) total time=   0.5s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.773) total time=   0.5s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.496) total time=   0.5s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.908, test=0.943) total time=   0.3s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.919, test=0.457) total time=   0.3s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.920, test=0.904) total time=   0.3s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.911, test=0.313) total time=   0.3s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.921, test=0.741) total time=   0.3s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.919, test=0.332) total time=   0.3s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.901, test=0.753) total time=   0.3s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.922, test=0.762) total time=   0.3s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.923, test=0.650) total time=   0.3s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.905, test=0.782) total time=   0.3s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.912, test=0.829) total time=   0.3s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.908, test=0.974) total time=   0.3s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.931, test=0.639) total time=   0.3s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.922, test=0.780) total time=   0.3s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=30;, score=(train=0.918, test=0.496) total time=   0.3s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.917, test=0.935) total time=   0.6s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.926, test=0.457) total time=   0.6s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.923, test=0.932) total time=   0.6s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.920, test=0.338) total time=   0.6s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.926, test=0.741) total time=   0.6s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.919, test=0.336) total time=   0.6s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.910, test=0.776) total time=   0.6s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.923, test=0.757) total time=   0.6s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.927, test=0.646) total time=   0.6s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.910, test=0.792) total time=   0.6s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.918, test=0.839) total time=   0.6s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.910, test=0.965) total time=   0.6s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.934, test=0.635) total time=   0.6s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.925, test=0.784) total time=   0.6s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=5, n_estimators=50;, score=(train=0.918, test=0.496) total time=   0.6s\n",
      "[CV 1/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.917, test=0.935) total time=   0.6s\n",
      "[CV 2/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.927, test=0.464) total time=   0.6s\n",
      "[CV 3/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.925, test=0.942) total time=   0.6s\n",
      "[CV 4/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.915, test=0.361) total time=   0.6s\n",
      "[CV 5/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.922, test=0.741) total time=   0.6s\n",
      "[CV 6/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.921, test=0.327) total time=   0.6s\n",
      "[CV 7/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.911, test=0.767) total time=   0.6s\n",
      "[CV 8/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.920, test=0.757) total time=   0.6s\n",
      "[CV 9/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.926, test=0.641) total time=   0.6s\n",
      "[CV 10/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.906, test=0.787) total time=   0.6s\n",
      "[CV 11/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.915, test=0.839) total time=   0.6s\n",
      "[CV 12/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.909, test=0.965) total time=   0.6s\n",
      "[CV 13/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.931, test=0.626) total time=   0.6s\n",
      "[CV 14/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.924, test=0.784) total time=   0.6s\n",
      "[CV 15/15] END max_depth=5, min_samples_split=10, n_estimators=50;, score=(train=0.917, test=0.496) total time=   0.6s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.989, test=0.935) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.597) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.989, test=0.918) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.995, test=0.616) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=0.713) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.411) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=0.793) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.989, test=0.663) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.485) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.741) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=0.869) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.989, test=0.957) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.693) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.989, test=0.935) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.591) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.989, test=0.918) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.995, test=0.616) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=0.713) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.411) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=0.793) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.989, test=0.663) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.994, test=0.485) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.741) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.988, test=0.869) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.989, test=0.957) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.991, test=0.693) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.758) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.992, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.997, test=0.935) total time=   0.5s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.994, test=0.485) total time=   0.5s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.860) total time=   0.5s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.605) total time=   0.5s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.995, test=0.728) total time=   0.5s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.997, test=0.282) total time=   0.5s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.993, test=0.821) total time=   0.5s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.996, test=0.654) total time=   0.5s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.996, test=0.577) total time=   0.5s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.999, test=0.756) total time=   0.5s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.868) total time=   0.5s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.961) total time=   0.5s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.998, test=0.660) total time=   0.5s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.997, test=0.805) total time=   0.5s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=30;, score=(train=0.996, test=0.496) total time=   0.5s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.999, test=0.939) total time=   2.0s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.993, test=0.471) total time=   2.0s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.999, test=0.874) total time=   2.0s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.999, test=0.594) total time=   1.9s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.998, test=0.734) total time=   1.9s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.998, test=0.278) total time=   1.9s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.997, test=0.843) total time=   1.9s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.996, test=0.676) total time=   1.9s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.997, test=0.544) total time=   1.9s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.999, test=0.751) total time=   1.8s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.998, test=0.854) total time=   1.9s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.998, test=0.965) total time=   1.9s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.998, test=0.672) total time=   1.9s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.999, test=0.799) total time=   1.9s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=2, n_estimators=100;, score=(train=0.998, test=0.496) total time=   1.9s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.939) total time=   0.1s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.982, test=0.499) total time=   0.1s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.870) total time=   0.1s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.436) total time=   0.1s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.994, test=0.734) total time=   0.1s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.444) total time=   0.1s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.991, test=0.803) total time=   0.1s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.990, test=0.574) total time=   0.1s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.383) total time=   0.1s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.992, test=0.730) total time=   0.1s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.845) total time=   0.1s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.993, test=0.965) total time=   0.1s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.689) total time=   0.1s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.791) total time=   0.1s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=10;, score=(train=0.995, test=0.496) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.948) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=0.457) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=0.946) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.582) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.730) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.223) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=0.762) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=0.699) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.461) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=0.772) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.850) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.952) total time=   0.1s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.730) total time=   0.1s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=0.791) total time=   0.1s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=0.496) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.948) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=0.457) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=0.946) total time=   0.2s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.582) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.730) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.223) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.997, test=0.762) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=0.699) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.998, test=0.461) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=0.772) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.850) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.952) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.995, test=0.730) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.994, test=0.791) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=10;, score=(train=0.996, test=0.496) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.948) total time=   0.1s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.471) total time=   0.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.894) total time=   0.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.450) total time=   0.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.724) total time=   0.1s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.471) total time=   0.1s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.812) total time=   0.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.693) total time=   0.1s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.483) total time=   0.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.758) total time=   0.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.840) total time=   0.1s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.957) total time=   0.1s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.730) total time=   0.1s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.766) total time=   0.1s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.496) total time=   0.1s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.948) total time=   0.1s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.471) total time=   0.1s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.894) total time=   0.1s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.450) total time=   0.1s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.724) total time=   0.1s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.471) total time=   0.1s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.812) total time=   0.1s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.693) total time=   0.1s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.483) total time=   0.1s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.996, test=0.758) total time=   0.1s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.840) total time=   0.1s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.957) total time=   0.1s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.998, test=0.730) total time=   0.1s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.999, test=0.766) total time=   0.1s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=10;, score=(train=0.997, test=0.496) total time=   0.1s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.992, test=0.948) total time=   0.0s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.566) total time=   0.0s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.871) total time=   0.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.421) total time=   0.0s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.739) total time=   0.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.752) total time=   0.0s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.803) total time=   0.0s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.564) total time=   0.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.398) total time=   0.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.771) total time=   0.0s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.681) total time=   0.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.736) total time=   0.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.992, test=0.948) total time=   0.0s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.566) total time=   0.0s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.871) total time=   0.0s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.421) total time=   0.0s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.739) total time=   0.0s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.994, test=0.752) total time=   0.0s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.803) total time=   0.0s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.564) total time=   0.0s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.398) total time=   0.0s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.771) total time=   0.0s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.993, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.681) total time=   0.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.996, test=0.736) total time=   0.0s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.995, test=0.496) total time=   0.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 8\n",
      "n_resources: 9999\n",
      "Fitting 15 folds for each of 8 candidates, totalling 120 fits\n",
      "[CV 1/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.917) total time=   0.2s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.420) total time=   0.3s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.998, test=0.822) total time=   0.2s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.579) total time=   0.2s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.770) total time=   0.2s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.402) total time=   0.2s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.839) total time=   0.2s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.642) total time=   0.2s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.613) total time=   0.2s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.808) total time=   0.2s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.875) total time=   0.2s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.958) total time=   0.2s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=1.000, test=0.695) total time=   0.2s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.830) total time=   0.2s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=5, n_estimators=5;, score=(train=1.000, test=0.498) total time=   0.2s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.920) total time=   0.2s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.415) total time=   0.2s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.998, test=0.822) total time=   0.2s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.579) total time=   0.2s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.770) total time=   0.2s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.402) total time=   0.2s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.839) total time=   0.3s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.642) total time=   0.2s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.613) total time=   0.2s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.808) total time=   0.2s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.875) total time=   0.2s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.947) total time=   0.2s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=1.000, test=0.695) total time=   0.2s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=0.999, test=0.830) total time=   0.2s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=5, n_estimators=5;, score=(train=1.000, test=0.498) total time=   0.2s\n",
      "[CV 1/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.994, test=0.942) total time=   1.6s\n",
      "[CV 2/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.991, test=0.450) total time=   1.8s\n",
      "[CV 3/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.832) total time=   1.7s\n",
      "[CV 4/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.993, test=0.567) total time=   1.6s\n",
      "[CV 5/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.768) total time=   1.7s\n",
      "[CV 6/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.331) total time=   1.6s\n",
      "[CV 7/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.992, test=0.854) total time=   1.7s\n",
      "[CV 8/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.994, test=0.661) total time=   1.7s\n",
      "[CV 9/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.545) total time=   1.7s\n",
      "[CV 10/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.996, test=0.807) total time=   1.6s\n",
      "[CV 11/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.994, test=0.891) total time=   1.6s\n",
      "[CV 12/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.995, test=0.967) total time=   1.6s\n",
      "[CV 13/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.656) total time=   1.6s\n",
      "[CV 14/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.998, test=0.844) total time=   1.6s\n",
      "[CV 15/15] END max_depth=10, min_samples_split=5, n_estimators=30;, score=(train=0.997, test=0.462) total time=   1.7s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.947) total time=   2.9s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.438) total time=   3.1s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.823) total time=   3.0s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.587) total time=   2.9s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.768) total time=   3.0s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.389) total time=   2.8s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.846) total time=   3.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.709) total time=   3.0s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.562) total time=   3.0s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.810) total time=   2.9s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.882) total time=   2.9s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.963) total time=   3.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.662) total time=   2.9s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.843) total time=   3.0s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.462) total time=   2.8s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.953) total time=   1.7s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.448) total time=   1.9s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.823) total time=   1.8s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.577) total time=   1.7s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.764) total time=   1.7s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.438) total time=   1.7s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.846) total time=   1.8s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.697) total time=   1.8s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.560) total time=   1.8s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.822) total time=   1.7s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.877) total time=   1.7s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.960) total time=   1.8s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.682) total time=   1.7s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.843) total time=   1.7s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.462) total time=   1.7s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.956) total time=   1.7s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.440) total time=   1.9s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.823) total time=   1.8s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.577) total time=   1.8s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.764) total time=   1.8s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.438) total time=   1.7s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.845) total time=   1.8s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.701) total time=   1.8s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.550) total time=   1.8s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.823) total time=   1.7s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.873) total time=   1.9s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.963) total time=   1.9s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.680) total time=   1.8s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.843) total time=   1.7s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.462) total time=   1.6s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.923) total time=   0.3s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.420) total time=   0.2s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.833) total time=   0.2s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.531) total time=   0.2s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.770) total time=   0.2s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.375) total time=   0.2s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.811) total time=   0.2s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.595) total time=   0.2s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.997, test=0.637) total time=   0.2s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.682) total time=   0.2s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.891) total time=   0.2s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.937) total time=   0.2s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.999, test=0.665) total time=   0.2s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.999, test=0.828) total time=   0.2s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=10, n_estimators=5;, score=(train=0.997, test=0.472) total time=   0.2s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.923) total time=   0.2s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.420) total time=   0.2s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.833) total time=   0.2s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.531) total time=   0.2s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.770) total time=   0.2s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.375) total time=   0.2s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.811) total time=   0.2s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.589) total time=   0.2s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.997, test=0.637) total time=   0.2s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.682) total time=   0.2s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.891) total time=   0.3s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.998, test=0.937) total time=   0.2s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.999, test=0.665) total time=   0.2s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.999, test=0.828) total time=   0.2s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=10, n_estimators=5;, score=(train=0.997, test=0.472) total time=   0.2s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 29997\n",
      "Fitting 15 folds for each of 3 candidates, totalling 45 fits\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.931) total time=   8.8s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.427) total time=   9.6s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.821) total time=   9.1s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.585) total time=   9.1s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.767) total time=   8.9s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.331) total time=   8.9s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.842) total time=   9.1s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.676) total time=   9.2s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.478) total time=   9.1s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.807) total time=   8.7s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.892) total time=   8.9s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.966) total time=   9.0s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.670) total time=   8.8s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.861) total time=   9.2s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=50;, score=(train=1.000, test=0.471) total time=   8.7s\n",
      "[CV 1/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.930) total time=   5.3s\n",
      "[CV 2/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.456) total time=   5.6s\n",
      "[CV 3/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.806) total time=   5.4s\n",
      "[CV 4/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.585) total time=   5.4s\n",
      "[CV 5/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.762) total time=   5.3s\n",
      "[CV 6/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.387) total time=   5.3s\n",
      "[CV 7/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.824) total time=   5.5s\n",
      "[CV 8/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.689) total time=   5.6s\n",
      "[CV 9/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.492) total time=   5.4s\n",
      "[CV 10/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.813) total time=   5.8s\n",
      "[CV 11/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.891) total time=   5.5s\n",
      "[CV 12/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.968) total time=   5.6s\n",
      "[CV 13/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.669) total time=   6.0s\n",
      "[CV 14/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.865) total time=   6.2s\n",
      "[CV 15/15] END max_depth=30, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.471) total time=   6.3s\n",
      "[CV 1/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.936) total time=   6.2s\n",
      "[CV 2/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.434) total time=   6.5s\n",
      "[CV 3/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.795) total time=   6.4s\n",
      "[CV 4/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.585) total time=   6.7s\n",
      "[CV 5/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.762) total time=   6.2s\n",
      "[CV 6/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.381) total time=   5.7s\n",
      "[CV 7/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.830) total time=   5.8s\n",
      "[CV 8/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.692) total time=   5.4s\n",
      "[CV 9/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.499) total time=   5.4s\n",
      "[CV 10/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.809) total time=   5.1s\n",
      "[CV 11/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.889) total time=   5.5s\n",
      "[CV 12/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.968) total time=   5.9s\n",
      "[CV 13/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.670) total time=   6.0s\n",
      "[CV 14/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.863) total time=   5.9s\n",
      "[CV 15/15] END max_depth=20, min_samples_split=2, n_estimators=30;, score=(train=1.000, test=0.471) total time=   5.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                     random_state=46),\n",
       "                    param_grid={&#x27;max_depth&#x27;: [5, 10, 20, 30],\n",
       "                                &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                &#x27;n_estimators&#x27;: [5, 10, 20, 30, 50, 100]},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=RandomForestClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                     random_state=46),\n",
       "                    param_grid={&#x27;max_depth&#x27;: [5, 10, 20, 30],\n",
       "                                &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                &#x27;n_estimators&#x27;: [5, 10, 20, 30, 50, 100]},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=46)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=46)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                                     random_state=46),\n",
       "                    param_grid={'max_depth': [5, 10, 20, 30],\n",
       "                                'min_samples_split': [2, 5, 10],\n",
       "                                'n_estimators': [5, 10, 20, 30, 50, 100]},\n",
       "                    random_state=46, scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_rf = {'n_estimators': [5, 10, 20, 30, 50, 100],\n",
    "               'max_depth': [5, 10, 20, 30],\n",
    "               'min_samples_split': [2, 5, 10]}\n",
    "rf = RandomForestClassifier(random_state=46, class_weight= 'balanced')\n",
    "rf_hyperparams = HalvingGridSearchCV(rf, parameters_rf, cv = cv, scoring = 'f1_weighted', random_state=46, verbose=3)\n",
    "rf_hyperparams.fit(X, y, groups = groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78223bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 30}\n",
      "0.7072752124043146\n"
     ]
    }
   ],
   "source": [
    "print(rf_hyperparams.best_params_)\n",
    "print(rf_hyperparams.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "071b556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = rf_hyperparams.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d873bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=46, class_weight= 'balanced', n_estimators = 30, min_samples_split= 2, max_depth= 30)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07c69448",
   "metadata": {},
   "source": [
    "### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb573df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 370\n",
      "max_resources_: 30000\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 100\n",
      "n_resources: 370\n",
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n",
      "[CV 1/15] END var_smoothing=1e-09;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-09;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-09;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-09;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-09;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-09;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-09;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-09;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-09;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-09;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-09;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-09;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-09;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-09;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-09;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805e-08;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083061e-08;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.579332246575682e-08;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1e-07;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-07;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-07;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-07;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-07;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-07;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-07;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-07;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-07;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-07;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-07;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-07;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-07;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-07;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-07;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.747, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.519911082952933e-07;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.750, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.750, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151277e-07;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.710, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.599, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.750, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.336699231206313e-07;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.707, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.750, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.111308307896872e-07;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.707, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.752, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.232846739442066e-06;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.707, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.752, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.873817422860387e-06;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.707, test=0.760) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.666, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.752, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.661, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805e-06;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.707, test=0.805) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.666, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.752, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.644, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.664, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.707, test=0.805) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.666, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.752, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.641, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.664, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1e-05;, score=(train=0.621, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-05;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-05;, score=(train=0.707, test=0.805) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-05;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-05;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-05;, score=(train=0.666, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-05;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-05;, score=(train=0.752, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-05;, score=(train=0.627, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-05;, score=(train=0.587, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-05;, score=(train=0.641, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-05;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-05;, score=(train=0.664, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-05;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-05;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.624, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.707, test=0.805) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.666, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.752, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.631, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.592, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.641, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.664, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.624, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.707, test=0.805) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.666, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.752, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.631, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.595, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.641, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.664, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.624, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.707, test=0.805) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.644, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.640, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.761, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.631, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.595, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.639, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.685, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.664, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.627, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.707, test=0.805) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.603, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.647, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.663, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.643, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.761, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.631, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.595, test=0.456) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.642, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.679, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.664, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.718, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.3366992312063123e-05;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.624, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.611, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.704, test=0.770) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.602, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.647, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.666, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.643, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.758, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.631, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.596, test=0.456) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.648, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.676, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.664, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.716, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.111308307896872e-05;, score=(train=0.666, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0001232846739442066;, score=(train=0.624, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0001232846739442066;, score=(train=0.615, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0001232846739442066;, score=(train=0.713, test=0.770) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0001232846739442066;, score=(train=0.604, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0001232846739442066;, score=(train=0.651, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0001232846739442066;, score=(train=0.666, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0001232846739442066;, score=(train=0.646, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0001232846739442066;, score=(train=0.758, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0001232846739442066;, score=(train=0.631, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0001232846739442066;, score=(train=0.599, test=0.456) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0001232846739442066;, score=(train=0.654, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0001232846739442066;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0001232846739442066;, score=(train=0.667, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0001232846739442066;, score=(train=0.716, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0001232846739442066;, score=(train=0.669, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0001873817422860383;, score=(train=0.627, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0001873817422860383;, score=(train=0.612, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0001873817422860383;, score=(train=0.719, test=0.770) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0001873817422860383;, score=(train=0.602, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0001873817422860383;, score=(train=0.651, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0001873817422860383;, score=(train=0.672, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0001873817422860383;, score=(train=0.646, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0001873817422860383;, score=(train=0.758, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0001873817422860383;, score=(train=0.631, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0001873817422860383;, score=(train=0.599, test=0.456) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0001873817422860383;, score=(train=0.657, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0001873817422860383;, score=(train=0.682, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0001873817422860383;, score=(train=0.667, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0001873817422860383;, score=(train=0.716, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0001873817422860383;, score=(train=0.666, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0002848035868435805;, score=(train=0.630, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0002848035868435805;, score=(train=0.615, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0002848035868435805;, score=(train=0.725, test=0.770) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0002848035868435805;, score=(train=0.604, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0002848035868435805;, score=(train=0.654, test=0.285) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0002848035868435805;, score=(train=0.672, test=0.767) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0002848035868435805;, score=(train=0.646, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0002848035868435805;, score=(train=0.758, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0002848035868435805;, score=(train=0.628, test=0.874) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0002848035868435805;, score=(train=0.610, test=0.456) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0002848035868435805;, score=(train=0.658, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0002848035868435805;, score=(train=0.682, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0002848035868435805;, score=(train=0.662, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0002848035868435805;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0002848035868435805;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.00043287612810830614;, score=(train=0.628, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.00043287612810830614;, score=(train=0.613, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.00043287612810830614;, score=(train=0.714, test=0.770) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.00043287612810830614;, score=(train=0.604, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.00043287612810830614;, score=(train=0.660, test=0.349) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.00043287612810830614;, score=(train=0.666, test=0.706) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.00043287612810830614;, score=(train=0.652, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.00043287612810830614;, score=(train=0.755, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.00043287612810830614;, score=(train=0.632, test=0.917) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.00043287612810830614;, score=(train=0.616, test=0.456) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.00043287612810830614;, score=(train=0.656, test=0.806) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.00043287612810830614;, score=(train=0.691, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.00043287612810830614;, score=(train=0.662, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.00043287612810830614;, score=(train=0.718, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.00043287612810830614;, score=(train=0.660, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0006579332246575682;, score=(train=0.628, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0006579332246575682;, score=(train=0.619, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0006579332246575682;, score=(train=0.723, test=0.770) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0006579332246575682;, score=(train=0.609, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0006579332246575682;, score=(train=0.664, test=0.407) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0006579332246575682;, score=(train=0.666, test=0.706) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0006579332246575682;, score=(train=0.655, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0006579332246575682;, score=(train=0.761, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0006579332246575682;, score=(train=0.629, test=0.917) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0006579332246575682;, score=(train=0.616, test=0.456) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0006579332246575682;, score=(train=0.659, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0006579332246575682;, score=(train=0.703, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0006579332246575682;, score=(train=0.662, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0006579332246575682;, score=(train=0.727, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0006579332246575682;, score=(train=0.660, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.001;, score=(train=0.629, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.001;, score=(train=0.613, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.001;, score=(train=0.720, test=0.770) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.001;, score=(train=0.619, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.001;, score=(train=0.658, test=0.407) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.001;, score=(train=0.666, test=0.706) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.001;, score=(train=0.657, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.001;, score=(train=0.764, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.001;, score=(train=0.630, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.001;, score=(train=0.628, test=0.487) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.001;, score=(train=0.659, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.001;, score=(train=0.706, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.001;, score=(train=0.660, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.001;, score=(train=0.727, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.001;, score=(train=0.663, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0015199110829529332;, score=(train=0.632, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0015199110829529332;, score=(train=0.615, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0015199110829529332;, score=(train=0.717, test=0.770) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0015199110829529332;, score=(train=0.629, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0015199110829529332;, score=(train=0.655, test=0.407) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0015199110829529332;, score=(train=0.670, test=0.706) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0015199110829529332;, score=(train=0.661, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0015199110829529332;, score=(train=0.767, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0015199110829529332;, score=(train=0.639, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0015199110829529332;, score=(train=0.628, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0015199110829529332;, score=(train=0.662, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0015199110829529332;, score=(train=0.703, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0015199110829529332;, score=(train=0.668, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0015199110829529332;, score=(train=0.727, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0015199110829529332;, score=(train=0.672, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0023101297000831626;, score=(train=0.638, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0023101297000831626;, score=(train=0.616, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0023101297000831626;, score=(train=0.712, test=0.770) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0023101297000831626;, score=(train=0.626, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0023101297000831626;, score=(train=0.655, test=0.407) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0023101297000831626;, score=(train=0.673, test=0.706) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0023101297000831626;, score=(train=0.655, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0023101297000831626;, score=(train=0.764, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0023101297000831626;, score=(train=0.645, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0023101297000831626;, score=(train=0.626, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0023101297000831626;, score=(train=0.665, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0023101297000831626;, score=(train=0.712, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0023101297000831626;, score=(train=0.677, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0023101297000831626;, score=(train=0.730, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0023101297000831626;, score=(train=0.675, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0035111917342151347;, score=(train=0.636, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0035111917342151347;, score=(train=0.622, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0035111917342151347;, score=(train=0.718, test=0.736) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0035111917342151347;, score=(train=0.621, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0035111917342151347;, score=(train=0.658, test=0.407) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0035111917342151347;, score=(train=0.684, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0035111917342151347;, score=(train=0.655, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0035111917342151347;, score=(train=0.764, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0035111917342151347;, score=(train=0.635, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0035111917342151347;, score=(train=0.626, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0035111917342151347;, score=(train=0.668, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0035111917342151347;, score=(train=0.709, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0035111917342151347;, score=(train=0.674, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0035111917342151347;, score=(train=0.739, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0035111917342151347;, score=(train=0.690, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.005336699231206312;, score=(train=0.636, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.005336699231206312;, score=(train=0.632, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.005336699231206312;, score=(train=0.720, test=0.776) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.005336699231206312;, score=(train=0.619, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.005336699231206312;, score=(train=0.658, test=0.462) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.005336699231206312;, score=(train=0.684, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.005336699231206312;, score=(train=0.655, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.005336699231206312;, score=(train=0.764, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.005336699231206312;, score=(train=0.638, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.005336699231206312;, score=(train=0.633, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.005336699231206312;, score=(train=0.674, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.005336699231206312;, score=(train=0.715, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.005336699231206312;, score=(train=0.675, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.005336699231206312;, score=(train=0.733, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.005336699231206312;, score=(train=0.687, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.008111308307896872;, score=(train=0.647, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.008111308307896872;, score=(train=0.632, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.008111308307896872;, score=(train=0.721, test=0.777) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.008111308307896872;, score=(train=0.611, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.008111308307896872;, score=(train=0.661, test=0.560) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.008111308307896872;, score=(train=0.696, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.008111308307896872;, score=(train=0.649, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.008111308307896872;, score=(train=0.767, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.008111308307896872;, score=(train=0.635, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.008111308307896872;, score=(train=0.627, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.008111308307896872;, score=(train=0.686, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.008111308307896872;, score=(train=0.712, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.008111308307896872;, score=(train=0.672, test=0.308) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.008111308307896872;, score=(train=0.730, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.008111308307896872;, score=(train=0.690, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.012328467394420659;, score=(train=0.659, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.012328467394420659;, score=(train=0.641, test=0.597) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.012328467394420659;, score=(train=0.718, test=0.777) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.012328467394420659;, score=(train=0.615, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.012328467394420659;, score=(train=0.664, test=0.605) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.012328467394420659;, score=(train=0.702, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.012328467394420659;, score=(train=0.646, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.012328467394420659;, score=(train=0.761, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.012328467394420659;, score=(train=0.639, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.012328467394420659;, score=(train=0.631, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.012328467394420659;, score=(train=0.680, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.012328467394420659;, score=(train=0.704, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.012328467394420659;, score=(train=0.675, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.012328467394420659;, score=(train=0.733, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.012328467394420659;, score=(train=0.699, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.01873817422860387;, score=(train=0.657, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.01873817422860387;, score=(train=0.641, test=0.597) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.01873817422860387;, score=(train=0.718, test=0.777) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.01873817422860387;, score=(train=0.620, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.01873817422860387;, score=(train=0.664, test=0.689) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.01873817422860387;, score=(train=0.714, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.01873817422860387;, score=(train=0.644, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.01873817422860387;, score=(train=0.758, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.01873817422860387;, score=(train=0.647, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.01873817422860387;, score=(train=0.632, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.01873817422860387;, score=(train=0.686, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.01873817422860387;, score=(train=0.704, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.01873817422860387;, score=(train=0.680, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.01873817422860387;, score=(train=0.727, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.01873817422860387;, score=(train=0.702, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.028480358684358047;, score=(train=0.657, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.028480358684358047;, score=(train=0.639, test=0.597) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.028480358684358047;, score=(train=0.721, test=0.777) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.028480358684358047;, score=(train=0.616, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.028480358684358047;, score=(train=0.662, test=0.768) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.028480358684358047;, score=(train=0.714, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.028480358684358047;, score=(train=0.652, test=0.422) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.028480358684358047;, score=(train=0.758, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.028480358684358047;, score=(train=0.659, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.028480358684358047;, score=(train=0.634, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.028480358684358047;, score=(train=0.695, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.028480358684358047;, score=(train=0.704, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.028480358684358047;, score=(train=0.675, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.028480358684358047;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.028480358684358047;, score=(train=0.696, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.043287612810830614;, score=(train=0.663, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.043287612810830614;, score=(train=0.651, test=0.532) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.043287612810830614;, score=(train=0.723, test=0.661) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.043287612810830614;, score=(train=0.617, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.043287612810830614;, score=(train=0.659, test=0.768) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.043287612810830614;, score=(train=0.723, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.043287612810830614;, score=(train=0.649, test=0.422) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.043287612810830614;, score=(train=0.761, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.043287612810830614;, score=(train=0.662, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.043287612810830614;, score=(train=0.642, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.043287612810830614;, score=(train=0.701, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.043287612810830614;, score=(train=0.698, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.043287612810830614;, score=(train=0.672, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.043287612810830614;, score=(train=0.719, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.043287612810830614;, score=(train=0.693, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.06579332246575682;, score=(train=0.666, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.06579332246575682;, score=(train=0.649, test=0.532) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.06579332246575682;, score=(train=0.726, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.06579332246575682;, score=(train=0.636, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.06579332246575682;, score=(train=0.662, test=0.844) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.06579332246575682;, score=(train=0.720, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.06579332246575682;, score=(train=0.659, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.06579332246575682;, score=(train=0.755, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.06579332246575682;, score=(train=0.668, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.06579332246575682;, score=(train=0.643, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.06579332246575682;, score=(train=0.701, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.06579332246575682;, score=(train=0.695, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.06579332246575682;, score=(train=0.686, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.06579332246575682;, score=(train=0.716, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.06579332246575682;, score=(train=0.693, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.1;, score=(train=0.675, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.1;, score=(train=0.655, test=0.532) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.1;, score=(train=0.721, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.1;, score=(train=0.654, test=0.739) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.1;, score=(train=0.665, test=0.920) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.1;, score=(train=0.720, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.1;, score=(train=0.674, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.1;, score=(train=0.755, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.1;, score=(train=0.671, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.1;, score=(train=0.653, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.1;, score=(train=0.701, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.1;, score=(train=0.686, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.1;, score=(train=0.681, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.1;, score=(train=0.719, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.1;, score=(train=0.705, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.1519911082952933;, score=(train=0.678, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.1519911082952933;, score=(train=0.655, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.1519911082952933;, score=(train=0.718, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.1519911082952933;, score=(train=0.660, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.1519911082952933;, score=(train=0.662, test=0.959) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.1519911082952933;, score=(train=0.720, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.1519911082952933;, score=(train=0.671, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.1519911082952933;, score=(train=0.752, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.1519911082952933;, score=(train=0.665, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.1519911082952933;, score=(train=0.671, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.1519911082952933;, score=(train=0.701, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.1519911082952933;, score=(train=0.686, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.1519911082952933;, score=(train=0.687, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.1519911082952933;, score=(train=0.719, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.1519911082952933;, score=(train=0.696, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.2310129700083158;, score=(train=0.681, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.2310129700083158;, score=(train=0.649, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.2310129700083158;, score=(train=0.715, test=0.576) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.2310129700083158;, score=(train=0.666, test=0.637) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.2310129700083158;, score=(train=0.677, test=0.959) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.2310129700083158;, score=(train=0.715, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.2310129700083158;, score=(train=0.674, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.2310129700083158;, score=(train=0.750, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.2310129700083158;, score=(train=0.674, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.2310129700083158;, score=(train=0.671, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.2310129700083158;, score=(train=0.701, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.2310129700083158;, score=(train=0.686, test=0.918) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.2310129700083158;, score=(train=0.687, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.2310129700083158;, score=(train=0.721, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.2310129700083158;, score=(train=0.688, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.3511191734215127;, score=(train=0.684, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.3511191734215127;, score=(train=0.643, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.3511191734215127;, score=(train=0.709, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.3511191734215127;, score=(train=0.667, test=0.580) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.3511191734215127;, score=(train=0.677, test=0.959) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.3511191734215127;, score=(train=0.723, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.3511191734215127;, score=(train=0.677, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.3511191734215127;, score=(train=0.744, test=0.373) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.3511191734215127;, score=(train=0.674, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.3511191734215127;, score=(train=0.671, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.3511191734215127;, score=(train=0.698, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.3511191734215127;, score=(train=0.680, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.3511191734215127;, score=(train=0.687, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.3511191734215127;, score=(train=0.716, test=0.548) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.3511191734215127;, score=(train=0.685, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.5336699231206302;, score=(train=0.692, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.5336699231206302;, score=(train=0.644, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.5336699231206302;, score=(train=0.706, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.5336699231206302;, score=(train=0.664, test=0.580) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.5336699231206302;, score=(train=0.686, test=0.917) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.5336699231206302;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.5336699231206302;, score=(train=0.677, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.5336699231206302;, score=(train=0.747, test=0.373) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.5336699231206302;, score=(train=0.678, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.5336699231206302;, score=(train=0.671, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.5336699231206302;, score=(train=0.698, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.5336699231206302;, score=(train=0.677, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.5336699231206302;, score=(train=0.692, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.5336699231206302;, score=(train=0.721, test=0.612) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.5336699231206302;, score=(train=0.691, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.811130830789689;, score=(train=0.681, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.811130830789689;, score=(train=0.650, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.811130830789689;, score=(train=0.706, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.811130830789689;, score=(train=0.667, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.811130830789689;, score=(train=0.686, test=0.917) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.811130830789689;, score=(train=0.724, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.811130830789689;, score=(train=0.674, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.811130830789689;, score=(train=0.747, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.811130830789689;, score=(train=0.678, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.811130830789689;, score=(train=0.672, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.811130830789689;, score=(train=0.706, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.811130830789689;, score=(train=0.691, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.811130830789689;, score=(train=0.701, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.811130830789689;, score=(train=0.724, test=0.612) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.811130830789689;, score=(train=0.694, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.2328467394420684;, score=(train=0.695, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.2328467394420684;, score=(train=0.653, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.2328467394420684;, score=(train=0.712, test=0.529) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.2328467394420684;, score=(train=0.676, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.2328467394420684;, score=(train=0.700, test=0.706) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.2328467394420684;, score=(train=0.738, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.2328467394420684;, score=(train=0.675, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.2328467394420684;, score=(train=0.750, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.2328467394420684;, score=(train=0.678, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.2328467394420684;, score=(train=0.669, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.2328467394420684;, score=(train=0.701, test=0.844) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.2328467394420684;, score=(train=0.706, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.2328467394420684;, score=(train=0.717, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.2328467394420684;, score=(train=0.724, test=0.670) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.2328467394420684;, score=(train=0.718, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.8738174228603868;, score=(train=0.716, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.8738174228603868;, score=(train=0.677, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.8738174228603868;, score=(train=0.712, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.8738174228603868;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.8738174228603868;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.8738174228603868;, score=(train=0.743, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.8738174228603868;, score=(train=0.690, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.8738174228603868;, score=(train=0.747, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.8738174228603868;, score=(train=0.675, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.8738174228603868;, score=(train=0.678, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.8738174228603868;, score=(train=0.709, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.8738174228603868;, score=(train=0.718, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.8738174228603868;, score=(train=0.736, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.8738174228603868;, score=(train=0.741, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.8738174228603868;, score=(train=0.729, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805;, score=(train=0.729, test=0.920) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805;, score=(train=0.717, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805;, score=(train=0.738, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805;, score=(train=0.699, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805;, score=(train=0.757, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805;, score=(train=0.747, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805;, score=(train=0.685, test=0.518) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805;, score=(train=0.766, test=0.684) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805;, score=(train=0.673, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805;, score=(train=0.693, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805;, score=(train=0.725, test=0.796) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805;, score=(train=0.743, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805;, score=(train=0.758, test=0.431) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805;, score=(train=0.774, test=0.826) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805;, score=(train=0.740, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083062;, score=(train=0.691, test=0.878) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083062;, score=(train=0.735, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083062;, score=(train=0.756, test=0.851) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083062;, score=(train=0.726, test=0.601) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083062;, score=(train=0.742, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083062;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083062;, score=(train=0.707, test=0.831) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083062;, score=(train=0.763, test=0.870) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083062;, score=(train=0.718, test=0.915) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083062;, score=(train=0.743, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083062;, score=(train=0.738, test=0.674) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083062;, score=(train=0.739, test=0.875) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083062;, score=(train=0.761, test=0.330) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083062;, score=(train=0.774, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083062;, score=(train=0.760, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.5793322465756825;, score=(train=0.608, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.5793322465756825;, score=(train=0.768, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.5793322465756825;, score=(train=0.652, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.5793322465756825;, score=(train=0.723, test=0.707) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.5793322465756825;, score=(train=0.628, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.5793322465756825;, score=(train=0.664, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.5793322465756825;, score=(train=0.700, test=0.833) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.5793322465756825;, score=(train=0.719, test=0.769) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.5793322465756825;, score=(train=0.685, test=0.915) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.5793322465756825;, score=(train=0.725, test=0.831) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.5793322465756825;, score=(train=0.688, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.5793322465756825;, score=(train=0.704, test=0.607) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.5793322465756825;, score=(train=0.595, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.5793322465756825;, score=(train=0.727, test=0.316) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.5793322465756825;, score=(train=0.681, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=10.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=10.0;, score=(train=0.709, test=0.658) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=10.0;, score=(train=0.508, test=0.740) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=10.0;, score=(train=0.643, test=0.361) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=10.0;, score=(train=0.506, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=10.0;, score=(train=0.550, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=10.0;, score=(train=0.617, test=0.739) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=10.0;, score=(train=0.650, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=10.0;, score=(train=0.653, test=0.611) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=10.0;, score=(train=0.605, test=1.000) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=10.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=10.0;, score=(train=0.566, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=10.0;, score=(train=0.506, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=10.0;, score=(train=0.592, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=10.0;, score=(train=0.562, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=15.199110829529332;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=15.199110829529332;, score=(train=0.479, test=0.909) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=15.199110829529332;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=15.199110829529332;, score=(train=0.474, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=15.199110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=15.199110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=15.199110829529332;, score=(train=0.457, test=0.468) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=15.199110829529332;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=15.199110829529332;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=15.199110829529332;, score=(train=0.467, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=15.199110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=15.199110829529332;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=15.199110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=15.199110829529332;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=15.199110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=23.10129700083158;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=23.10129700083158;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=23.10129700083158;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=23.10129700083158;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=23.10129700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=23.10129700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=23.10129700083158;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=23.10129700083158;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=23.10129700083158;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=23.10129700083158;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=23.10129700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=23.10129700083158;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=23.10129700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=23.10129700083158;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=23.10129700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=35.11191734215127;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=35.11191734215127;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=35.11191734215127;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=35.11191734215127;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=35.11191734215127;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=35.11191734215127;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=35.11191734215127;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=35.11191734215127;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=35.11191734215127;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=35.11191734215127;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=35.11191734215127;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=35.11191734215127;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=35.11191734215127;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=35.11191734215127;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=35.11191734215127;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=53.36699231206324;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=53.36699231206324;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=53.36699231206324;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=53.36699231206324;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=53.36699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=53.36699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=53.36699231206324;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=53.36699231206324;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=53.36699231206324;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=53.36699231206324;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=53.36699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=53.36699231206324;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=53.36699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=53.36699231206324;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=53.36699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=81.11308307896888;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=81.11308307896888;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=81.11308307896888;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=81.11308307896888;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=81.11308307896888;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=81.11308307896888;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=81.11308307896888;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=81.11308307896888;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=81.11308307896888;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=81.11308307896888;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=81.11308307896888;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=81.11308307896888;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=81.11308307896888;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=81.11308307896888;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=81.11308307896888;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=123.28467394420684;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=123.28467394420684;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=123.28467394420684;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=123.28467394420684;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=123.28467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=123.28467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=123.28467394420684;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=123.28467394420684;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=123.28467394420684;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=123.28467394420684;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=123.28467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=123.28467394420684;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=123.28467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=123.28467394420684;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=123.28467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=187.38174228603867;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=187.38174228603867;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=187.38174228603867;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=187.38174228603867;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=187.38174228603867;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=187.38174228603867;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=187.38174228603867;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=187.38174228603867;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=187.38174228603867;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=187.38174228603867;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=187.38174228603867;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=187.38174228603867;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=187.38174228603867;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=187.38174228603867;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=187.38174228603867;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=284.8035868435805;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=284.8035868435805;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=284.8035868435805;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=284.8035868435805;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=284.8035868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=284.8035868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=284.8035868435805;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=284.8035868435805;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=284.8035868435805;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=284.8035868435805;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=284.8035868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=284.8035868435805;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=284.8035868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=284.8035868435805;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=284.8035868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=432.87612810830615;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=432.87612810830615;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=432.87612810830615;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=432.87612810830615;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=432.87612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=432.87612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=432.87612810830615;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=432.87612810830615;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=432.87612810830615;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=432.87612810830615;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=432.87612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=432.87612810830615;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=432.87612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=432.87612810830615;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=432.87612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=657.9332246575682;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=657.9332246575682;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=657.9332246575682;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=657.9332246575682;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=657.9332246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=657.9332246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=657.9332246575682;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=657.9332246575682;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=657.9332246575682;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=657.9332246575682;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=657.9332246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=657.9332246575682;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=657.9332246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=657.9332246575682;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=657.9332246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1000.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1000.0;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1000.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1000.0;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1000.0;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1000.0;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1000.0;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1000.0;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1000.0;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1000.0;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1519.9110829529332;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1519.9110829529332;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1519.9110829529332;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1519.9110829529332;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1519.9110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1519.9110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1519.9110829529332;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1519.9110829529332;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1519.9110829529332;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1519.9110829529332;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1519.9110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1519.9110829529332;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1519.9110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1519.9110829529332;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1519.9110829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2310.1297000831582;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2310.1297000831582;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2310.1297000831582;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2310.1297000831582;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2310.1297000831582;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2310.1297000831582;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2310.1297000831582;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2310.1297000831582;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2310.1297000831582;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2310.1297000831582;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2310.1297000831582;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2310.1297000831582;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2310.1297000831582;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2310.1297000831582;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2310.1297000831582;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3511.1917342151273;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3511.1917342151273;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3511.1917342151273;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3511.1917342151273;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3511.1917342151273;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3511.1917342151273;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3511.1917342151273;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3511.1917342151273;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3511.1917342151273;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3511.1917342151273;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3511.1917342151273;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3511.1917342151273;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3511.1917342151273;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3511.1917342151273;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3511.1917342151273;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5336.699231206324;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5336.699231206324;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5336.699231206324;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5336.699231206324;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5336.699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5336.699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5336.699231206324;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5336.699231206324;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5336.699231206324;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5336.699231206324;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5336.699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5336.699231206324;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5336.699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5336.699231206324;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5336.699231206324;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8111.308307896889;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8111.308307896889;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8111.308307896889;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8111.308307896889;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8111.308307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8111.308307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8111.308307896889;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8111.308307896889;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8111.308307896889;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8111.308307896889;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8111.308307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8111.308307896889;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8111.308307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8111.308307896889;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8111.308307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=12328.467394420684;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=12328.467394420684;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=12328.467394420684;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=12328.467394420684;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=12328.467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=12328.467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=12328.467394420684;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=12328.467394420684;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=12328.467394420684;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=12328.467394420684;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=12328.467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=12328.467394420684;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=12328.467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=12328.467394420684;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=12328.467394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=18738.174228603868;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=18738.174228603868;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=18738.174228603868;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=18738.174228603868;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=18738.174228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=18738.174228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=18738.174228603868;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=18738.174228603868;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=18738.174228603868;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=18738.174228603868;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=18738.174228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=18738.174228603868;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=18738.174228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=18738.174228603868;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=18738.174228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=28480.35868435805;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=28480.35868435805;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=28480.35868435805;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=28480.35868435805;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=28480.35868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=28480.35868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=28480.35868435805;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=28480.35868435805;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=28480.35868435805;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=28480.35868435805;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=28480.35868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=28480.35868435805;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=28480.35868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=28480.35868435805;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=28480.35868435805;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=43287.612810830615;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=43287.612810830615;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=43287.612810830615;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=43287.612810830615;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=43287.612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=43287.612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=43287.612810830615;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=43287.612810830615;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=43287.612810830615;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=43287.612810830615;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=43287.612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=43287.612810830615;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=43287.612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=43287.612810830615;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=43287.612810830615;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=65793.32246575682;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=65793.32246575682;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=65793.32246575682;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=65793.32246575682;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=65793.32246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=65793.32246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=65793.32246575682;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=65793.32246575682;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=65793.32246575682;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=65793.32246575682;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=65793.32246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=65793.32246575682;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=65793.32246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=65793.32246575682;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=65793.32246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=100000.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=100000.0;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=100000.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=100000.0;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=100000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=100000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=100000.0;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=100000.0;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=100000.0;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=100000.0;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=100000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=100000.0;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=100000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=100000.0;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=100000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=151991.10829529332;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=151991.10829529332;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=151991.10829529332;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=151991.10829529332;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=151991.10829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=151991.10829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=151991.10829529332;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=151991.10829529332;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=151991.10829529332;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=151991.10829529332;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=151991.10829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=151991.10829529332;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=151991.10829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=151991.10829529332;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=151991.10829529332;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=231012.9700083158;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=231012.9700083158;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=231012.9700083158;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=231012.9700083158;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=231012.9700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=231012.9700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=231012.9700083158;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=231012.9700083158;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=231012.9700083158;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=231012.9700083158;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=231012.9700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=231012.9700083158;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=231012.9700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=231012.9700083158;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=231012.9700083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=351119.17342151416;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=351119.17342151416;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=351119.17342151416;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=351119.17342151416;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=351119.17342151416;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=351119.17342151416;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=351119.17342151416;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=351119.17342151416;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=351119.17342151416;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=351119.17342151416;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=351119.17342151416;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=351119.17342151416;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=351119.17342151416;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=351119.17342151416;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=351119.17342151416;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=533669.9231206323;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=533669.9231206323;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=533669.9231206323;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=533669.9231206323;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=533669.9231206323;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=533669.9231206323;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=533669.9231206323;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=533669.9231206323;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=533669.9231206323;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=533669.9231206323;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=533669.9231206323;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=533669.9231206323;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=533669.9231206323;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=533669.9231206323;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=533669.9231206323;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=811130.8307896889;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=811130.8307896889;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=811130.8307896889;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=811130.8307896889;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=811130.8307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=811130.8307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=811130.8307896889;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=811130.8307896889;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=811130.8307896889;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=811130.8307896889;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=811130.8307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=811130.8307896889;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=811130.8307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=811130.8307896889;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=811130.8307896889;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1232846.7394420684;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1232846.7394420684;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1232846.7394420684;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1232846.7394420684;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1232846.7394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1232846.7394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1232846.7394420684;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1232846.7394420684;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1232846.7394420684;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1232846.7394420684;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1232846.7394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1232846.7394420684;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1232846.7394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1232846.7394420684;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1232846.7394420684;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1873817.4228603868;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1873817.4228603868;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1873817.4228603868;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1873817.4228603868;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1873817.4228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1873817.4228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1873817.4228603868;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1873817.4228603868;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1873817.4228603868;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1873817.4228603868;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1873817.4228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1873817.4228603868;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1873817.4228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1873817.4228603868;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1873817.4228603868;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2848035.8684358047;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2848035.8684358047;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2848035.8684358047;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2848035.8684358047;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2848035.8684358047;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2848035.8684358047;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2848035.8684358047;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2848035.8684358047;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2848035.8684358047;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2848035.8684358047;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2848035.8684358047;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2848035.8684358047;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2848035.8684358047;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2848035.8684358047;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2848035.8684358047;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4328761.281083061;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4328761.281083061;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4328761.281083061;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4328761.281083061;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4328761.281083061;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4328761.281083061;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4328761.281083061;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4328761.281083061;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4328761.281083061;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4328761.281083061;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4328761.281083061;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4328761.281083061;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4328761.281083061;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4328761.281083061;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4328761.281083061;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6579332.246575682;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6579332.246575682;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6579332.246575682;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6579332.246575682;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6579332.246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6579332.246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6579332.246575682;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6579332.246575682;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6579332.246575682;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6579332.246575682;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6579332.246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6579332.246575682;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6579332.246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6579332.246575682;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6579332.246575682;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=10000000.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=10000000.0;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=10000000.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=10000000.0;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=10000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=10000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=10000000.0;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=10000000.0;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=10000000.0;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=10000000.0;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=10000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=10000000.0;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=10000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=10000000.0;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=10000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=15199110.829529393;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=15199110.829529393;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=15199110.829529393;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=15199110.829529393;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=15199110.829529393;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=15199110.829529393;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=15199110.829529393;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=15199110.829529393;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=15199110.829529393;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=15199110.829529393;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=15199110.829529393;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=15199110.829529393;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=15199110.829529393;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=15199110.829529393;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=15199110.829529393;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=23101297.00083158;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=23101297.00083158;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=23101297.00083158;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=23101297.00083158;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=23101297.00083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=23101297.00083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=23101297.00083158;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=23101297.00083158;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=23101297.00083158;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=23101297.00083158;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=23101297.00083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=23101297.00083158;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=23101297.00083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=23101297.00083158;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=23101297.00083158;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=35111917.34215142;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=35111917.34215142;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=35111917.34215142;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=35111917.34215142;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=35111917.34215142;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=35111917.34215142;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=35111917.34215142;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=35111917.34215142;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=35111917.34215142;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=35111917.34215142;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=35111917.34215142;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=35111917.34215142;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=35111917.34215142;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=35111917.34215142;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=35111917.34215142;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=53366992.312063016;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=53366992.312063016;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=53366992.312063016;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=53366992.312063016;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=53366992.312063016;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=53366992.312063016;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=53366992.312063016;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=53366992.312063016;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=53366992.312063016;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=53366992.312063016;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=53366992.312063016;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=53366992.312063016;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=53366992.312063016;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=53366992.312063016;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=53366992.312063016;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=81113083.0789689;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=81113083.0789689;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=81113083.0789689;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=81113083.0789689;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=81113083.0789689;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=81113083.0789689;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=81113083.0789689;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=81113083.0789689;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=81113083.0789689;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=81113083.0789689;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=81113083.0789689;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=81113083.0789689;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=81113083.0789689;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=81113083.0789689;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=81113083.0789689;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=123284673.94420634;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=123284673.94420634;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=123284673.94420634;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=123284673.94420634;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=123284673.94420634;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=123284673.94420634;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=123284673.94420634;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=123284673.94420634;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=123284673.94420634;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=123284673.94420634;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=123284673.94420634;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=123284673.94420634;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=123284673.94420634;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=123284673.94420634;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=123284673.94420634;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=187381742.2860387;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=187381742.2860387;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=187381742.2860387;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=187381742.2860387;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=187381742.2860387;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=187381742.2860387;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=187381742.2860387;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=187381742.2860387;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=187381742.2860387;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=187381742.2860387;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=187381742.2860387;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=187381742.2860387;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=187381742.2860387;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=187381742.2860387;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=187381742.2860387;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=284803586.8435793;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=284803586.8435793;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=284803586.8435793;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=284803586.8435793;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=284803586.8435793;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=284803586.8435793;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=284803586.8435793;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=284803586.8435793;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=284803586.8435793;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=284803586.8435793;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=284803586.8435793;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=284803586.8435793;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=284803586.8435793;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=284803586.8435793;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=284803586.8435793;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=432876128.10830617;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=432876128.10830617;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=432876128.10830617;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=432876128.10830617;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=432876128.10830617;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=432876128.10830617;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=432876128.10830617;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=432876128.10830617;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=432876128.10830617;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=432876128.10830617;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=432876128.10830617;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=432876128.10830617;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=432876128.10830617;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=432876128.10830617;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=432876128.10830617;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=657933224.657571;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=657933224.657571;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=657933224.657571;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=657933224.657571;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=657933224.657571;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=657933224.657571;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=657933224.657571;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=657933224.657571;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=657933224.657571;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=657933224.657571;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=657933224.657571;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=657933224.657571;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=657933224.657571;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=657933224.657571;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=657933224.657571;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1000000000.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1000000000.0;, score=(train=0.435, test=0.385) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1000000000.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1000000000.0;, score=(train=0.461, test=0.381) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1000000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1000000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1000000000.0;, score=(train=0.457, test=0.381) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1000000000.0;, score=(train=0.480, test=0.358) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1000000000.0;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1000000000.0;, score=(train=0.454, test=0.381) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1000000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1000000000.0;, score=(train=0.456, test=0.450) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1000000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1000000000.0;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1000000000.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 34\n",
      "n_resources: 1110\n",
      "Fitting 15 folds for each of 34 candidates, totalling 510 fits\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.606, test=0.667) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.702, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.672, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.627, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-07;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.606, test=0.667) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.702, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.672, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.627, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.232846739442066e-08;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.606, test=0.667) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.702, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.672, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.627, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=8.11130830789689e-09;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.606, test=0.667) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.702, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.672, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.627, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=5.336699231206302e-09;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.606, test=0.667) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.702, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.672, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.627, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.519911082952933e-09;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.606, test=0.667) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.702, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.672, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.627, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-09;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.606, test=0.667) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.702, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.672, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.627, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.873817422860383e-08;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.606, test=0.667) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.702, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.672, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.627, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.5111917342151273e-09;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.008111308307896872;, score=(train=0.664, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.008111308307896872;, score=(train=0.662, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.008111308307896872;, score=(train=0.693, test=0.845) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.008111308307896872;, score=(train=0.631, test=0.756) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.008111308307896872;, score=(train=0.686, test=0.675) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.008111308307896872;, score=(train=0.711, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.008111308307896872;, score=(train=0.700, test=0.425) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.008111308307896872;, score=(train=0.736, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.008111308307896872;, score=(train=0.682, test=0.866) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.008111308307896872;, score=(train=0.661, test=0.263) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.008111308307896872;, score=(train=0.681, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.008111308307896872;, score=(train=0.689, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.008111308307896872;, score=(train=0.694, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.008111308307896872;, score=(train=0.709, test=0.571) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.008111308307896872;, score=(train=0.706, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.3511191734215127;, score=(train=0.673, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.3511191734215127;, score=(train=0.660, test=0.446) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.3511191734215127;, score=(train=0.695, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.3511191734215127;, score=(train=0.665, test=0.702) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.3511191734215127;, score=(train=0.685, test=0.857) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.3511191734215127;, score=(train=0.740, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.3511191734215127;, score=(train=0.697, test=0.373) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.3511191734215127;, score=(train=0.723, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.3511191734215127;, score=(train=0.679, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.3511191734215127;, score=(train=0.684, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.3511191734215127;, score=(train=0.683, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.3511191734215127;, score=(train=0.677, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.3511191734215127;, score=(train=0.716, test=0.399) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.3511191734215127;, score=(train=0.693, test=0.608) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.3511191734215127;, score=(train=0.703, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.2310129700083158;, score=(train=0.677, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.2310129700083158;, score=(train=0.666, test=0.446) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.2310129700083158;, score=(train=0.695, test=0.684) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.2310129700083158;, score=(train=0.659, test=0.785) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.2310129700083158;, score=(train=0.678, test=0.888) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.2310129700083158;, score=(train=0.739, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.2310129700083158;, score=(train=0.699, test=0.373) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.2310129700083158;, score=(train=0.729, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.2310129700083158;, score=(train=0.678, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.2310129700083158;, score=(train=0.688, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.2310129700083158;, score=(train=0.682, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.2310129700083158;, score=(train=0.675, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.2310129700083158;, score=(train=0.722, test=0.440) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.2310129700083158;, score=(train=0.695, test=0.608) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.2310129700083158;, score=(train=0.711, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.5336699231206302;, score=(train=0.679, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.5336699231206302;, score=(train=0.656, test=0.446) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.5336699231206302;, score=(train=0.697, test=0.640) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.5336699231206302;, score=(train=0.665, test=0.702) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.5336699231206302;, score=(train=0.695, test=0.857) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.5336699231206302;, score=(train=0.740, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.5336699231206302;, score=(train=0.695, test=0.415) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.5336699231206302;, score=(train=0.717, test=0.288) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.5336699231206302;, score=(train=0.680, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.5336699231206302;, score=(train=0.687, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.5336699231206302;, score=(train=0.683, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.5336699231206302;, score=(train=0.676, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.5336699231206302;, score=(train=0.712, test=0.399) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.5336699231206302;, score=(train=0.702, test=0.626) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.5336699231206302;, score=(train=0.705, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0006579332246575682;, score=(train=0.645, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0006579332246575682;, score=(train=0.660, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0006579332246575682;, score=(train=0.682, test=0.871) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0006579332246575682;, score=(train=0.613, test=0.712) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0006579332246575682;, score=(train=0.669, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0006579332246575682;, score=(train=0.684, test=0.650) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0006579332246575682;, score=(train=0.713, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0006579332246575682;, score=(train=0.723, test=0.225) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0006579332246575682;, score=(train=0.682, test=0.784) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0006579332246575682;, score=(train=0.644, test=0.281) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0006579332246575682;, score=(train=0.661, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0006579332246575682;, score=(train=0.656, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0006579332246575682;, score=(train=0.684, test=0.460) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0006579332246575682;, score=(train=0.698, test=0.447) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0006579332246575682;, score=(train=0.680, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1e-05;, score=(train=0.627, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1e-05;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1e-05;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1e-05;, score=(train=0.605, test=0.651) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1e-05;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1e-05;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1e-05;, score=(train=0.704, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1e-05;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1e-05;, score=(train=0.671, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1e-05;, score=(train=0.628, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1e-05;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1e-05;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1e-05;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1e-05;, score=(train=0.688, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1e-05;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.605, test=0.651) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.704, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.716, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.671, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.628, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.639, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.579332246575683e-06;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.627, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.605, test=0.651) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.672, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.706, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.716, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.673, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.630, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.653, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.689, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.5199110829529332e-05;, score=(train=0.664, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.656, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.676, test=0.871) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.604, test=0.651) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.672, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.671, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.708, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.718, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.672, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.630, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.654, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.673, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.688, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.310129700083158e-05;, score=(train=0.664, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.630, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.655, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.677, test=0.871) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.604, test=0.651) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.672, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.672, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.709, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.718, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.673, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.628, test=0.320) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.656, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.641, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.675, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.689, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=3.511191734215135e-05;, score=(train=0.664, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.628, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.657, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.675, test=0.857) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.605, test=0.651) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.670, test=0.694) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.704, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.715, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.671, test=0.756) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.628, test=0.342) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.652, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.640, test=0.987) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.672, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.686, test=0.375) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083061e-06;, score=(train=0.663, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.012328467394420659;, score=(train=0.667, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.012328467394420659;, score=(train=0.666, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.012328467394420659;, score=(train=0.696, test=0.832) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.012328467394420659;, score=(train=0.633, test=0.784) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.012328467394420659;, score=(train=0.684, test=0.726) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.012328467394420659;, score=(train=0.722, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.012328467394420659;, score=(train=0.702, test=0.405) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.012328467394420659;, score=(train=0.738, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.012328467394420659;, score=(train=0.678, test=0.879) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.012328467394420659;, score=(train=0.667, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.012328467394420659;, score=(train=0.678, test=0.774) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.012328467394420659;, score=(train=0.689, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.012328467394420659;, score=(train=0.696, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.012328467394420659;, score=(train=0.705, test=0.571) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.012328467394420659;, score=(train=0.707, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.811130830789689;, score=(train=0.687, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.811130830789689;, score=(train=0.658, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.811130830789689;, score=(train=0.702, test=0.655) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.811130830789689;, score=(train=0.667, test=0.727) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.811130830789689;, score=(train=0.701, test=0.841) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.811130830789689;, score=(train=0.739, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.811130830789689;, score=(train=0.701, test=0.435) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.811130830789689;, score=(train=0.718, test=0.341) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.811130830789689;, score=(train=0.678, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.811130830789689;, score=(train=0.690, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.811130830789689;, score=(train=0.689, test=0.750) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.811130830789689;, score=(train=0.677, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.811130830789689;, score=(train=0.726, test=0.420) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.811130830789689;, score=(train=0.706, test=0.626) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.811130830789689;, score=(train=0.717, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.001;, score=(train=0.647, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.001;, score=(train=0.662, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.001;, score=(train=0.687, test=0.871) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.001;, score=(train=0.617, test=0.727) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.001;, score=(train=0.671, test=0.426) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.001;, score=(train=0.686, test=0.601) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.001;, score=(train=0.708, test=0.405) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.001;, score=(train=0.730, test=0.225) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.001;, score=(train=0.684, test=0.784) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.001;, score=(train=0.645, test=0.281) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.001;, score=(train=0.665, test=0.765) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.001;, score=(train=0.657, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.001;, score=(train=0.683, test=0.460) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.001;, score=(train=0.696, test=0.447) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.001;, score=(train=0.683, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.8738174228603868;, score=(train=0.720, test=0.895) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.8738174228603868;, score=(train=0.675, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.8738174228603868;, score=(train=0.724, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.8738174228603868;, score=(train=0.692, test=0.716) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.8738174228603868;, score=(train=0.744, test=0.516) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.8738174228603868;, score=(train=0.758, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.8738174228603868;, score=(train=0.708, test=0.595) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.8738174228603868;, score=(train=0.739, test=0.391) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.8738174228603868;, score=(train=0.697, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.8738174228603868;, score=(train=0.707, test=0.368) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.8738174228603868;, score=(train=0.716, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.8738174228603868;, score=(train=0.705, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.8738174228603868;, score=(train=0.754, test=0.467) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.8738174228603868;, score=(train=0.724, test=0.774) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.8738174228603868;, score=(train=0.739, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.1519911082952933;, score=(train=0.675, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.1519911082952933;, score=(train=0.673, test=0.446) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.1519911082952933;, score=(train=0.699, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.1519911082952933;, score=(train=0.661, test=0.799) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.1519911082952933;, score=(train=0.677, test=0.888) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.1519911082952933;, score=(train=0.734, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.1519911082952933;, score=(train=0.701, test=0.364) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.1519911082952933;, score=(train=0.730, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.1519911082952933;, score=(train=0.677, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.1519911082952933;, score=(train=0.686, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.1519911082952933;, score=(train=0.685, test=0.774) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.1519911082952933;, score=(train=0.677, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.1519911082952933;, score=(train=0.722, test=0.460) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.1519911082952933;, score=(train=0.697, test=0.608) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.1519911082952933;, score=(train=0.715, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.06579332246575682;, score=(train=0.667, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.06579332246575682;, score=(train=0.672, test=0.468) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.06579332246575682;, score=(train=0.700, test=0.712) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.06579332246575682;, score=(train=0.656, test=0.812) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.06579332246575682;, score=(train=0.675, test=0.862) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.06579332246575682;, score=(train=0.732, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.06579332246575682;, score=(train=0.700, test=0.364) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.06579332246575682;, score=(train=0.729, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.06579332246575682;, score=(train=0.680, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.06579332246575682;, score=(train=0.687, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.06579332246575682;, score=(train=0.685, test=0.774) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.06579332246575682;, score=(train=0.685, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.06579332246575682;, score=(train=0.717, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.06579332246575682;, score=(train=0.707, test=0.590) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.06579332246575682;, score=(train=0.713, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.043287612810830614;, score=(train=0.666, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.043287612810830614;, score=(train=0.667, test=0.489) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.043287612810830614;, score=(train=0.697, test=0.726) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.043287612810830614;, score=(train=0.651, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.043287612810830614;, score=(train=0.675, test=0.813) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.043287612810830614;, score=(train=0.737, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.043287612810830614;, score=(train=0.700, test=0.364) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.043287612810830614;, score=(train=0.735, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.043287612810830614;, score=(train=0.679, test=0.986) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.043287612810830614;, score=(train=0.681, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.043287612810830614;, score=(train=0.684, test=0.774) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.043287612810830614;, score=(train=0.686, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.043287612810830614;, score=(train=0.715, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.043287612810830614;, score=(train=0.705, test=0.590) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.043287612810830614;, score=(train=0.713, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0015199110829529332;, score=(train=0.646, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0015199110829529332;, score=(train=0.663, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0015199110829529332;, score=(train=0.690, test=0.871) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0015199110829529332;, score=(train=0.617, test=0.727) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0015199110829529332;, score=(train=0.673, test=0.459) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0015199110829529332;, score=(train=0.691, test=0.574) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0015199110829529332;, score=(train=0.709, test=0.405) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0015199110829529332;, score=(train=0.730, test=0.225) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0015199110829529332;, score=(train=0.683, test=0.798) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0015199110829529332;, score=(train=0.651, test=0.289) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0015199110829529332;, score=(train=0.667, test=0.751) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0015199110829529332;, score=(train=0.666, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0015199110829529332;, score=(train=0.686, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0015199110829529332;, score=(train=0.697, test=0.447) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0015199110829529332;, score=(train=0.692, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.0023101297000831626;, score=(train=0.644, test=0.896) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.0023101297000831626;, score=(train=0.663, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.0023101297000831626;, score=(train=0.690, test=0.871) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.0023101297000831626;, score=(train=0.620, test=0.742) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.0023101297000831626;, score=(train=0.673, test=0.507) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.0023101297000831626;, score=(train=0.691, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.0023101297000831626;, score=(train=0.705, test=0.425) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.0023101297000831626;, score=(train=0.733, test=0.225) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.0023101297000831626;, score=(train=0.678, test=0.839) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.0023101297000831626;, score=(train=0.653, test=0.263) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.0023101297000831626;, score=(train=0.670, test=0.751) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.0023101297000831626;, score=(train=0.676, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.0023101297000831626;, score=(train=0.684, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.0023101297000831626;, score=(train=0.701, test=0.469) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.0023101297000831626;, score=(train=0.697, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.1;, score=(train=0.672, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.1;, score=(train=0.668, test=0.446) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.1;, score=(train=0.698, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.1;, score=(train=0.655, test=0.799) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.1;, score=(train=0.674, test=0.888) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.1;, score=(train=0.731, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.1;, score=(train=0.701, test=0.364) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.1;, score=(train=0.728, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.1;, score=(train=0.680, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.1;, score=(train=0.684, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.1;, score=(train=0.684, test=0.774) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.1;, score=(train=0.680, test=0.907) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.1;, score=(train=0.719, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.1;, score=(train=0.703, test=0.608) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.1;, score=(train=0.716, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.01873817422860387;, score=(train=0.672, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.01873817422860387;, score=(train=0.666, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.01873817422860387;, score=(train=0.692, test=0.820) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.01873817422860387;, score=(train=0.629, test=0.812) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.01873817422860387;, score=(train=0.683, test=0.763) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.01873817422860387;, score=(train=0.729, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.01873817422860387;, score=(train=0.694, test=0.405) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.01873817422860387;, score=(train=0.732, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.01873817422860387;, score=(train=0.680, test=0.946) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.01873817422860387;, score=(train=0.676, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.01873817422860387;, score=(train=0.674, test=0.774) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.01873817422860387;, score=(train=0.688, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.01873817422860387;, score=(train=0.702, test=0.479) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.01873817422860387;, score=(train=0.710, test=0.571) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.01873817422860387;, score=(train=0.709, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.5793322465756825;, score=(train=0.611, test=0.546) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.5793322465756825;, score=(train=0.757, test=0.468) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.5793322465756825;, score=(train=0.633, test=0.959) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.5793322465756825;, score=(train=0.713, test=0.693) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.5793322465756825;, score=(train=0.672, test=0.516) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.5793322465756825;, score=(train=0.705, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.5793322465756825;, score=(train=0.682, test=0.858) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.5793322465756825;, score=(train=0.721, test=0.820) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.5793322465756825;, score=(train=0.686, test=0.748) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.5793322465756825;, score=(train=0.679, test=0.945) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.5793322465756825;, score=(train=0.648, test=0.516) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.5793322465756825;, score=(train=0.698, test=0.400) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.5793322465756825;, score=(train=0.693, test=0.497) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.5793322465756825;, score=(train=0.716, test=0.510) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.5793322465756825;, score=(train=0.728, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.028480358684358047;, score=(train=0.669, test=0.909) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.028480358684358047;, score=(train=0.668, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.028480358684358047;, score=(train=0.697, test=0.767) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.028480358684358047;, score=(train=0.653, test=0.812) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.028480358684358047;, score=(train=0.681, test=0.801) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.028480358684358047;, score=(train=0.735, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.028480358684358047;, score=(train=0.694, test=0.385) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.028480358684358047;, score=(train=0.736, test=0.231) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.028480358684358047;, score=(train=0.677, test=0.973) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.028480358684358047;, score=(train=0.667, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.028480358684358047;, score=(train=0.681, test=0.774) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.028480358684358047;, score=(train=0.686, test=0.921) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.028480358684358047;, score=(train=0.707, test=0.460) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.028480358684358047;, score=(train=0.703, test=0.590) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.028480358684358047;, score=(train=0.712, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805;, score=(train=0.743, test=0.854) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805;, score=(train=0.702, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805;, score=(train=0.757, test=0.754) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805;, score=(train=0.723, test=0.758) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805;, score=(train=0.768, test=0.516) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805;, score=(train=0.771, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805;, score=(train=0.734, test=0.785) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805;, score=(train=0.743, test=0.614) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805;, score=(train=0.744, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805;, score=(train=0.746, test=0.513) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805;, score=(train=0.748, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805;, score=(train=0.728, test=0.934) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805;, score=(train=0.779, test=0.464) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805;, score=(train=0.745, test=0.804) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805;, score=(train=0.757, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083062;, score=(train=0.715, test=0.834) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083062;, score=(train=0.742, test=0.401) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083062;, score=(train=0.736, test=0.909) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083062;, score=(train=0.740, test=0.850) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083062;, score=(train=0.774, test=0.516) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083062;, score=(train=0.780, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083062;, score=(train=0.736, test=0.824) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083062;, score=(train=0.753, test=0.874) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083062;, score=(train=0.721, test=0.930) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083062;, score=(train=0.760, test=0.784) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083062;, score=(train=0.739, test=0.704) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083062;, score=(train=0.735, test=0.894) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083062;, score=(train=0.794, test=0.433) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083062;, score=(train=0.755, test=0.717) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083062;, score=(train=0.783, test=0.516) total time=   0.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 12\n",
      "n_resources: 3330\n",
      "Fitting 15 folds for each of 12 candidates, totalling 180 fits\n",
      "[CV 1/15] END var_smoothing=0.012328467394420659;, score=(train=0.675, test=0.930) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.012328467394420659;, score=(train=0.687, test=0.419) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.012328467394420659;, score=(train=0.697, test=0.798) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.012328467394420659;, score=(train=0.675, test=0.848) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.012328467394420659;, score=(train=0.695, test=0.692) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.012328467394420659;, score=(train=0.709, test=0.715) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.012328467394420659;, score=(train=0.707, test=0.433) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.012328467394420659;, score=(train=0.726, test=0.199) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.012328467394420659;, score=(train=0.693, test=0.950) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.012328467394420659;, score=(train=0.694, test=0.261) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.012328467394420659;, score=(train=0.685, test=0.771) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.012328467394420659;, score=(train=0.685, test=0.939) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.012328467394420659;, score=(train=0.708, test=0.502) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.012328467394420659;, score=(train=0.706, test=0.535) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.012328467394420659;, score=(train=0.700, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.811130830789689;, score=(train=0.686, test=0.917) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.811130830789689;, score=(train=0.685, test=0.354) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.811130830789689;, score=(train=0.705, test=0.593) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.811130830789689;, score=(train=0.689, test=0.765) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.811130830789689;, score=(train=0.683, test=0.839) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.811130830789689;, score=(train=0.728, test=0.496) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.811130830789689;, score=(train=0.701, test=0.453) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.811130830789689;, score=(train=0.715, test=0.250) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.811130830789689;, score=(train=0.684, test=0.995) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.811130830789689;, score=(train=0.702, test=0.270) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.811130830789689;, score=(train=0.689, test=0.746) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.811130830789689;, score=(train=0.690, test=0.926) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.811130830789689;, score=(train=0.716, test=0.474) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.811130830789689;, score=(train=0.694, test=0.631) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.811130830789689;, score=(train=0.711, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.1519911082952933;, score=(train=0.683, test=0.917) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.1519911082952933;, score=(train=0.689, test=0.379) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.1519911082952933;, score=(train=0.703, test=0.665) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.1519911082952933;, score=(train=0.679, test=0.816) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.1519911082952933;, score=(train=0.686, test=0.890) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.1519911082952933;, score=(train=0.719, test=0.496) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.1519911082952933;, score=(train=0.708, test=0.393) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.1519911082952933;, score=(train=0.725, test=0.191) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.1519911082952933;, score=(train=0.687, test=0.995) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.1519911082952933;, score=(train=0.703, test=0.243) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.1519911082952933;, score=(train=0.691, test=0.763) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.1519911082952933;, score=(train=0.699, test=0.898) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.1519911082952933;, score=(train=0.706, test=0.483) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.1519911082952933;, score=(train=0.701, test=0.602) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.1519911082952933;, score=(train=0.715, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.043287612810830614;, score=(train=0.678, test=0.926) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.043287612810830614;, score=(train=0.688, test=0.379) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.043287612810830614;, score=(train=0.704, test=0.698) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.043287612810830614;, score=(train=0.679, test=0.834) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.043287612810830614;, score=(train=0.690, test=0.793) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.043287612810830614;, score=(train=0.715, test=0.605) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.043287612810830614;, score=(train=0.709, test=0.394) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.043287612810830614;, score=(train=0.731, test=0.189) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.043287612810830614;, score=(train=0.692, test=0.982) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.043287612810830614;, score=(train=0.702, test=0.252) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.043287612810830614;, score=(train=0.693, test=0.775) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.043287612810830614;, score=(train=0.700, test=0.917) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.043287612810830614;, score=(train=0.706, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.043287612810830614;, score=(train=0.708, test=0.554) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.043287612810830614;, score=(train=0.717, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.06579332246575682;, score=(train=0.678, test=0.926) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.06579332246575682;, score=(train=0.688, test=0.379) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.06579332246575682;, score=(train=0.704, test=0.684) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.06579332246575682;, score=(train=0.681, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.06579332246575682;, score=(train=0.687, test=0.835) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.06579332246575682;, score=(train=0.715, test=0.516) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.06579332246575682;, score=(train=0.711, test=0.397) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.06579332246575682;, score=(train=0.727, test=0.191) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.06579332246575682;, score=(train=0.690, test=0.991) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.06579332246575682;, score=(train=0.704, test=0.243) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.06579332246575682;, score=(train=0.694, test=0.775) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.06579332246575682;, score=(train=0.701, test=0.903) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.06579332246575682;, score=(train=0.704, test=0.502) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.06579332246575682;, score=(train=0.705, test=0.578) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.06579332246575682;, score=(train=0.714, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.1;, score=(train=0.680, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.1;, score=(train=0.687, test=0.379) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.1;, score=(train=0.703, test=0.674) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.1;, score=(train=0.681, test=0.825) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.1;, score=(train=0.686, test=0.877) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.1;, score=(train=0.712, test=0.496) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.1;, score=(train=0.710, test=0.390) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.1;, score=(train=0.726, test=0.191) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.1;, score=(train=0.689, test=0.991) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.1;, score=(train=0.705, test=0.243) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.1;, score=(train=0.693, test=0.767) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.1;, score=(train=0.700, test=0.898) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.1;, score=(train=0.703, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.1;, score=(train=0.706, test=0.590) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.1;, score=(train=0.715, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.028480358684358047;, score=(train=0.679, test=0.926) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.028480358684358047;, score=(train=0.686, test=0.403) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.028480358684358047;, score=(train=0.702, test=0.708) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.028480358684358047;, score=(train=0.679, test=0.834) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.028480358684358047;, score=(train=0.691, test=0.764) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.028480358684358047;, score=(train=0.711, test=0.659) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.028480358684358047;, score=(train=0.712, test=0.423) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.028480358684358047;, score=(train=0.728, test=0.199) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.028480358684358047;, score=(train=0.693, test=0.982) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.028480358684358047;, score=(train=0.703, test=0.261) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.028480358684358047;, score=(train=0.688, test=0.775) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.028480358684358047;, score=(train=0.696, test=0.926) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.028480358684358047;, score=(train=0.711, test=0.489) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.028480358684358047;, score=(train=0.705, test=0.554) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.028480358684358047;, score=(train=0.715, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=0.01873817422860387;, score=(train=0.680, test=0.930) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=0.01873817422860387;, score=(train=0.688, test=0.411) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=0.01873817422860387;, score=(train=0.702, test=0.763) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=0.01873817422860387;, score=(train=0.676, test=0.839) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=0.01873817422860387;, score=(train=0.693, test=0.726) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=0.01873817422860387;, score=(train=0.710, test=0.674) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=0.01873817422860387;, score=(train=0.705, test=0.420) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=0.01873817422860387;, score=(train=0.728, test=0.199) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=0.01873817422860387;, score=(train=0.693, test=0.973) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=0.01873817422860387;, score=(train=0.703, test=0.261) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=0.01873817422860387;, score=(train=0.688, test=0.775) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=0.01873817422860387;, score=(train=0.693, test=0.930) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=0.01873817422860387;, score=(train=0.713, test=0.496) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=0.01873817422860387;, score=(train=0.707, test=0.535) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=0.01873817422860387;, score=(train=0.711, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.5793322465756825;, score=(train=0.645, test=0.761) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.5793322465756825;, score=(train=0.744, test=0.499) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.5793322465756825;, score=(train=0.674, test=0.974) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.5793322465756825;, score=(train=0.716, test=0.741) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.5793322465756825;, score=(train=0.691, test=0.496) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.5793322465756825;, score=(train=0.711, test=0.496) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.5793322465756825;, score=(train=0.692, test=0.815) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.5793322465756825;, score=(train=0.713, test=0.841) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.5793322465756825;, score=(train=0.687, test=0.781) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.5793322465756825;, score=(train=0.696, test=0.936) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.5793322465756825;, score=(train=0.685, test=0.670) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.5793322465756825;, score=(train=0.668, test=0.441) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.5793322465756825;, score=(train=0.702, test=0.440) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.5793322465756825;, score=(train=0.711, test=0.521) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.5793322465756825;, score=(train=0.741, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=1.8738174228603868;, score=(train=0.714, test=0.904) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.8738174228603868;, score=(train=0.700, test=0.354) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.8738174228603868;, score=(train=0.724, test=0.679) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.8738174228603868;, score=(train=0.714, test=0.770) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.8738174228603868;, score=(train=0.726, test=0.613) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.8738174228603868;, score=(train=0.754, test=0.496) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.8738174228603868;, score=(train=0.711, test=0.663) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.8738174228603868;, score=(train=0.722, test=0.397) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.8738174228603868;, score=(train=0.712, test=0.982) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.8738174228603868;, score=(train=0.728, test=0.361) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.8738174228603868;, score=(train=0.712, test=0.746) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.8738174228603868;, score=(train=0.721, test=0.903) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.8738174228603868;, score=(train=0.746, test=0.512) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.8738174228603868;, score=(train=0.709, test=0.739) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.8738174228603868;, score=(train=0.730, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805;, score=(train=0.747, test=0.868) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805;, score=(train=0.725, test=0.354) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805;, score=(train=0.750, test=0.745) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805;, score=(train=0.737, test=0.789) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805;, score=(train=0.762, test=0.496) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805;, score=(train=0.767, test=0.496) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805;, score=(train=0.738, test=0.780) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805;, score=(train=0.737, test=0.663) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805;, score=(train=0.738, test=0.963) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805;, score=(train=0.756, test=0.490) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805;, score=(train=0.748, test=0.754) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805;, score=(train=0.744, test=0.889) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805;, score=(train=0.775, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805;, score=(train=0.734, test=0.792) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805;, score=(train=0.753, test=0.496) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083062;, score=(train=0.742, test=0.837) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083062;, score=(train=0.754, test=0.379) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083062;, score=(train=0.760, test=0.850) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083062;, score=(train=0.758, test=0.851) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083062;, score=(train=0.772, test=0.496) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083062;, score=(train=0.769, test=0.496) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083062;, score=(train=0.745, test=0.800) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083062;, score=(train=0.742, test=0.879) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083062;, score=(train=0.733, test=0.895) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083062;, score=(train=0.763, test=0.806) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083062;, score=(train=0.754, test=0.742) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083062;, score=(train=0.727, test=0.724) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083062;, score=(train=0.779, test=0.553) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083062;, score=(train=0.753, test=0.742) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083062;, score=(train=0.772, test=0.496) total time=   0.0s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 4\n",
      "n_resources: 9990\n",
      "Fitting 15 folds for each of 4 candidates, totalling 60 fits\n",
      "[CV 1/15] END var_smoothing=1.8738174228603868;, score=(train=0.714, test=0.898) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=1.8738174228603868;, score=(train=0.715, test=0.309) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=1.8738174228603868;, score=(train=0.716, test=0.705) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=1.8738174228603868;, score=(train=0.714, test=0.793) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=1.8738174228603868;, score=(train=0.720, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=1.8738174228603868;, score=(train=0.749, test=0.462) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=1.8738174228603868;, score=(train=0.712, test=0.679) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=1.8738174228603868;, score=(train=0.729, test=0.450) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=1.8738174228603868;, score=(train=0.709, test=0.969) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=1.8738174228603868;, score=(train=0.724, test=0.469) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=1.8738174228603868;, score=(train=0.711, test=0.762) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=1.8738174228603868;, score=(train=0.728, test=0.898) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=1.8738174228603868;, score=(train=0.740, test=0.592) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=1.8738174228603868;, score=(train=0.721, test=0.781) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=1.8738174228603868;, score=(train=0.726, test=0.462) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=6.5793322465756825;, score=(train=0.654, test=0.724) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=6.5793322465756825;, score=(train=0.743, test=0.460) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=6.5793322465756825;, score=(train=0.665, test=0.950) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=6.5793322465756825;, score=(train=0.700, test=0.582) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=6.5793322465756825;, score=(train=0.694, test=0.462) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=6.5793322465756825;, score=(train=0.707, test=0.462) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=6.5793322465756825;, score=(train=0.681, test=0.831) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=6.5793322465756825;, score=(train=0.685, test=0.744) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=6.5793322465756825;, score=(train=0.671, test=0.740) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=6.5793322465756825;, score=(train=0.671, test=0.949) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=6.5793322465756825;, score=(train=0.685, test=0.642) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=6.5793322465756825;, score=(train=0.641, test=0.451) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=6.5793322465756825;, score=(train=0.693, test=0.441) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=6.5793322465756825;, score=(train=0.687, test=0.465) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=6.5793322465756825;, score=(train=0.733, test=0.462) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805;, score=(train=0.742, test=0.886) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805;, score=(train=0.741, test=0.315) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805;, score=(train=0.748, test=0.747) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805;, score=(train=0.736, test=0.845) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805;, score=(train=0.756, test=0.462) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805;, score=(train=0.768, test=0.462) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805;, score=(train=0.743, test=0.786) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805;, score=(train=0.742, test=0.781) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805;, score=(train=0.737, test=0.938) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805;, score=(train=0.751, test=0.585) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805;, score=(train=0.745, test=0.767) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805;, score=(train=0.745, test=0.893) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805;, score=(train=0.767, test=0.571) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805;, score=(train=0.745, test=0.792) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805;, score=(train=0.748, test=0.462) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=4.328761281083062;, score=(train=0.735, test=0.860) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083062;, score=(train=0.768, test=0.338) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083062;, score=(train=0.746, test=0.847) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083062;, score=(train=0.755, test=0.808) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083062;, score=(train=0.772, test=0.462) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083062;, score=(train=0.760, test=0.462) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083062;, score=(train=0.747, test=0.827) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083062;, score=(train=0.747, test=0.849) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083062;, score=(train=0.726, test=0.866) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083062;, score=(train=0.753, test=0.873) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083062;, score=(train=0.753, test=0.709) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083062;, score=(train=0.731, test=0.518) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083062;, score=(train=0.770, test=0.542) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083062;, score=(train=0.748, test=0.740) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083062;, score=(train=0.774, test=0.462) total time=   0.0s\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 2\n",
      "n_resources: 29970\n",
      "Fitting 15 folds for each of 2 candidates, totalling 30 fits\n",
      "[CV 1/15] END var_smoothing=4.328761281083062;, score=(train=0.730, test=0.873) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=4.328761281083062;, score=(train=0.774, test=0.296) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=4.328761281083062;, score=(train=0.741, test=0.806) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=4.328761281083062;, score=(train=0.750, test=0.793) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=4.328761281083062;, score=(train=0.765, test=0.472) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=4.328761281083062;, score=(train=0.757, test=0.472) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=4.328761281083062;, score=(train=0.743, test=0.845) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=4.328761281083062;, score=(train=0.747, test=0.820) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=4.328761281083062;, score=(train=0.720, test=0.869) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=4.328761281083062;, score=(train=0.749, test=0.872) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=4.328761281083062;, score=(train=0.747, test=0.717) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=4.328761281083062;, score=(train=0.728, test=0.616) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=4.328761281083062;, score=(train=0.769, test=0.573) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=4.328761281083062;, score=(train=0.745, test=0.754) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=4.328761281083062;, score=(train=0.769, test=0.472) total time=   0.0s\n",
      "[CV 1/15] END var_smoothing=2.848035868435805;, score=(train=0.738, test=0.899) total time=   0.0s\n",
      "[CV 2/15] END var_smoothing=2.848035868435805;, score=(train=0.750, test=0.280) total time=   0.0s\n",
      "[CV 3/15] END var_smoothing=2.848035868435805;, score=(train=0.743, test=0.719) total time=   0.0s\n",
      "[CV 4/15] END var_smoothing=2.848035868435805;, score=(train=0.734, test=0.848) total time=   0.0s\n",
      "[CV 5/15] END var_smoothing=2.848035868435805;, score=(train=0.753, test=0.484) total time=   0.0s\n",
      "[CV 6/15] END var_smoothing=2.848035868435805;, score=(train=0.760, test=0.472) total time=   0.0s\n",
      "[CV 7/15] END var_smoothing=2.848035868435805;, score=(train=0.737, test=0.781) total time=   0.0s\n",
      "[CV 8/15] END var_smoothing=2.848035868435805;, score=(train=0.740, test=0.778) total time=   0.0s\n",
      "[CV 9/15] END var_smoothing=2.848035868435805;, score=(train=0.729, test=0.943) total time=   0.0s\n",
      "[CV 10/15] END var_smoothing=2.848035868435805;, score=(train=0.747, test=0.596) total time=   0.0s\n",
      "[CV 11/15] END var_smoothing=2.848035868435805;, score=(train=0.742, test=0.772) total time=   0.0s\n",
      "[CV 12/15] END var_smoothing=2.848035868435805;, score=(train=0.741, test=0.909) total time=   0.0s\n",
      "[CV 13/15] END var_smoothing=2.848035868435805;, score=(train=0.759, test=0.572) total time=   0.0s\n",
      "[CV 14/15] END var_smoothing=2.848035868435805;, score=(train=0.743, test=0.797) total time=   0.0s\n",
      "[CV 15/15] END var_smoothing=2.848035868435805;, score=(train=0.746, test=0.472) total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=GaussianNB(),\n",
       "                    param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e-09, 1.51991108e-09, 2.31012970e-09, 3.51119173e-09,\n",
       "       5.33669923e-09, 8.11130831e-09, 1.23284674e-08, 1.87381742e-08,\n",
       "       2.84803587e-08, 4.32876128e-08, 6.57933225e-08, 1.00000000e-07,\n",
       "       1.51991108e-07, 2.31012970e...\n",
       "       3.51119173e+05, 5.33669923e+05, 8.11130831e+05, 1.23284674e+06,\n",
       "       1.87381742e+06, 2.84803587e+06, 4.32876128e+06, 6.57933225e+06,\n",
       "       1.00000000e+07, 1.51991108e+07, 2.31012970e+07, 3.51119173e+07,\n",
       "       5.33669923e+07, 8.11130831e+07, 1.23284674e+08, 1.87381742e+08,\n",
       "       2.84803587e+08, 4.32876128e+08, 6.57933225e+08, 1.00000000e+09])},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=GaussianNB(),\n",
       "                    param_grid={&#x27;var_smoothing&#x27;: array([1.00000000e-09, 1.51991108e-09, 2.31012970e-09, 3.51119173e-09,\n",
       "       5.33669923e-09, 8.11130831e-09, 1.23284674e-08, 1.87381742e-08,\n",
       "       2.84803587e-08, 4.32876128e-08, 6.57933225e-08, 1.00000000e-07,\n",
       "       1.51991108e-07, 2.31012970e...\n",
       "       3.51119173e+05, 5.33669923e+05, 8.11130831e+05, 1.23284674e+06,\n",
       "       1.87381742e+06, 2.84803587e+06, 4.32876128e+06, 6.57933225e+06,\n",
       "       1.00000000e+07, 1.51991108e+07, 2.31012970e+07, 3.51119173e+07,\n",
       "       5.33669923e+07, 8.11130831e+07, 1.23284674e+08, 1.87381742e+08,\n",
       "       2.84803587e+08, 4.32876128e+08, 6.57933225e+08, 1.00000000e+09])},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=GaussianNB(),\n",
       "                    param_grid={'var_smoothing': array([1.00000000e-09, 1.51991108e-09, 2.31012970e-09, 3.51119173e-09,\n",
       "       5.33669923e-09, 8.11130831e-09, 1.23284674e-08, 1.87381742e-08,\n",
       "       2.84803587e-08, 4.32876128e-08, 6.57933225e-08, 1.00000000e-07,\n",
       "       1.51991108e-07, 2.31012970e...\n",
       "       3.51119173e+05, 5.33669923e+05, 8.11130831e+05, 1.23284674e+06,\n",
       "       1.87381742e+06, 2.84803587e+06, 4.32876128e+06, 6.57933225e+06,\n",
       "       1.00000000e+07, 1.51991108e+07, 2.31012970e+07, 3.51119173e+07,\n",
       "       5.33669923e+07, 8.11130831e+07, 1.23284674e+08, 1.87381742e+08,\n",
       "       2.84803587e+08, 4.32876128e+08, 6.57933225e+08, 1.00000000e+09])},\n",
       "                    random_state=46, scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_gnb = {'var_smoothing': np.logspace(-9, 9, 100)}\n",
    "gnb = GaussianNB()\n",
    "gnb_hyperparams = HalvingGridSearchCV(gnb, parameters_gnb, cv = cv, scoring = 'f1_weighted', random_state=46, verbose=3)\n",
    "gnb_hyperparams.fit(X, y, groups = groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6841d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 2.848035868435805}\n",
      "0.6880488285217028\n"
     ]
    }
   ],
   "source": [
    "print(gnb_hyperparams.best_params_)\n",
    "print(gnb_hyperparams.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d0610cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = gnb_hyperparams.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c5ef22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB(var_smoothing = 2.848035868435805)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4d9c9",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89902138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 5\n",
      "n_required_iterations: 5\n",
      "n_possible_iterations: 5\n",
      "min_resources_: 370\n",
      "max_resources_: 30000\n",
      "aggressive_elimination: False\n",
      "factor: 3\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 81\n",
      "n_resources: 370\n",
      "Fitting 15 folds for each of 81 candidates, totalling 1215 fits\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.961) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.940, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.956, test=0.914) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.690) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.953, test=0.760) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.954, test=0.175) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.931, test=0.874) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.971, test=0.739) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.951, test=0.872) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.957, test=0.786) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.939, test=0.674) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.921) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.806) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.971, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.962, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.940, test=0.459) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.956, test=0.914) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.690) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.953, test=0.760) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.954, test=0.175) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.931, test=0.874) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.968, test=0.739) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.951, test=0.872) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.957, test=0.786) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.939, test=0.674) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.921) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.806) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.968, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.962, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.953, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.937, test=0.459) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.945, test=0.914) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.690) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.942, test=0.724) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.130) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.934, test=0.833) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.739) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.945, test=0.833) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.971, test=0.739) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.950, test=0.833) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.959, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.806) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.960, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.740) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.690) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.724) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.724) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.792) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.825) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.791) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.786) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.706) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.806) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.635) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.377) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.740) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.766) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.760) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.874) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.783) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.739) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.706) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.806) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.635) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.377) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.740) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.580) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.724) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.750) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.875) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.783) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.786) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.822) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.806) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.597) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.864) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.785) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.750) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.833) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.738) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.792) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.786) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.785) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.766) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.824) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.914) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.796) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.666) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.874) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.738) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.792) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.826) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.822) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.806) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.824) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.597) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.808) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.871) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.833) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.833) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.738) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.709) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.786) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.785) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.840) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.637, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.493, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.629, test=0.740) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.699, test=0.831) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.674, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.656, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.751, test=0.652) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.744, test=0.689) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.690, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.613, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.653, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.645, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.716, test=0.613) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.759, test=0.638) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.688, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.616, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.345, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.634, test=0.808) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.620, test=0.450) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.691, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.686, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.618, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.748, test=0.825) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.589, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.460, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.643, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.490, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.693, test=0.640) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.768, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.695, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.245, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.519, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.248, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.677, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.250, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.614, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.704, test=0.670) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.550, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.715, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.682, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.726, test=0.777) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.699, test=0.786) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.738, test=0.871) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.741, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.716, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.775, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.690, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.713, test=0.518) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.732, test=0.920) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.721, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.726, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.758, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.744, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.692, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.617, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.717, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.712, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.729, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.689, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.758, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.680, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.680, test=0.450) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.706, test=0.882) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.664, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.698, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.738, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.726, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.522, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.247, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.648, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.378, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.613, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.599, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.311, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.729, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.268, test=0.450) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.274, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.628, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.255, test=0.619) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.628, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.774, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.606, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.715, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.694, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.734, test=0.777) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.705, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.732, test=0.871) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.744, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.707, test=0.487) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.761, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.693, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.722, test=0.580) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.715, test=0.833) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.718, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.718, test=0.436) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.758, test=0.783) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.746, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.692, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.619, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.712, test=0.619) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.687, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.732, test=0.635) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.746, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.690, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.755, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.678, test=1.000) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.686, test=0.450) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.709, test=0.840) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.671, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.720, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.755, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.735, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.633, test=1.000) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.378, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.570, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.573, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.294, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.730, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.268, test=0.374) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.274, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.617, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.261, test=0.619) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.562, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.772, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.560, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.961) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.940, test=0.459) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.956, test=0.914) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.690) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.953, test=0.760) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.954, test=0.175) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.931, test=0.874) total time=   0.8s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.971, test=0.739) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.951, test=0.872) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.957, test=0.786) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.939, test=0.674) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.921) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.806) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.971, test=0.782) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.962, test=0.550) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.961) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.940, test=0.459) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.956, test=0.914) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.690) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.953, test=0.760) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.954, test=0.175) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.931, test=0.874) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.968, test=0.739) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.951, test=0.872) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.957, test=0.786) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.939, test=0.674) total time=   1.0s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.921) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.806) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.968, test=0.782) total time=   0.4s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.962, test=0.550) total time=   0.4s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.953, test=0.961) total time=   0.4s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.937, test=0.459) total time=   0.4s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.945, test=0.914) total time=   0.4s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.690) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.942, test=0.724) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.130) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.934, test=0.833) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.739) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.945, test=0.833) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.971, test=0.739) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.950, test=0.833) total time=   0.4s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.959, test=0.960) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.806) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.960, test=0.782) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.550) total time=   0.4s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.377) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.740) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.690) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.724) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.724) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.792) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.825) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.791) total time=   0.9s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.786) total time=   0.8s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.706) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.806) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.782) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.635) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.377) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.740) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.766) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.760) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.874) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.783) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.739) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.706) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.806) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.782) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.635) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.377) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.740) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.580) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.724) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.750) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.875) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.783) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.831) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.786) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.822) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.8s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.806) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.922) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.597) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.864) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.690) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.785) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.750) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.833) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.738) total time=   0.5s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.792) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.786) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.785) total time=   0.9s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.920) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.766) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.824) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.550) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.4s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.459) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.914) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.796) total time=   0.9s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.666) total time=   5.1s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.874) total time=   1.2s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.738) total time=   2.0s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.792) total time=   1.5s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.826) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.822) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.806) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.824) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.597) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.808) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.690) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.871) total time=   0.5s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.833) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.833) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.738) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.709) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.786) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.785) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.960) total time=   1.1s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.840) total time=   1.2s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.9s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.9s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.940, test=0.459) total time=   0.2s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.956, test=0.914) total time=   0.3s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.690) total time=   0.3s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.953, test=0.760) total time=   0.2s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.954, test=0.175) total time=   0.2s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.931, test=0.874) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.968, test=0.739) total time=   0.3s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.951, test=0.872) total time=   0.3s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.957, test=0.786) total time=   4.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.939, test=0.674) total time=   0.3s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.921) total time=   0.2s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.806) total time=   0.4s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.965, test=0.782) total time=   0.4s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.962, test=0.550) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.961) total time=   0.3s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.940, test=0.459) total time=   0.3s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.956, test=0.914) total time=   0.8s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.690) total time=   0.4s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.950, test=0.750) total time=   0.2s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.954, test=0.175) total time=   0.2s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.931, test=0.874) total time=   0.2s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.968, test=0.739) total time=   0.2s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.951, test=0.872) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.957, test=0.786) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.939, test=0.674) total time=   0.3s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.921) total time=   0.2s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.806) total time=   0.2s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.960, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.962, test=0.550) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.953, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.937, test=0.459) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.945, test=0.914) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.690) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.942, test=0.724) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.130) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.937, test=0.833) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.739) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.945, test=0.833) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.971, test=0.739) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.950, test=0.833) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.959, test=0.960) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.806) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.960, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.377) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.740) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.690) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.766) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.833) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.792) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.783) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.791) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.739) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.706) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.806) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.635) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.740) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.766) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.724) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.833) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.783) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.791) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.786) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.767) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.806) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.635) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.377) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.740) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.518) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.724) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.785) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.917) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.783) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.872) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.786) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.822) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.806) total time=   0.2s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.2s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.658) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.914) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.690) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.785) total time=   0.2s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.803) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.833) total time=   0.3s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.783) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.833) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.872) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.733) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.844) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.824) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.532) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.914) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.637) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.785) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.796) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.792) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.738) total time=   0.3s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.872) total time=   0.3s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.872) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.822) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.768) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.824) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.864) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.580) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.871) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.785) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.792) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.825) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.709) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.786) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.822) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.920) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.882) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.286, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.512, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.306, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.715, test=0.867) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.286, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.666, test=0.666) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.747, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.544, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.251, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.254, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.728, test=0.913) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.250, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.667, test=0.608) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.763, test=0.826) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.512, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.682, test=0.309) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.778, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.689, test=0.878) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.519, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.720, test=0.814) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.653, test=0.450) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.722, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.729, test=0.635) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.671, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.752, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.643, test=0.958) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.605, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.710, test=0.644) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.610, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.722, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.736, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.728, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.678, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.431, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.717, test=0.814) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.626, test=0.450) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.746, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.698, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.622, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.752, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.585, test=0.917) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.507, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.726, test=0.706) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.562, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.736, test=0.375) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.741, test=0.868) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.739, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.705, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.725, test=0.316) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.710, test=0.878) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.543, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.691, test=0.777) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.684, test=0.518) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.754, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.756, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.657, test=0.450) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.758, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.638, test=0.831) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.650, test=0.374) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.681, test=0.644) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.618, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.739, test=0.160) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.755, test=0.825) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.760, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.698, test=0.635) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.460, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.673, test=0.814) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.640, test=0.450) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.764, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.762, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.578, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.744, test=0.514) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.563, test=0.739) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.519, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.720, test=0.674) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.582, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.738, test=0.101) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.766, test=0.783) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.757, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.705, test=0.290) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.690, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.961) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.940, test=0.459) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.956, test=0.914) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.690) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.953, test=0.760) total time=   0.7s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.954, test=0.175) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.931, test=0.874) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.968, test=0.739) total time=   0.8s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.951, test=0.872) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.957, test=0.786) total time=   0.8s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.939, test=0.674) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.921) total time=   0.7s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.806) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.965, test=0.782) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.962, test=0.550) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.961) total time=   0.8s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.940, test=0.459) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.956, test=0.914) total time=   1.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.690) total time=   1.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.950, test=0.750) total time=   0.8s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.954, test=0.175) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.931, test=0.874) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.968, test=0.739) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.951, test=0.872) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.957, test=0.786) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.939, test=0.674) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.921) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.806) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.960, test=0.782) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.962, test=0.550) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.953, test=0.961) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.937, test=0.459) total time=   0.8s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.945, test=0.914) total time=   0.8s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.690) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.942, test=0.724) total time=   0.9s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.130) total time=   1.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.937, test=0.833) total time=   0.9s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.739) total time=   0.9s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.945, test=0.833) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.971, test=0.739) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.950, test=0.833) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.959, test=0.960) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.806) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.960, test=0.782) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.962, test=0.550) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.377) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.740) total time=   0.8s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.690) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.766) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.833) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.792) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.783) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.791) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.739) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.706) total time=   0.8s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.806) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.782) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.635) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.7s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.377) total time=   0.9s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.740) total time=   0.9s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.766) total time=   0.7s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.724) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.833) total time=   0.8s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.783) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.791) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.786) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.767) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=1.000) total time=   0.7s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.806) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.782) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.635) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.7s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.377) total time=   0.9s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.740) total time=   0.8s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.518) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.724) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.785) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.917) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.783) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.872) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.786) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.822) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=1.000) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.806) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.658) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.914) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.690) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.785) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.803) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.833) total time=   0.5s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.783) total time=   0.8s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.833) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.872) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.733) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.960) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.844) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.824) total time=   0.7s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.550) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.5s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.532) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.914) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.637) total time=   0.5s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.785) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.796) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.792) total time=   0.9s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.738) total time=   0.8s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.872) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.872) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.822) total time=   0.9s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.9s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.768) total time=   0.8s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.824) total time=   0.8s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.5s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.4s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.459) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.864) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.580) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.871) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.785) total time=   0.5s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.792) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.825) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.709) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.786) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.822) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.920) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.882) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.6s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.971, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.936, test=0.532) total time=   0.1s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.936, test=0.914) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.960, test=0.450) total time=   0.1s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.977, test=0.750) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.954, test=0.175) total time=   0.1s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.939, test=0.874) total time=   0.1s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.965, test=0.739) total time=   0.2s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.951, test=0.875) total time=   0.1s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.974, test=0.786) total time=   0.2s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.833) total time=   0.1s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.965, test=0.921) total time=   0.1s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.956, test=0.766) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.960, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.001;, score=(train=0.965, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.971, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.936, test=0.532) total time=   0.1s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.936, test=0.914) total time=   0.1s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.960, test=0.450) total time=   0.1s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.974, test=0.785) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.954, test=0.175) total time=   0.1s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.939, test=0.874) total time=   0.1s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.965, test=0.739) total time=   0.2s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.951, test=0.875) total time=   0.1s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.974, test=0.786) total time=   0.2s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.833) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.965, test=0.921) total time=   0.1s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.956, test=0.766) total time=   0.1s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.957, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=0.03162277660168379;, score=(train=0.965, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.965, test=0.961) total time=   0.2s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.940, test=0.532) total time=   0.1s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.942, test=0.914) total time=   0.1s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.288) total time=   0.1s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.760) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.971, test=0.153) total time=   0.3s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.951, test=0.917) total time=   0.1s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.953, test=0.739) total time=   0.1s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.942, test=0.833) total time=   0.1s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.786) total time=   0.1s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.956, test=0.833) total time=   0.1s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.957, test=0.960) total time=   0.1s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.939, test=0.806) total time=   0.1s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.968, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.001, lambda=1.0;, score=(train=0.965, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.459) total time=   0.1s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.740) total time=   0.1s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.518) total time=   0.1s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.724) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.785) total time=   0.1s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.875) total time=   0.1s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.783) total time=   0.2s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.833) total time=   0.1s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.786) total time=   0.1s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.991, test=0.822) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.960) total time=   0.1s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.729) total time=   0.1s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.377) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.740) total time=   0.1s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.518) total time=   0.1s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.724) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.785) total time=   0.1s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.875) total time=   0.1s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.783) total time=   0.1s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.874) total time=   0.1s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.786) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.822) total time=   0.1s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.1s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.729) total time=   0.1s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.961) total time=   0.1s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.459) total time=   0.2s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.740) total time=   0.1s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.580) total time=   0.1s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.724) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.785) total time=   0.1s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.917) total time=   0.1s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.825) total time=   0.1s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.917) total time=   0.1s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.872) total time=   0.1s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.822) total time=   0.1s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.960) total time=   0.1s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.729) total time=   0.1s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.782) total time=   0.1s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.635) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.864) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.840) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.645) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.874) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.780) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.792) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.786) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.833) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.729) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.550) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.828) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.840) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.750) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.875) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.738) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.833) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.833) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.729) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.459) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.808) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.690) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.803) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.840) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.825) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.709) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.833) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.822) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.960) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.806) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.001, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=0.03162277660168379, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.001;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=0.03162277660168379;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.503, test=0.550) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.241, test=0.284) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.495, test=0.656) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.220, test=0.288) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.223, test=0.288) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.205, test=0.309) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.226, test=0.288) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.224, test=0.229) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.487, test=0.358) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gblinear, eta=1.0, lambda=1.0;, score=(train=0.499, test=0.550) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.971, test=0.961) total time=   0.7s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.936, test=0.532) total time=   0.6s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.936, test=0.914) total time=   0.6s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.960, test=0.450) total time=   0.6s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.977, test=0.750) total time=   0.7s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.954, test=0.175) total time=   0.6s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.939, test=0.874) total time=   0.7s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.965, test=0.739) total time=   0.6s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.951, test=0.875) total time=   0.6s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.974, test=0.786) total time=   0.6s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.959, test=0.833) total time=   0.6s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.965, test=0.921) total time=   0.6s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.956, test=0.766) total time=   0.6s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.960, test=0.782) total time=   0.5s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.001;, score=(train=0.965, test=0.550) total time=   0.7s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.971, test=0.961) total time=   0.6s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.936, test=0.532) total time=   0.5s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.936, test=0.914) total time=   0.6s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.960, test=0.450) total time=   0.6s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.974, test=0.785) total time=   0.6s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.954, test=0.175) total time=   0.7s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.939, test=0.874) total time=   0.6s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.965, test=0.739) total time=   0.7s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.951, test=0.875) total time=   0.6s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.974, test=0.786) total time=   1.7s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.959, test=0.833) total time=   1.0s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.965, test=0.921) total time=   1.7s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.956, test=0.766) total time=   1.3s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.957, test=0.782) total time=   1.0s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.001, lambda=0.03162277660168379;, score=(train=0.965, test=0.550) total time=   0.8s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.965, test=0.961) total time=   0.6s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.940, test=0.532) total time=   0.6s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.942, test=0.914) total time=   0.6s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.288) total time=   0.6s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.760) total time=   0.6s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.971, test=0.153) total time=   0.7s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.951, test=0.917) total time=   0.6s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.953, test=0.739) total time=   0.6s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.942, test=0.833) total time=   0.6s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.954, test=0.786) total time=   0.6s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.956, test=0.833) total time=   0.6s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.957, test=0.960) total time=   0.6s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.939, test=0.806) total time=   0.6s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.968, test=0.782) total time=   0.6s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.001, lambda=1.0;, score=(train=0.965, test=0.550) total time=   0.5s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.961) total time=   0.5s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.459) total time=   0.5s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.740) total time=   0.6s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.518) total time=   0.7s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.724) total time=   0.7s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.785) total time=   0.6s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.875) total time=   0.6s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.783) total time=   0.6s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.833) total time=   0.7s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.786) total time=   0.6s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.991, test=0.822) total time=   0.8s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.960) total time=   0.8s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.729) total time=   1.1s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.782) total time=   1.1s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.001;, score=(train=1.000, test=0.550) total time=   0.8s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.961) total time=   0.9s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.377) total time=   0.8s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.740) total time=   0.8s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.518) total time=   0.9s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.724) total time=   1.2s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.785) total time=   1.3s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.875) total time=   0.8s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.783) total time=   0.8s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.874) total time=   0.9s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.786) total time=   0.8s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.822) total time=   0.8s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=1.000) total time=   0.9s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.729) total time=   1.0s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.782) total time=   0.8s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.6s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.961) total time=   0.8s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.459) total time=   0.6s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.740) total time=   0.7s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.580) total time=   0.9s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.724) total time=   1.0s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=1.000, test=0.785) total time=   0.7s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.917) total time=   1.0s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.825) total time=   0.8s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.917) total time=   1.0s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.872) total time=   1.1s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.822) total time=   1.0s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.960) total time=   1.2s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.729) total time=   1.1s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.997, test=0.782) total time=   1.2s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.635) total time=   1.4s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.922) total time=   0.9s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.459) total time=   1.1s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.864) total time=   0.7s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.690) total time=   1.8s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.840) total time=   1.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.645) total time=   0.7s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.874) total time=   0.7s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.780) total time=   0.6s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.792) total time=   0.7s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.786) total time=   0.8s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.833) total time=   1.0s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.960) total time=   1.1s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.729) total time=   0.7s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.782) total time=   0.4s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.550) total time=   0.4s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.961) total time=   0.4s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.459) total time=   0.4s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.828) total time=   0.5s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   0.6s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.840) total time=   0.4s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.750) total time=   0.5s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.875) total time=   0.5s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.738) total time=   0.6s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.833) total time=   0.5s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.831) total time=   0.6s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.833) total time=   0.6s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.960) total time=   0.6s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.729) total time=   0.6s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.782) total time=   0.4s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.5s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.961) total time=   0.5s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.459) total time=   0.5s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.808) total time=   0.4s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.690) total time=   0.6s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.803) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.840) total time=   0.4s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.917) total time=   0.5s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.825) total time=   0.5s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.709) total time=   0.5s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.833) total time=   0.5s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.822) total time=   0.6s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.960) total time=   0.5s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.806) total time=   0.5s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.782) total time=   0.4s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.4s\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 27\n",
      "n_resources: 1110\n",
      "Fitting 15 folds for each of 27 candidates, totalling 405 fits\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.947) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.995, test=0.510) total time=   0.2s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.995, test=0.889) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.988, test=0.619) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.697) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.995, test=0.213) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.992, test=0.744) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.990, test=0.744) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.994, test=0.651) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.993, test=0.728) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.993, test=0.877) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.991, test=0.948) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.997, test=0.697) total time=   0.2s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.998, test=0.733) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.001;, score=(train=0.995, test=0.574) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.992, test=0.947) total time=   0.7s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.510) total time=   0.8s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.889) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.986, test=0.619) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.992, test=0.735) total time=   0.7s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.993, test=0.388) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.730) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.729) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.990, test=0.705) total time=   0.8s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.986, test=0.770) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.987, test=0.847) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.990, test=0.935) total time=   0.7s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.993, test=0.648) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.998, test=0.746) total time=   0.7s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.574) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.992, test=0.947) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.510) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.889) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.986, test=0.619) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.992, test=0.735) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.993, test=0.388) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.730) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.991, test=0.729) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.990, test=0.705) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.986, test=0.770) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.987, test=0.847) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.990, test=0.935) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.993, test=0.648) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.998, test=0.746) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.994, test=0.574) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.947) total time=   0.7s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.468) total time=   0.8s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.995, test=0.902) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.989, test=0.550) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.995, test=0.697) total time=   0.7s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.993, test=0.230) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.731) total time=   0.9s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.759) total time=   1.5s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.650) total time=   1.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.741) total time=   1.5s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.877) total time=   1.5s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.989, test=0.935) total time=   1.6s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.672) total time=   1.2s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.733) total time=   1.9s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.574) total time=   1.3s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.947) total time=   0.3s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.468) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.995, test=0.902) total time=   0.4s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.989, test=0.550) total time=   0.3s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.995, test=0.697) total time=   0.3s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.993, test=0.230) total time=   0.3s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.731) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.759) total time=   0.3s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.650) total time=   0.3s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.991, test=0.741) total time=   0.2s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.877) total time=   0.3s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.989, test=0.935) total time=   0.4s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.672) total time=   0.4s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.733) total time=   0.3s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.574) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.998, test=0.947) total time=   0.3s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.489) total time=   0.2s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.995, test=0.889) total time=   0.3s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.987, test=0.619) total time=   0.3s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.995, test=0.697) total time=   0.4s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.993, test=0.213) total time=   0.3s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.992, test=0.785) total time=   0.4s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.993, test=0.729) total time=   0.4s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.998, test=0.678) total time=   0.5s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.992, test=0.728) total time=   0.5s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.992, test=0.877) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.935) total time=   0.3s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.672) total time=   0.4s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.999, test=0.733) total time=   0.2s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.574) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.998, test=0.947) total time=   0.9s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.489) total time=   0.9s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.995, test=0.889) total time=   1.0s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.987, test=0.619) total time=   1.4s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.995, test=0.697) total time=   0.8s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.993, test=0.213) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.992, test=0.785) total time=   1.0s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.993, test=0.729) total time=   1.3s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.998, test=0.678) total time=   1.2s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.992, test=0.728) total time=   1.2s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.992, test=0.877) total time=   1.4s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.994, test=0.935) total time=   1.5s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.997, test=0.672) total time=   1.2s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.999, test=0.733) total time=   0.9s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=0.03162277660168379, lambda=0.03162277660168379;, score=(train=0.996, test=0.574) total time=   1.4s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.947) total time=   0.8s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.568) total time=   0.7s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.918) total time=   0.7s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.532) total time=   0.7s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.735) total time=   0.7s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.505) total time=   0.7s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.852) total time=   0.6s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.716) total time=   0.6s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.731) total time=   0.6s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.810) total time=   0.6s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.862) total time=   0.6s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.935) total time=   0.6s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.622) total time=   0.8s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.760) total time=   0.7s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.503) total time=   0.6s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.568) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.532) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.735) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.505) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.852) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.716) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.731) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.810) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.862) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.935) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.622) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.760) total time=   0.0s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.503) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.568) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.871) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.690) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.668) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.892) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.731) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.606) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.850) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.847) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.665) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.761) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.558) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.922) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.568) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.871) total time=   0.9s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.690) total time=   0.8s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.668) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.892) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.731) total time=   0.8s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.606) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.850) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.847) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.948) total time=   0.7s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.665) total time=   0.7s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.761) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.558) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.934) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.622) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.889) total time=   0.8s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.651) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.735) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.649) total time=   0.7s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.892) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.746) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.825) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.797) total time=   1.0s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.862) total time=   1.0s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   1.1s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.685) total time=   1.1s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.734) total time=   0.9s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.516) total time=   0.9s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.934) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.622) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.889) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.651) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.649) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.892) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.746) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.825) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.797) total time=   0.2s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.862) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.685) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.734) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.516) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.934) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.568) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.918) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.735) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.588) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.865) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.731) total time=   0.0s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.665) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.836) total time=   0.0s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.877) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.660) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.748) total time=   0.1s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.546) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.934) total time=   0.9s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.568) total time=   0.9s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.918) total time=   0.9s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.5s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.735) total time=   0.5s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.588) total time=   0.6s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.865) total time=   0.6s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.731) total time=   0.6s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.665) total time=   0.6s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.836) total time=   0.6s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.877) total time=   0.5s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.948) total time=   0.6s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.660) total time=   0.6s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.748) total time=   0.5s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.546) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.934) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.605) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.932) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.619) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.650) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.602) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.864) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.746) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.798) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.782) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.862) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.974) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.745) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.718) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.601) total time=   0.0s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.934) total time=   0.7s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.605) total time=   0.7s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.932) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.619) total time=   0.7s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.650) total time=   0.7s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.602) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.864) total time=   0.9s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.746) total time=   0.8s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.798) total time=   0.8s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.782) total time=   1.0s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.862) total time=   0.8s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.974) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.745) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.718) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.601) total time=   0.6s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.986, test=0.947) total time=   0.2s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.510) total time=   0.2s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.903) total time=   0.2s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.986, test=0.585) total time=   0.2s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.989, test=0.735) total time=   0.1s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.990, test=0.486) total time=   0.1s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.987, test=0.675) total time=   0.1s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.729) total time=   0.2s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.987, test=0.705) total time=   0.1s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.982, test=0.757) total time=   0.1s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.985, test=0.819) total time=   0.1s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.985, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.685) total time=   0.2s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.992, test=0.732) total time=   0.1s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=0.03162277660168379, lambda=1.0;, score=(train=0.989, test=0.574) total time=   0.1s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.986, test=0.947) total time=   0.8s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.510) total time=   0.8s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.903) total time=   0.8s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.986, test=0.585) total time=   0.8s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.989, test=0.735) total time=   0.7s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.990, test=0.486) total time=   0.7s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.987, test=0.675) total time=   0.8s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.729) total time=   0.8s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.987, test=0.705) total time=   0.8s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.982, test=0.757) total time=   0.7s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.985, test=0.819) total time=   0.8s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.985, test=0.961) total time=   1.1s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.988, test=0.685) total time=   1.0s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.992, test=0.732) total time=   0.9s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=0.03162277660168379, lambda=1.0;, score=(train=0.989, test=0.574) total time=   0.8s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.922) total time=   0.8s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.605) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.890) total time=   0.8s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.712) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.663) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.892) total time=   0.6s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.731) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.705) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.837) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.847) total time=   0.8s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.948) total time=   0.8s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.653) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.775) total time=   0.7s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.539) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.605) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.890) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.550) total time=   0.0s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.712) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.663) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.892) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.731) total time=   0.0s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.705) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.837) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.847) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.948) total time=   0.0s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.653) total time=   0.0s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.775) total time=   0.0s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.539) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.922) total time=   0.0s\n",
      "[CV 2/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.510) total time=   0.0s\n",
      "[CV 3/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.903) total time=   0.0s\n",
      "[CV 4/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.585) total time=   0.0s\n",
      "[CV 5/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.754) total time=   0.0s\n",
      "[CV 6/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.641) total time=   0.0s\n",
      "[CV 7/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.891) total time=   0.0s\n",
      "[CV 8/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.716) total time=   0.1s\n",
      "[CV 9/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.597) total time=   0.0s\n",
      "[CV 10/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.851) total time=   0.1s\n",
      "[CV 11/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.877) total time=   0.0s\n",
      "[CV 12/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.935) total time=   0.0s\n",
      "[CV 13/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.745) total time=   0.0s\n",
      "[CV 14/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.677) total time=   0.1s\n",
      "[CV 15/15] END alpha=1.0, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.503) total time=   0.0s\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.922) total time=   0.7s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.510) total time=   0.8s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.903) total time=   0.9s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.585) total time=   0.6s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.754) total time=   0.7s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.641) total time=   0.7s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.891) total time=   0.6s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.716) total time=   0.7s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.597) total time=   0.7s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.851) total time=   0.7s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.877) total time=   0.7s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.935) total time=   0.7s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.745) total time=   0.7s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.677) total time=   0.7s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.503) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.934) total time=   1.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.587) total time=   1.6s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.890) total time=   0.7s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.650) total time=   0.7s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.579) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.904) total time=   0.8s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.716) total time=   0.7s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.812) total time=   0.9s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.779) total time=   0.9s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.847) total time=   1.5s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.935) total time=   1.3s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.699) total time=   1.2s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   1.2s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.546) total time=   1.4s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.934) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.587) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.890) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.550) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.650) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.579) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.904) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.716) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.812) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.779) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.847) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.935) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.699) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.690) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.546) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.947) total time=   1.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.587) total time=   1.2s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   1.4s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.585) total time=   1.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.626) total time=   0.8s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.649) total time=   0.8s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.865) total time=   0.9s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.746) total time=   0.9s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.718) total time=   0.8s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.766) total time=   0.8s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.877) total time=   0.7s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.8s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.677) total time=   0.8s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.733) total time=   0.7s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.601) total time=   0.7s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.947) total time=   0.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.587) total time=   0.0s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.917) total time=   0.0s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.585) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.626) total time=   0.0s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.649) total time=   0.0s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.865) total time=   0.0s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.746) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.718) total time=   0.0s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.766) total time=   0.0s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.877) total time=   0.0s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.961) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.677) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.733) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.601) total time=   0.0s\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 9\n",
      "n_resources: 3330\n",
      "Fitting 15 folds for each of 9 candidates, totalling 135 fits\n",
      "[CV 1/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.948) total time=   1.2s\n",
      "[CV 2/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.485) total time=   2.3s\n",
      "[CV 3/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.895) total time=   1.9s\n",
      "[CV 4/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.616) total time=   1.6s\n",
      "[CV 5/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.715) total time=   2.8s\n",
      "[CV 6/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.444) total time=   1.5s\n",
      "[CV 7/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.865) total time=   2.3s\n",
      "[CV 8/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.727) total time=   1.6s\n",
      "[CV 9/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.460) total time=   1.1s\n",
      "[CV 10/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.767) total time=   1.4s\n",
      "[CV 11/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.826) total time=   1.2s\n",
      "[CV 12/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.965) total time=   2.3s\n",
      "[CV 13/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.642) total time=   1.8s\n",
      "[CV 14/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.787) total time=   1.7s\n",
      "[CV 15/15] END alpha=1.0, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.544) total time=   1.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.935) total time=   2.0s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.457) total time=   1.8s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.893) total time=   1.5s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.644) total time=   1.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.688) total time=   1.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.543) total time=   1.6s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.888) total time=   1.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.788) total time=   1.1s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.448) total time=   1.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.788) total time=   1.1s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.876) total time=   1.2s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.944) total time=   1.0s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.693) total time=   1.0s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.815) total time=   1.0s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.526) total time=   1.1s\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.935) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.457) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.893) total time=   0.2s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.644) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.688) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.543) total time=   0.2s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.888) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.788) total time=   0.2s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.448) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.788) total time=   0.2s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.876) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.944) total time=   0.2s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.693) total time=   0.2s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.815) total time=   0.2s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.526) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.948) total time=   1.0s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.492) total time=   1.1s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.900) total time=   1.1s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.599) total time=   1.0s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.708) total time=   1.1s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.518) total time=   1.1s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.905) total time=   1.1s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.721) total time=   1.1s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.478) total time=   1.1s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.816) total time=   1.1s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.880) total time=   1.1s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.978) total time=   1.0s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.673) total time=   1.1s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.791) total time=   1.0s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.526) total time=   1.1s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.948) total time=   0.2s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.492) total time=   0.2s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.900) total time=   0.2s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.599) total time=   0.2s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.708) total time=   0.2s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.518) total time=   0.2s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.905) total time=   0.2s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.721) total time=   0.2s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.478) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.816) total time=   0.2s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.880) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.978) total time=   0.2s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.673) total time=   0.2s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.791) total time=   0.2s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.526) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.926) total time=   0.1s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.471) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.906) total time=   0.1s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.638) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.728) total time=   0.2s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.511) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.860) total time=   0.1s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.760) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.450) total time=   0.2s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.786) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.842) total time=   0.2s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.948) total time=   0.1s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.677) total time=   0.3s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.750) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.535) total time=   0.2s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.926) total time=   1.2s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.471) total time=   0.9s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.906) total time=   1.0s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.638) total time=   1.0s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.728) total time=   1.0s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.511) total time=   1.0s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.860) total time=   1.1s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.760) total time=   1.0s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.450) total time=   1.1s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.786) total time=   1.1s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.842) total time=   1.0s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.948) total time=   1.0s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.677) total time=   1.0s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.750) total time=   1.0s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.03162277660168379;, score=(train=1.000, test=0.535) total time=   1.0s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.922) total time=   0.3s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.464) total time=   0.1s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.896) total time=   0.2s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.616) total time=   0.1s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.674) total time=   0.1s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.583) total time=   0.1s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.861) total time=   0.2s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.764) total time=   0.1s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.466) total time=   0.1s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.820) total time=   0.1s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.901) total time=   0.1s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.944) total time=   0.2s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.648) total time=   0.1s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.784) total time=   0.1s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.535) total time=   0.1s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.922) total time=   0.9s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.464) total time=   1.0s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.896) total time=   1.0s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.616) total time=   1.0s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.674) total time=   1.0s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.583) total time=   1.0s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.861) total time=   1.0s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.764) total time=   1.0s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.466) total time=   1.0s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.820) total time=   1.0s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.901) total time=   1.0s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.944) total time=   1.4s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.648) total time=   1.0s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.784) total time=   1.1s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.535) total time=   1.0s\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 3\n",
      "n_resources: 9990\n",
      "Fitting 15 folds for each of 3 candidates, totalling 45 fits\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.936) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.462) total time=   0.5s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.813) total time=   0.5s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.640) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.647) total time=   0.6s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.496) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.899) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.729) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.517) total time=   0.6s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.792) total time=   0.6s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.882) total time=   0.5s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.960) total time=   0.5s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.704) total time=   0.5s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.837) total time=   0.5s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.472) total time=   0.6s\n",
      "[CV 1/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.929) total time=   2.4s\n",
      "[CV 2/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.484) total time=   2.5s\n",
      "[CV 3/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.832) total time=   2.4s\n",
      "[CV 4/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.567) total time=   2.2s\n",
      "[CV 5/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.701) total time=   2.3s\n",
      "[CV 6/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.488) total time=   2.2s\n",
      "[CV 7/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.884) total time=   2.3s\n",
      "[CV 8/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.770) total time=   2.3s\n",
      "[CV 9/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.478) total time=   2.1s\n",
      "[CV 10/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.797) total time=   2.3s\n",
      "[CV 11/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.880) total time=   2.2s\n",
      "[CV 12/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.970) total time=   2.4s\n",
      "[CV 13/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.697) total time=   2.2s\n",
      "[CV 14/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.847) total time=   2.8s\n",
      "[CV 15/15] END alpha=0.001, booster=dart, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.462) total time=   2.6s\n",
      "[CV 1/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.929) total time=   0.6s\n",
      "[CV 2/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.484) total time=   0.6s\n",
      "[CV 3/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.832) total time=   0.6s\n",
      "[CV 4/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.567) total time=   0.6s\n",
      "[CV 5/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.701) total time=   0.7s\n",
      "[CV 6/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.488) total time=   0.6s\n",
      "[CV 7/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.884) total time=   0.7s\n",
      "[CV 8/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.770) total time=   0.6s\n",
      "[CV 9/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.478) total time=   0.7s\n",
      "[CV 10/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.797) total time=   0.7s\n",
      "[CV 11/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.880) total time=   0.6s\n",
      "[CV 12/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.970) total time=   0.6s\n",
      "[CV 13/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.697) total time=   0.6s\n",
      "[CV 14/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.847) total time=   0.6s\n",
      "[CV 15/15] END alpha=0.001, booster=gbtree, eta=1.0, lambda=1.0;, score=(train=1.000, test=0.462) total time=   0.6s\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 1\n",
      "n_resources: 29970\n",
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n",
      "[CV 1/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.923) total time=   1.8s\n",
      "[CV 2/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.449) total time=   1.6s\n",
      "[CV 3/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.846) total time=   1.8s\n",
      "[CV 4/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.611) total time=   1.6s\n",
      "[CV 5/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.685) total time=   1.8s\n",
      "[CV 6/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.506) total time=   1.6s\n",
      "[CV 7/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.884) total time=   1.8s\n",
      "[CV 8/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.716) total time=   1.8s\n",
      "[CV 9/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.435) total time=   1.6s\n",
      "[CV 10/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.803) total time=   1.7s\n",
      "[CV 11/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.902) total time=   1.8s\n",
      "[CV 12/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.959) total time=   1.9s\n",
      "[CV 13/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.667) total time=   1.8s\n",
      "[CV 14/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.891) total time=   1.9s\n",
      "[CV 15/15] END alpha=0.03162277660168379, booster=gbtree, eta=1.0, lambda=0.001;, score=(train=1.000, test=0.486) total time=   1.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            i...\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...),\n",
       "                    param_grid={&#x27;alpha&#x27;: array([0.001     , 0.03162278, 1.        ]),\n",
       "                                &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;, &#x27;dart&#x27;],\n",
       "                                &#x27;eta&#x27;: array([0.001     , 0.03162278, 1.        ]),\n",
       "                                &#x27;lambda&#x27;: array([0.001     , 0.03162278, 1.        ])},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HalvingGridSearchCV</label><div class=\"sk-toggleable__content\"><pre>HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            i...\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...),\n",
       "                    param_grid={&#x27;alpha&#x27;: array([0.001     , 0.03162278, 1.        ]),\n",
       "                                &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;, &#x27;dart&#x27;],\n",
       "                                &#x27;eta&#x27;: array([0.001     , 0.03162278, 1.        ]),\n",
       "                                &#x27;lambda&#x27;: array([0.001     , 0.03162278, 1.        ])},\n",
       "                    random_state=46, scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "HalvingGridSearchCV(cv=StratifiedGroupKFold(n_splits=15, random_state=46, shuffle=True),\n",
       "                    estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            callbacks=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            early_stopping_rounds=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric=None,\n",
       "                                            feature_types=None, gamma=None,\n",
       "                                            gpu_id=None, grow_policy=None,\n",
       "                                            i...\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None, ...),\n",
       "                    param_grid={'alpha': array([0.001     , 0.03162278, 1.        ]),\n",
       "                                'booster': ['gbtree', 'gblinear', 'dart'],\n",
       "                                'eta': array([0.001     , 0.03162278, 1.        ]),\n",
       "                                'lambda': array([0.001     , 0.03162278, 1.        ])},\n",
       "                    random_state=46, scoring='f1_weighted', verbose=3)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_xgb = {'booster': ['gbtree', 'gblinear', 'dart'], \n",
    "                  'lambda': np.logspace(-3, 0, 3),\n",
    "                  'alpha': np.logspace(-3, 0, 3),\n",
    "                  'eta': np.logspace(-3, 0, 3)}\n",
    "xgb = XGBClassifier(scale_pos_weight = false/true, objective = 'binary:logistic')\n",
    "xgb_hyperparams = HalvingGridSearchCV(xgb, parameters_xgb, cv = cv, scoring = 'f1_weighted', random_state=46, verbose=3)\n",
    "xgb_hyperparams.fit(X, y, groups = groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e6e9309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.03162277660168379, 'booster': 'gbtree', 'eta': 1.0, 'lambda': 0.001}\n",
      "0.7175920625692569\n"
     ]
    }
   ],
   "source": [
    "print(xgb_hyperparams.best_params_)\n",
    "print(xgb_hyperparams.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cee688b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb_hyperparams.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ffb64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(scale_pos_weight = 1.67, objective = 'binary:logistic', booster='gbtree', random_state=46, alpha = 0.03162277660168379, eta = 1.0, reg_lambda = 0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2dc7ea7",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107f0889",
   "metadata": {},
   "source": [
    "###### https://towardsdatascience.com/quickly-test-multiple-models-a98477476f0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10e16d59",
   "metadata": {},
   "source": [
    "### Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c23914d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exps(X: pd.DataFrame , y: pd.DataFrame, ID: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''\n",
    "        Lightweight script to test many models and find winners\n",
    "        :param X: features\n",
    "        :param y: target\n",
    "        :param ID: grouping variable for LOSO cross-validation\n",
    "        :return: DataFrame of predictions\n",
    "        '''\n",
    "    \n",
    "        dfs = []\n",
    "        models = [\n",
    "               ('LogReg', logreg_hyperparams.best_estimator_), \n",
    "               ('RF', rf_hyperparams.best_estimator_),\n",
    "               ('GNB', gnb_hyperparams.best_estimator_),\n",
    "               ('XGB', xgb_hyperparams.best_estimator_)\n",
    "               ]\n",
    "        results = []\n",
    "        names = []\n",
    "        scoring = ['balanced_accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted', 'roc_auc']\n",
    "        target_names = ['no-anxiety', 'anxiety']\n",
    "        for name, model in models:\n",
    "                cv_results = cross_validate(model, X, y, cv=cv, scoring=scoring, groups = ID)\n",
    "                y_pred = cross_val_predict(model, X, y, cv=cv, groups = ID)\n",
    "                print(name)\n",
    "                print(classification_report(y, y_pred, target_names=target_names))\n",
    "                results.append(cv_results)\n",
    "                names.append(name)\n",
    "                this_df = pd.DataFrame(cv_results)\n",
    "                this_df['model'] = name\n",
    "                dfs.append(this_df)\n",
    "        final = pd.concat(dfs, ignore_index=True)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68e17cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  no-anxiety       0.85      0.73      0.79     18780\n",
      "     anxiety       0.64      0.79      0.71     11220\n",
      "\n",
      "    accuracy                           0.75     30000\n",
      "   macro avg       0.75      0.76      0.75     30000\n",
      "weighted avg       0.77      0.75      0.76     30000\n",
      "\n",
      "RF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  no-anxiety       0.79      0.74      0.77     18780\n",
      "     anxiety       0.61      0.67      0.64     11220\n",
      "\n",
      "    accuracy                           0.72     30000\n",
      "   macro avg       0.70      0.71      0.70     30000\n",
      "weighted avg       0.72      0.72      0.72     30000\n",
      "\n",
      "GNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  no-anxiety       0.80      0.75      0.77     18780\n",
      "     anxiety       0.62      0.69      0.65     11220\n",
      "\n",
      "    accuracy                           0.73     30000\n",
      "   macro avg       0.71      0.72      0.71     30000\n",
      "weighted avg       0.73      0.73      0.73     30000\n",
      "\n",
      "XGB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  no-anxiety       0.80      0.78      0.79     18780\n",
      "     anxiety       0.65      0.67      0.66     11220\n",
      "\n",
      "    accuracy                           0.74     30000\n",
      "   macro avg       0.72      0.73      0.73     30000\n",
      "weighted avg       0.74      0.74      0.74     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final = run_exps(X=X, y=y, ID=groups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be06c6d4",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "79394ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstraps = []\n",
    "for model in list(set(final.model.values)):\n",
    "    model_df = final.loc[final.model == model]\n",
    "    bootstrap = model_df.sample(n=10, replace=True, random_state=46)\n",
    "    bootstraps.append(bootstrap)\n",
    "        \n",
    "bootstrap_df = pd.concat(bootstraps, ignore_index=True)\n",
    "results_long = pd.melt(bootstrap_df,id_vars=['model'],var_name='metrics', value_name='values')\n",
    "time_metrics = ['fit_time','score_time'] # fit time metrics\n",
    "\n",
    "## PERFORMANCE METRICS\n",
    "results_long_nofit = results_long.loc[~results_long['metrics'].isin(time_metrics)] # get df without fit data\n",
    "results_long_nofit = results_long_nofit.sort_values(by='values')\n",
    "\n",
    "## TIME METRICS\n",
    "results_long_fit = results_long.loc[results_long['metrics'].isin(time_metrics)] # df with fit data\n",
    "results_long_fit = results_long_fit.sort_values(by='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "52c3c529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_nofit)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Classification Metric')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67da277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "g = sns.boxplot(x=\"model\", y=\"values\", hue=\"metrics\", data=results_long_fit)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.title('Comparison of Model by Fit and Score Time')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2daaa554",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "819a3bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_roc_auc</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_recall_weighted</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_balanced_accuracy</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_f1_weighted</th>\n",
       "      <th colspan=\"2\" halign=\"left\">test_precision_weighted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GNB</th>\n",
       "      <td>0.122849</td>\n",
       "      <td>0.868137</td>\n",
       "      <td>0.126059</td>\n",
       "      <td>0.759500</td>\n",
       "      <td>0.151438</td>\n",
       "      <td>0.740708</td>\n",
       "      <td>0.167884</td>\n",
       "      <td>0.731490</td>\n",
       "      <td>0.162967</td>\n",
       "      <td>0.773513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.038712</td>\n",
       "      <td>0.913222</td>\n",
       "      <td>0.054899</td>\n",
       "      <td>0.818001</td>\n",
       "      <td>0.063050</td>\n",
       "      <td>0.817743</td>\n",
       "      <td>0.058193</td>\n",
       "      <td>0.815860</td>\n",
       "      <td>0.053570</td>\n",
       "      <td>0.847109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.233357</td>\n",
       "      <td>0.768358</td>\n",
       "      <td>0.209526</td>\n",
       "      <td>0.722626</td>\n",
       "      <td>0.199105</td>\n",
       "      <td>0.704210</td>\n",
       "      <td>0.206248</td>\n",
       "      <td>0.716705</td>\n",
       "      <td>0.200170</td>\n",
       "      <td>0.755350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.194420</td>\n",
       "      <td>0.821513</td>\n",
       "      <td>0.166753</td>\n",
       "      <td>0.751453</td>\n",
       "      <td>0.155451</td>\n",
       "      <td>0.732203</td>\n",
       "      <td>0.173564</td>\n",
       "      <td>0.738760</td>\n",
       "      <td>0.151795</td>\n",
       "      <td>0.784158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       test_roc_auc           test_recall_weighted            \\\n",
       "                std      mean                  std      mean   \n",
       "model                                                          \n",
       "GNB        0.122849  0.868137             0.126059  0.759500   \n",
       "LogReg     0.038712  0.913222             0.054899  0.818001   \n",
       "RF         0.233357  0.768358             0.209526  0.722626   \n",
       "XGB        0.194420  0.821513             0.166753  0.751453   \n",
       "\n",
       "       test_balanced_accuracy           test_f1_weighted            \\\n",
       "                          std      mean              std      mean   \n",
       "model                                                                \n",
       "GNB                  0.151438  0.740708         0.167884  0.731490   \n",
       "LogReg               0.063050  0.817743         0.058193  0.815860   \n",
       "RF                   0.199105  0.704210         0.206248  0.716705   \n",
       "XGB                  0.155451  0.732203         0.173564  0.738760   \n",
       "\n",
       "       test_precision_weighted            \n",
       "                           std      mean  \n",
       "model                                     \n",
       "GNB                   0.162967  0.773513  \n",
       "LogReg                0.053570  0.847109  \n",
       "RF                    0.200170  0.755350  \n",
       "XGB                   0.151795  0.784158  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = list(set(results_long_nofit.metrics.values))\n",
    "bootstrap_df.groupby(['model'])[metrics].agg([np.std, np.mean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a495be64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">score_time</th>\n",
       "      <th colspan=\"2\" halign=\"left\">fit_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GNB</th>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.019042</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.020419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.025550</td>\n",
       "      <td>0.123518</td>\n",
       "      <td>1.463087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.035606</td>\n",
       "      <td>0.074287</td>\n",
       "      <td>5.430568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.036248</td>\n",
       "      <td>0.111681</td>\n",
       "      <td>1.444102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score_time            fit_time          \n",
       "              std      mean       std      mean\n",
       "model                                          \n",
       "GNB      0.003339  0.019042  0.002345  0.020419\n",
       "LogReg   0.005072  0.025550  0.123518  1.463087\n",
       "RF       0.002636  0.035606  0.074287  5.430568\n",
       "XGB      0.004727  0.036248  0.111681  1.444102"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_metrics = list(set(results_long_fit.metrics.values))\n",
    "bootstrap_df.groupby(['model'])[time_metrics].agg([np.std, np.mean])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74976342-0409-40f7-9a66-6fba19753cb1",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f8d45ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "for i, clf in enumerate([logreg_hyperparams.best_estimator_, rf_hyperparams.best_estimator_, gnb_hyperparams.best_estimator_, xgb_hyperparams.best_estimator_]):\n",
    "    prediction = cross_val_predict(clf, X, y, cv=cv, groups=groups)\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y, prediction, display_labels=np.unique(y), normalize='true')\n",
    "    disp.plot(ax=axes[i], colorbar=True, cmap='coolwarm')\n",
    "    disp.ax_.set_title(f\"Model {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dcc2fcc",
   "metadata": {},
   "source": [
    "### McNemar's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2992dff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pred = cross_val_predict(logreg, X, y, cv=cv, groups=groups)\n",
    "gnb_pred = cross_val_predict(gnb, X, y, cv=cv, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d71ec4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19284  3338]\n",
      " [ 2513  4865]]\n",
      "chi-squared: 116.04443684840199\n",
      "p-value: 4.647651116708927e-27\n"
     ]
    }
   ],
   "source": [
    "tb = mcnemar_table(y_target=y, \n",
    "                   y_model1=logreg_pred, \n",
    "                   y_model2=gnb_pred, )\n",
    "\n",
    "print(tb)\n",
    "\n",
    "chi2, p = mcnemar(ary=tb, corrected=True)\n",
    "print('chi-squared:', chi2)\n",
    "print('p-value:', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f8f86",
   "metadata": {},
   "source": [
    "### Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "581570d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explainer = shap.Explainer(logreg, X)\n",
    "shap_values = explainer(X)\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2ecf6cd-8a73-4054-a03c-cb92973106e5",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9a114bca-858d-47ac-9454-2e4dd865be3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    classmap = {\n",
    "        0: 'Baseline',\n",
    "        1: 'Stress'\n",
    "    }\n",
    "    c_code = port(logreg_hyperparams.best_estimator_, classmap=classmap)\n",
    "\n",
    "    with open('C:/Users/aless/OneDrive - Universit√† degli Studi di Catania/tesi/codes/arduinocode/Final_code/Classifier.h', 'w') as file:\n",
    "        file.write(c_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "25a53023",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/Users/aless/OneDrive - Universit√† degli Studi di Catania/tesi/codes/ML and DL - Python/ML/classifier.sav'\n",
    "pickle.dump(logreg_hyperparams.best_estimator_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da538524",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "110a4ad9b3b23ac6a757cfb6c77f1e39e8d0496598f07ec14a944919c025e818"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
